{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e15c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f26a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal #dùng cho môi trường liên tục\n",
    "from torch.distributions import Categorical #Lựa chọn hành động từ phân phối rời rạc.\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09648e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1bfd7",
   "metadata": {},
   "source": [
    "PAPER ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab618a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV_paper():\n",
    "    def __init__(self,\n",
    "                 lambda_rate,\n",
    "                 D_max,\n",
    "                 xi,\n",
    "                 max_power,\n",
    "                 snr_feedback,\n",
    "                 harq_type):\n",
    "        \n",
    "\n",
    "        # Tham số hệ thống\n",
    "        self.lambda_rate = lambda_rate  # Tốc độ đến trung bình (bit/slot)\n",
    "        self.D_max = D_max  # Độ trễ tối đa (slot)\n",
    "        self.xi = xi  # Xác suất vi phạm độ trễ mục tiêu\n",
    "        self.max_power = max_power  # Công suất tối đa\n",
    "        self.snr_feedback = snr_feedback  # Có phản hồi SNR hay không\n",
    "        self.harq_type = harq_type  # Loại HARQ: 'CC' hoặc 'IR'\n",
    "        self.n = 200  # Số lần sử dụng kênh mỗi slot\n",
    "        self.T = int(10 / xi)  # Số slot mỗi episode\n",
    "        self.Delta = 20 * max_power  # Hằng số phạt lớn\n",
    "        self.beta = 16  # Số mũ cho hàm phạt\n",
    "\n",
    "\n",
    "        # Không gian trạng thái\n",
    "        state_dim = 4 if not snr_feedback else 5\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(state_dim,), dtype=np.float32)\n",
    "\n",
    "\n",
    "        # Không gian hành động: [R(t), p(t)]\n",
    "        self.action_space = gym.spaces.Box(low=np.array([0.1, 0.5]), high=np.array([np.inf, max_power]), dtype=np.float32)\n",
    "\n",
    "        # Bộ nhớ lịch sử A(t) cho D_max slot gần nhất\n",
    "        self.arrival_history = []\n",
    "        self.previous_snrs = []\n",
    "\n",
    "        # Khởi tạo trạng thái\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        #Đặt lại môi trường về trạng thái ban đầu\n",
    "        self.q_t = 0  # Độ dài hàng đợi\n",
    "        self.A_t = np.random.poisson(self.lambda_rate)  # Số bit đến\n",
    "        self.d_t = 0  # Số lần vi phạm độ trễ trong episode\n",
    "        self.k = 0  # Số lần truyền của gói tin hiện tại\n",
    "        self.t = 0  # đếm bước hiện tại\n",
    "        self.gamma_k = 0 if self.snr_feedback else None  # SNR còn lại\n",
    "        self.arrival_history = [self.A_t]\n",
    "        self.previous_snrs = []\n",
    "        state = [self.q_t, self.A_t, self.d_t, self.k]\n",
    "        if self.snr_feedback:\n",
    "            state.append(self.gamma_k)\n",
    "        return np.array(state)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        R_t, p_t = action  # Tốc độ mã hóa và công suất truyền\n",
    "        self.t += 1\n",
    "\n",
    "\n",
    "        R_t = max(R_t, 0.1)\n",
    "        p_t = np.clip(p_t, 0.5, self.max_power)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Mô phỏng kênh fading Rayleigh\n",
    "        h = np.random.normal(0, 1) + 1j * np.random.normal(0, 1)\n",
    "        snr = p_t * (np.abs(h)**2)\n",
    "\n",
    "\n",
    "\n",
    "        # Xác định thành công truyền\n",
    "        if self.k == 0:  # Truyền mới\n",
    "            success = np.log2(1 + snr) >= R_t\n",
    "        else:  # Truyền lại\n",
    "            if self.harq_type == 'CC':\n",
    "                if self.snr_feedback:\n",
    "                    accumulated_snr = sum(self.previous_snrs) + snr\n",
    "                    success = np.log2(1 + accumulated_snr) >= R_t\n",
    "                else:\n",
    "                    # Giả định công suất không đổi qua các lần truyền lại\n",
    "                    # Cần xem lại vì mỗi lần truyền lại p_t không đổi nhưng có h khác nhau\n",
    "                    accumulated_snr = sum(self.previous_snrs) + snr\n",
    "                    success = np.log2(1 + accumulated_snr) >= R_t\n",
    "            elif self.harq_type == 'IR':\n",
    "                if self.snr_feedback:\n",
    "                    total_rate = sum([np.log2(1 + s) for s in self.previous_snrs]) + np.log2(1 + snr)\n",
    "                    success = total_rate >= R_t\n",
    "        \n",
    "\n",
    "        \n",
    "        # Tính toán tốc độ phục vụ S(t)\n",
    "        S_t = self.n * R_t if success else 0\n",
    "\n",
    "        # Cập nhật độ dài hàng đợi tạm thời\n",
    "        q_tmp = max(self.q_t + self.A_t - S_t, 0)\n",
    "\n",
    "\n",
    "        \n",
    "        # Tính q_th(t) dựa trên lịch sử A(t) trong D_max slot\n",
    "        if len(self.arrival_history) >= self.D_max:\n",
    "            q_th = sum(self.arrival_history[-self.D_max:])\n",
    "        else:\n",
    "            q_th = sum(self.arrival_history)\n",
    "        \n",
    "        # Kiểm tra vi phạm độ trễ\n",
    "        if q_tmp > q_th:\n",
    "            self.d_t += 1\n",
    "            w_t = self._calculate_penalty()\n",
    "            reward = -p_t - w_t\n",
    "        else:\n",
    "            reward = -p_t\n",
    "        \n",
    "        # Cập nhật hàng đợi với PODD\n",
    "        self.q_t = min(q_tmp, q_th)\n",
    "\n",
    "\n",
    "\n",
    "        # Cập nhật trạng thái\n",
    "        self.A_t = np.random.poisson(self.lambda_rate)\n",
    "        self.arrival_history.append(self.A_t)\n",
    "        if len(self.arrival_history) > self.D_max:\n",
    "            self.arrival_history.pop(0)\n",
    "        \n",
    "        if success:\n",
    "            self.k = 0\n",
    "            self.gamma_k = 0 if self.snr_feedback else None\n",
    "            self.previous_snrs = []\n",
    "        else:\n",
    "            self.k += 1\n",
    "            self.previous_snrs.append(snr)\n",
    "            if self.snr_feedback:\n",
    "                if self.harq_type == 'CC':\n",
    "                    self.gamma_k = max(2**R_t - 1 - sum(self.previous_snrs), 0)\n",
    "                elif self.harq_type == 'IR':\n",
    "                    self.gamma_k = max((2**R_t) / np.prod([1 + s for s in self.previous_snrs]) - 1, 0)\n",
    "        \n",
    "        state = [self.q_t, self.A_t, self.d_t, self.k]\n",
    "        if self.snr_feedback:\n",
    "            state.append(self.gamma_k)\n",
    "        \n",
    "        # Kiểm tra kết thúc episode (giả định đơn giản)\n",
    "        done = self.t >= self.T\n",
    "        \n",
    "        info = {'power': p_t, 'delay_violation': self.d_t, 'Rate': R_t}\n",
    "        \n",
    "        return np.array(state), reward, done, info\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _calculate_penalty(self):\n",
    "        #Tính toán giá trị phạt w(t) dựa trên số lần vi phạm độ trễ.\n",
    "        if self.d_t <= self.T * self.xi:\n",
    "            return self.Delta * (self.d_t / (self.T * self.xi)) ** self.beta\n",
    "        return self.Delta\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337bec74",
   "metadata": {},
   "source": [
    "Tạo RolloutBuffer, lưu data lại để train, tạo hàm để update lúc train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51be318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RolloutBuffer Bộ nhớ tạm lưu giữ thông tin huấn luyện sau\n",
    "#lưu trữ tạm thời các quỹ đạo \n",
    "#tập hợp dữ liệu về các tương tác của tác nhân (agent) với môi trường trong một tập hợp (episode), tính hàm lợi thế\n",
    "\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = [] #Lưu các hành động đã thực hiện\n",
    "        self.states = []  #Lưu các trạng thái hiện tại\n",
    "        self.logprobs = []#Lưu log của xác suất pi(a|s)\n",
    "        self.rewards = [] #Lưu lại reward\n",
    "        self.state_values = [] # Giá trị trạng thái V do critic dự đoán, để tính hàm lợi thế\n",
    "        self.is_terminals = [] #Lưu lại cờ kết thúc\n",
    "\n",
    "\n",
    "    def clear(self): #xóa buffer để update data mới\n",
    "        del self.actions[:] \n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.state_values[:]\n",
    "        del self.is_terminals[:]\n",
    "\n",
    "\n",
    "#Actor: Mạng chính sách, xuất ra phân phối xác suất dựa trên trạng thái\n",
    "#Critic: Mạng giá trị, Ước lượng giá trị trạng thái (Vt) để tính hàm ưu tiên\n",
    "#hàm này giúp Agent chọn lọc hành động, đánh giá được trạng thái.\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std = None):\n",
    "        #state_dim: Số chiều của state\n",
    "        #action_dim: số chiều của action\n",
    "        #xem action có liên tục không\n",
    "        #action_std_init: độ lệch chuẩn cho phân phối liên tục\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        #Nếu hành động liên tục lưu lại chiều hành động chuyển đến phương sai action_std_init^2\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std * action_std).to(device)\n",
    "\n",
    "        # ACTOR\n",
    "        if has_continuous_action_space : # continuous action space\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 128),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(128, 128),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(128, action_dim),\n",
    "                            #nn.Tanh()\n",
    "        #Nếu là hành động liên tục thì đầu ra là trung bình u(s) phân phối Gauss => phân phối hành động π(a|s) = N(u,tổng)\n",
    "        #Tanh giới hạn đầu ra từ [-1,1], phù hợp vs phạm v hành động\n",
    "                        )\n",
    "        else: # discrete action space\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 128),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(128, 128),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(128, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "        #Không gian rời rạc: xuất ra xác suất cho từng action rời rạc theo Softmax\n",
    "\n",
    "        # CRITIC\n",
    "        # Tương tự như actor nhưng xuất ra là 1 giá trị đơn ước lượng giá trị trạng thái Vt\n",
    "        # Dùng để tính hàm lợi thế At = Q(s,a) - Vt\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 128),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(128, 128),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(128, 1)\n",
    "                    )\n",
    "        \n",
    "    #Cập nhật phương sai cho hành động liên tục\n",
    "    #tức là điều chỉnh khám phá, độ biến động cho các action\n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "    \n",
    "    def act(self, state): #đầu vào là state hiện tại\n",
    "\n",
    "        # ACTOR\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state) #Nếu đầu vào là state liên tục thì đầu ra actor là giá trị trung bình u phân phối gauss\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0) #phương sai Cov\n",
    "            dist = MultivariateNormal(action_mean, cov_mat) #tạo phân phối đa biến\n",
    "        else:\n",
    "            action_probs = self.actor(state) #đầu ra softmax\n",
    "            dist = Categorical(action_probs) #phân phối rời rạc\n",
    "\n",
    "        action = dist.sample() #chọn hành động bằng cách lấy mẫu phân phối \n",
    "        action_logprob = dist.log_prob(action) #lấy log của các suất được chọn (π(a|s))\n",
    "\n",
    "        # CRITIC\n",
    "        state_val = self.critic(state) #xuất ra giá Vt từ critic\n",
    "\n",
    "        return action.detach(), action_logprob.detach(), state_val.detach() #trả về action, log, Vt để lưu vào RolloutBuffer\n",
    "\n",
    "    #Dùng để tính toán lại các giá trị cần thiết khi cập nhật danh sách:\n",
    "        #+Log xác suất hành động \n",
    "        #+Entropy của chính sách\n",
    "        #+Ước lượng giá trị trạng thái Vt\n",
    "    # Đầu vào là state, action cũ đầu ra là logprob (mới), value (mới), entropy\n",
    "    # So sánh policy cũ và mới.\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        # ACTOR\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "\n",
    "            # for single action continuous environments\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "\n",
    "        # CRITIC\n",
    "        state_values = self.critic(state)\n",
    "\n",
    "        return action_logprobs, state_values, dist_entropy \n",
    "# Tại sao có act rồi cần dùng evaluate:\n",
    "#    + act dùng để action và thu thập dữ liệu xong lưu vào RolloutBuffer để train\n",
    "#    + evaluate dùng để tính toán train, policy cũ và mới: ratio, advantage, entropy.\n",
    "# act → buffer → evaluate → loss → update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c85aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, lambda_gae, K_epochs, eps_clip, has_continuous_action_space, action_std, minibatch_size=200):\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        self.lambda_gae = lambda_gae\n",
    "        self.minibatch_size = minibatch_size  # Thêm minibatch_size\n",
    "\n",
    "        self.buffer = RolloutBuffer()\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "            {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "            {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "        ])\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "    def select_action(self, state):\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob, state_val = self.policy_old.act(state)\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "            self.buffer.state_values.append(state_val)\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob, state_val = self.policy_old.act(state)\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "            self.buffer.state_values.append(state_val)\n",
    "            return action.item()\n",
    "\n",
    "    def update(self):\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "        old_state_values = torch.squeeze(torch.stack(self.buffer.state_values, dim=0)).detach().to(device)\n",
    "        is_terminals = torch.tensor(self.buffer.is_terminals, dtype=torch.float32).to(device)\n",
    "\n",
    "        # Compute advantages using GAE\n",
    "        advantages = torch.zeros_like(rewards).to(device)\n",
    "        gae = 0\n",
    "        for t in reversed(range(len(rewards))):\n",
    "            if t == len(rewards) - 1:\n",
    "                next_value = 0  # No next state value at the end\n",
    "            else:\n",
    "                next_value = old_state_values[t + 1] * (1 - is_terminals[t + 1])\n",
    "            delta = rewards[t] + self.gamma * next_value - old_state_values[t]\n",
    "            gae = delta + self.gamma * self.lambda_gae * (1 - is_terminals[t]) * gae\n",
    "            advantages[t] = gae\n",
    "\n",
    "        # Normalize advantages\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-7)\n",
    "\n",
    "        # Create TensorDataset and DataLoader\n",
    "        dataset = TensorDataset(old_states, old_actions, old_logprobs, rewards, advantages)\n",
    "        dataloader = DataLoader(dataset, batch_size=self.minibatch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "            for batch in dataloader:\n",
    "                batch_states, batch_actions, batch_logprobs, batch_rewards, batch_advantages = batch\n",
    "                logprobs, state_values, dist_entropy = self.policy.evaluate(batch_states, batch_actions)\n",
    "                state_values = torch.squeeze(state_values)\n",
    "                ratios = torch.exp(logprobs - batch_logprobs.detach())\n",
    "                surr1 = ratios * batch_advantages\n",
    "                surr2 = torch.clamp(ratios, 1 - self.eps_clip, 1 + self.eps_clip) * batch_advantages\n",
    "                loss = -torch.min(surr1, surr2) + 0.5 * self.MseLoss(state_values, batch_rewards) - 0.01 * dist_entropy\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.mean().backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # Clear buffer\n",
    "        self.buffer.clear()\n",
    "\n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f94ce84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------\n",
      "max training timesteps :  5000000\n",
      "max timesteps per episode :  1000\n",
      "log frequency : 2000 timesteps\n",
      "printing average reward over episodes in last : 4000 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "state space dimension :  5\n",
      "action space dimension :  2\n",
      "--------------------------------------------------------------------------------------------\n",
      "Initializing a continuous action space policy\n",
      "--------------------------------------------------------------------------------------------\n",
      "starting std of action distribution :  0.5\n",
      "decay rate of std of action distribution :  0.005\n",
      "minimum std of action distribution :  0.1\n",
      "decay frequency of std of action distribution : 50000 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "PPO update frequency : 2048 timesteps\n",
      "PPO K epochs :  80\n",
      "PPO epsilon clip :  0.2\n",
      "discount factor (gamma) :  0.99\n",
      "--------------------------------------------------------------------------------------------\n",
      "optimizer learning rate actor :  0.0002\n",
      "optimizer learning rate critic :  0.0002\n",
      "============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "C:\\Users\\DELL\\AppData\\Roaming\\Python\\Python39\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode  0 : Reward =  -542910.5120661517\n",
      "Saving better model at episode 0 with reward -542910.5120661517\n",
      "Episode  1 : Reward =  -542912.8751106521\n",
      "Episode  2 : Reward =  -539031.6553371885\n",
      "Saving better model at episode 2 with reward -539031.6553371885\n",
      "Episode  3 : Reward =  -542363.0181350041\n",
      "Episode  4 : Reward =  -541248.1592348084\n",
      "Episode  5 : Reward =  -543465.6051366917\n",
      "Episode  6 : Reward =  -541805.4214673834\n",
      "Episode  7 : Reward =  -540134.0872987312\n",
      "Episode  8 : Reward =  -541799.0235612588\n",
      "Episode  9 : Reward =  -545686.8663812397\n",
      "Episode  10 : Reward =  -540692.214943601\n",
      "Episode  11 : Reward =  -544030.5440688455\n",
      "Episode  12 : Reward =  -540144.4813564223\n",
      "Episode  13 : Reward =  -541811.663877924\n",
      "Episode  14 : Reward =  -540143.3568079275\n",
      "Episode  15 : Reward =  -543473.551163911\n",
      "Episode  16 : Reward =  -539585.0740469168\n",
      "Episode  17 : Reward =  -539588.1652832697\n",
      "Episode  18 : Reward =  -539036.3734256962\n",
      "Episode  19 : Reward =  -542365.0759248663\n",
      "Episode  20 : Reward =  -539590.3382361601\n",
      "Episode  21 : Reward =  -539033.9893257358\n",
      "Episode  22 : Reward =  -539035.4314932564\n",
      "Episode  23 : Reward =  -544580.4296428616\n",
      "Episode  24 : Reward =  -540145.7708556455\n",
      "Episode  25 : Reward =  -539037.248842273\n",
      "Episode  26 : Reward =  -542918.4607777854\n",
      "Episode  27 : Reward =  -542921.480619218\n",
      "Episode  28 : Reward =  -540700.248428358\n",
      "Episode  29 : Reward =  -542909.1280913611\n",
      "Episode  30 : Reward =  -541245.4308079347\n",
      "Episode  31 : Reward =  -541799.256826778\n",
      "Episode  32 : Reward =  -542359.7972055007\n",
      "Episode  33 : Reward =  -539031.4445093015\n",
      "Saving better model at episode 33 with reward -539031.4445093015\n",
      "Episode  34 : Reward =  -540697.1394276752\n",
      "Episode  35 : Reward =  -542362.7829570699\n",
      "Episode  36 : Reward =  -541804.4665999012\n",
      "Episode  37 : Reward =  -541807.1267016726\n",
      "Episode  38 : Reward =  -544021.0978426063\n",
      "Episode  39 : Reward =  -542359.7607335377\n",
      "Episode  40 : Reward =  -540144.5324132246\n",
      "Episode  41 : Reward =  -541797.9068853455\n",
      "Episode  42 : Reward =  -544576.399252897\n",
      "Episode  43 : Reward =  -543467.6957704417\n",
      "Episode  44 : Reward =  -541246.3279266224\n",
      "Episode  45 : Reward =  -540135.641300599\n",
      "Episode  46 : Reward =  -540695.6637553109\n",
      "Episode  47 : Reward =  -544018.5587475025\n",
      "Episode  48 : Reward =  -542356.9881631065\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.495\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  49 : Reward =  -539033.7203017214\n",
      "Episode  50 : Reward =  -539583.9665467213\n",
      "Episode  51 : Reward =  -542906.733655717\n",
      "Episode  52 : Reward =  -540697.8638993038\n",
      "Episode  53 : Reward =  -539024.4279986956\n",
      "Saving better model at episode 53 with reward -539024.4279986956\n",
      "Episode  54 : Reward =  -541245.7809324131\n",
      "Episode  55 : Reward =  -541245.2543591127\n",
      "Episode  56 : Reward =  -541247.9246432647\n",
      "Episode  57 : Reward =  -544022.004605981\n",
      "Episode  58 : Reward =  -540699.7100572123\n",
      "Episode  59 : Reward =  -539030.469460819\n",
      "Episode  60 : Reward =  -539583.5410867403\n",
      "Episode  61 : Reward =  -541805.6342528062\n",
      "Episode  62 : Reward =  -543472.3454154722\n",
      "Episode  63 : Reward =  -541252.9382536873\n",
      "Episode  64 : Reward =  -541258.6097236738\n",
      "Episode  65 : Reward =  -541266.109069334\n",
      "Episode  66 : Reward =  -541821.0593194561\n",
      "Episode  67 : Reward =  -545145.0152499464\n",
      "Episode  68 : Reward =  -543485.6721049539\n",
      "Episode  69 : Reward =  -540712.2160081996\n",
      "Episode  70 : Reward =  -545149.351888099\n",
      "Episode  71 : Reward =  -541252.5807040796\n",
      "Episode  72 : Reward =  -543480.9324424259\n",
      "Episode  73 : Reward =  -544034.3140883171\n",
      "Episode  74 : Reward =  -542365.0725290704\n",
      "Episode  75 : Reward =  -538487.9507668025\n",
      "Saving better model at episode 75 with reward -538487.9507668025\n",
      "Episode  76 : Reward =  -541818.4768849807\n",
      "Episode  77 : Reward =  -544595.287839597\n",
      "Episode  78 : Reward =  -542920.8280838986\n",
      "Episode  79 : Reward =  -538480.3715220101\n",
      "Saving better model at episode 79 with reward -538480.3715220101\n",
      "Episode  80 : Reward =  -541256.2096122965\n",
      "Episode  81 : Reward =  -539034.6705577114\n",
      "Episode  82 : Reward =  -540148.9557763737\n",
      "Episode  83 : Reward =  -542924.9543635508\n",
      "Episode  84 : Reward =  -544040.4864059412\n",
      "Episode  85 : Reward =  -544040.3237778866\n",
      "Episode  86 : Reward =  -542359.938112073\n",
      "Episode  87 : Reward =  -541251.4632114634\n",
      "Episode  88 : Reward =  -545151.0942883876\n",
      "Episode  89 : Reward =  -543483.4710814349\n",
      "Episode  90 : Reward =  -543484.1836919776\n",
      "Episode  91 : Reward =  -543477.0134057394\n",
      "Episode  92 : Reward =  -540710.0739117397\n",
      "Episode  93 : Reward =  -538486.098917783\n",
      "Episode  94 : Reward =  -539035.514559839\n",
      "Episode  95 : Reward =  -542365.0297605324\n",
      "Episode  96 : Reward =  -545139.9323471573\n",
      "Episode  97 : Reward =  -545141.5847048548\n",
      "Episode  98 : Reward =  -543471.074416279\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.49\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  99 : Reward =  -544585.1155514772\n",
      "Episode  100 : Reward =  -545689.9509162424\n",
      "Episode  101 : Reward =  -542355.649942093\n",
      "Episode  102 : Reward =  -542359.8384441066\n",
      "Episode  103 : Reward =  -541250.0275633201\n",
      "Episode  104 : Reward =  -544582.2442816551\n",
      "Episode  105 : Reward =  -540692.614337994\n",
      "Episode  106 : Reward =  -542911.8682347198\n",
      "Episode  107 : Reward =  -546809.0116822304\n",
      "Episode  108 : Reward =  -544581.6106662209\n",
      "Episode  109 : Reward =  -544032.8593740189\n",
      "Episode  110 : Reward =  -536263.8659343601\n",
      "Saving better model at episode 110 with reward -536263.8659343601\n",
      "Episode  111 : Reward =  -545140.5707643416\n",
      "Episode  112 : Reward =  -542920.1900714298\n",
      "Episode  113 : Reward =  -540701.2370264663\n",
      "Episode  114 : Reward =  -537925.0693593299\n",
      "Episode  115 : Reward =  -537370.4068296496\n",
      "Episode  116 : Reward =  -538479.7568427331\n",
      "Episode  117 : Reward =  -541247.4593214855\n",
      "Episode  118 : Reward =  -541806.8336880403\n",
      "Episode  119 : Reward =  -542915.0166465302\n",
      "Episode  120 : Reward =  -544029.0149913752\n",
      "Episode  121 : Reward =  -539032.0881967881\n",
      "Episode  122 : Reward =  -540695.069903685\n",
      "Episode  123 : Reward =  -540136.6549321216\n",
      "Episode  124 : Reward =  -541254.3990046248\n",
      "Episode  125 : Reward =  -542354.2289401222\n",
      "Episode  126 : Reward =  -542353.4902529645\n",
      "Episode  127 : Reward =  -541803.3037601905\n",
      "Episode  128 : Reward =  -542909.1294953485\n",
      "Episode  129 : Reward =  -540684.0639010204\n",
      "Episode  130 : Reward =  -541795.7591505246\n",
      "Episode  131 : Reward =  -541797.4710039692\n",
      "Episode  132 : Reward =  -539577.0299847792\n",
      "Episode  133 : Reward =  -543463.0120398394\n",
      "Episode  134 : Reward =  -543463.072791814\n",
      "Episode  135 : Reward =  -543467.1204980008\n",
      "Episode  136 : Reward =  -540687.9155178203\n",
      "Episode  137 : Reward =  -542350.724970572\n",
      "Episode  138 : Reward =  -542349.955572002\n",
      "Episode  139 : Reward =  -536251.9973817945\n",
      "Saving better model at episode 139 with reward -536251.9973817945\n",
      "Episode  140 : Reward =  -542353.8802967\n",
      "Episode  141 : Reward =  -538471.5111916668\n",
      "Episode  142 : Reward =  -540137.6073720854\n",
      "Episode  143 : Reward =  -536243.5011098862\n",
      "Saving better model at episode 143 with reward -536243.5011098862\n",
      "Episode  144 : Reward =  -542905.6728797217\n",
      "Episode  145 : Reward =  -543460.1104599229\n",
      "Episode  146 : Reward =  -541240.3329273328\n",
      "Episode  147 : Reward =  -537911.6862058913\n",
      "Episode  148 : Reward =  -542351.0722513128\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.485\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  149 : Reward =  -539575.5577860544\n",
      "Episode  150 : Reward =  -544013.433478924\n",
      "Episode  151 : Reward =  -539023.8124208787\n",
      "Episode  152 : Reward =  -541798.0640419917\n",
      "Episode  153 : Reward =  -540130.571886341\n",
      "Episode  154 : Reward =  -539022.461219702\n",
      "Episode  155 : Reward =  -539572.9476001333\n",
      "Episode  156 : Reward =  -538462.6084328301\n",
      "Episode  157 : Reward =  -540684.9142770304\n",
      "Episode  158 : Reward =  -534581.489614674\n",
      "Saving better model at episode 158 with reward -534581.489614674\n",
      "Episode  159 : Reward =  -539022.158264909\n",
      "Episode  160 : Reward =  -538466.5735668547\n",
      "Episode  161 : Reward =  -541241.583242105\n",
      "Episode  162 : Reward =  -539018.6316442826\n",
      "Episode  163 : Reward =  -537348.8724766914\n",
      "Episode  164 : Reward =  -540691.5387010707\n",
      "Episode  165 : Reward =  -538467.6547729976\n",
      "Episode  166 : Reward =  -544016.9557403647\n",
      "Episode  167 : Reward =  -538465.7063465721\n",
      "Episode  168 : Reward =  -539583.6628021072\n",
      "Episode  169 : Reward =  -537908.5083872353\n",
      "Episode  170 : Reward =  -537907.3997064506\n",
      "Episode  171 : Reward =  -540128.4853675765\n",
      "Episode  172 : Reward =  -539021.2481648066\n",
      "Episode  173 : Reward =  -537359.7696843091\n",
      "Episode  174 : Reward =  -540688.9774584903\n",
      "Episode  175 : Reward =  -542355.9469491768\n",
      "Episode  176 : Reward =  -538473.0098376281\n",
      "Episode  177 : Reward =  -537363.195197219\n",
      "Episode  178 : Reward =  -537913.5744435465\n",
      "Episode  179 : Reward =  -534587.5039110269\n",
      "Episode  180 : Reward =  -530143.4988727403\n",
      "Saving better model at episode 180 with reward -530143.4988727403\n",
      "Episode  181 : Reward =  -537920.0258078849\n",
      "Episode  182 : Reward =  -535145.1955891666\n",
      "Episode  183 : Reward =  -537364.6477857176\n",
      "Episode  184 : Reward =  -540139.7274383706\n",
      "Episode  185 : Reward =  -535699.4090404062\n",
      "Episode  186 : Reward =  -536253.7861512185\n",
      "Episode  187 : Reward =  -536251.9062235237\n",
      "Episode  188 : Reward =  -536251.4732789875\n",
      "Episode  189 : Reward =  -536808.408143601\n",
      "Episode  190 : Reward =  -536247.7524279833\n",
      "Episode  191 : Reward =  -535139.4269443569\n",
      "Episode  192 : Reward =  -538469.7632632859\n",
      "Episode  193 : Reward =  -534586.8171898212\n",
      "Episode  194 : Reward =  -537363.5138005558\n",
      "Episode  195 : Reward =  -536806.4665492984\n",
      "Episode  196 : Reward =  -537913.6604714071\n",
      "Episode  197 : Reward =  -530704.5273158713\n",
      "Episode  198 : Reward =  -532362.8551715572\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.48\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  199 : Reward =  -538471.2243235118\n",
      "Episode  200 : Reward =  -533476.6408733748\n",
      "Episode  201 : Reward =  -536245.2118210078\n",
      "Episode  202 : Reward =  -532916.0977650573\n",
      "Episode  203 : Reward =  -538468.8250604279\n",
      "Episode  204 : Reward =  -534579.6288147654\n",
      "Episode  205 : Reward =  -537357.6799988691\n",
      "Episode  206 : Reward =  -530695.346486704\n",
      "Episode  207 : Reward =  -536798.2001661869\n",
      "Episode  208 : Reward =  -534021.3951644653\n",
      "Episode  209 : Reward =  -534588.0342665996\n",
      "Episode  210 : Reward =  -534032.6642866486\n",
      "Episode  211 : Reward =  -529589.0756726365\n",
      "Saving better model at episode 211 with reward -529589.0756726365\n",
      "Episode  212 : Reward =  -533479.5290582202\n",
      "Episode  213 : Reward =  -529592.8583905201\n",
      "Episode  214 : Reward =  -530711.0683296486\n",
      "Episode  215 : Reward =  -527376.8850873087\n",
      "Saving better model at episode 215 with reward -527376.8850873087\n",
      "Episode  216 : Reward =  -523492.93879604863\n",
      "Saving better model at episode 216 with reward -523492.93879604863\n",
      "Episode  217 : Reward =  -527928.4448009437\n",
      "Episode  218 : Reward =  -525705.0400753795\n",
      "Episode  219 : Reward =  -531815.9196751344\n",
      "Episode  220 : Reward =  -525154.4543005673\n",
      "Episode  221 : Reward =  -535143.5597802815\n",
      "Episode  222 : Reward =  -527372.9794729326\n",
      "Episode  223 : Reward =  -536259.2611592293\n",
      "Episode  224 : Reward =  -531260.2396929757\n",
      "Episode  225 : Reward =  -535705.6993586569\n",
      "Episode  226 : Reward =  -529601.1680675249\n",
      "Episode  227 : Reward =  -528490.4979360737\n",
      "Episode  228 : Reward =  -531264.8523287073\n",
      "Episode  229 : Reward =  -527383.4054988001\n",
      "Episode  230 : Reward =  -526828.2115717771\n",
      "Episode  231 : Reward =  -527932.3152464336\n",
      "Episode  232 : Reward =  -530708.4159612819\n",
      "Episode  233 : Reward =  -525719.0853458225\n",
      "Episode  234 : Reward =  -521281.1048875974\n",
      "Saving better model at episode 234 with reward -521281.1048875974\n",
      "Episode  235 : Reward =  -530711.743323402\n",
      "Episode  236 : Reward =  -529604.8466185431\n",
      "Episode  237 : Reward =  -531268.3859830395\n",
      "Episode  238 : Reward =  -527425.8413118098\n",
      "Episode  239 : Reward =  -526309.7169783623\n",
      "Episode  240 : Reward =  -529650.7890086274\n",
      "Episode  241 : Reward =  -533531.8039131187\n",
      "Episode  242 : Reward =  -533559.7766870878\n",
      "Episode  243 : Reward =  -528010.6161098188\n",
      "Episode  244 : Reward =  -529135.8120741019\n",
      "Episode  245 : Reward =  -530791.0070402785\n",
      "Episode  246 : Reward =  -533555.8010134719\n",
      "Episode  247 : Reward =  -537996.2307397401\n",
      "Episode  248 : Reward =  -537425.7302515451\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.475\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  249 : Reward =  -535761.9602850227\n",
      "Episode  250 : Reward =  -540768.0004384054\n",
      "Episode  251 : Reward =  -537447.3600199167\n",
      "Episode  252 : Reward =  -539657.5314801405\n",
      "Episode  253 : Reward =  -537446.5661345068\n",
      "Episode  254 : Reward =  -540208.1119141382\n",
      "Episode  255 : Reward =  -539641.1058418821\n",
      "Episode  256 : Reward =  -535187.8969361004\n",
      "Episode  257 : Reward =  -540189.6805872124\n",
      "Episode  258 : Reward =  -543526.2824603907\n",
      "Episode  259 : Reward =  -546300.5284029096\n",
      "Episode  260 : Reward =  -544708.8668258245\n",
      "Episode  261 : Reward =  -543578.9457194797\n",
      "Episode  262 : Reward =  -543588.1218812458\n",
      "Episode  263 : Reward =  -546357.3206220716\n",
      "Episode  264 : Reward =  -544650.2985708768\n",
      "Episode  265 : Reward =  -546870.836711544\n",
      "Episode  266 : Reward =  -539115.6579008439\n",
      "Episode  267 : Reward =  -535768.4479032307\n",
      "Episode  268 : Reward =  -540761.3143156304\n",
      "Episode  269 : Reward =  -539111.8501249292\n",
      "Episode  270 : Reward =  -536879.1837465974\n",
      "Episode  271 : Reward =  -532415.8426360447\n",
      "Episode  272 : Reward =  -541879.6109066205\n",
      "Episode  273 : Reward =  -542991.288127925\n",
      "Episode  274 : Reward =  -542427.4872944284\n",
      "Episode  275 : Reward =  -545226.7404998329\n",
      "Episode  276 : Reward =  -544131.7424255335\n",
      "Episode  277 : Reward =  -543581.5377327196\n",
      "Episode  278 : Reward =  -540265.3416826528\n",
      "Episode  279 : Reward =  -543609.0658227793\n",
      "Episode  280 : Reward =  -543064.4596342107\n",
      "Episode  281 : Reward =  -540311.691456477\n",
      "Episode  282 : Reward =  -543642.0602595202\n",
      "Episode  283 : Reward =  -533144.3241008809\n",
      "Episode  284 : Reward =  -530367.9214163852\n",
      "Episode  285 : Reward =  -529251.9912643203\n",
      "Episode  286 : Reward =  -533146.0513753584\n",
      "Episode  287 : Reward =  -529264.8992796311\n",
      "Episode  288 : Reward =  -522048.7007174152\n",
      "Episode  289 : Reward =  -521501.4154284523\n",
      "Episode  290 : Reward =  -519263.8653027216\n",
      "Saving better model at episode 290 with reward -519263.8653027216\n",
      "Episode  291 : Reward =  -517546.74027544307\n",
      "Saving better model at episode 291 with reward -517546.74027544307\n",
      "Episode  292 : Reward =  -510311.1696114434\n",
      "Saving better model at episode 292 with reward -510311.1696114434\n",
      "Episode  293 : Reward =  -499220.2381032567\n",
      "Saving better model at episode 293 with reward -499220.2381032567\n",
      "Episode  294 : Reward =  -483137.530793234\n",
      "Saving better model at episode 294 with reward -483137.530793234\n",
      "Episode  295 : Reward =  -505372.07148449705\n",
      "Episode  296 : Reward =  -503157.1581023119\n",
      "Episode  297 : Reward =  -487084.06486699625\n",
      "Episode  298 : Reward =  -502078.02189365216\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.47\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  299 : Reward =  -485401.9797040194\n",
      "Episode  300 : Reward =  -504776.69518406957\n",
      "Episode  301 : Reward =  -481532.97418946505\n",
      "Saving better model at episode 301 with reward -481532.97418946505\n",
      "Episode  302 : Reward =  -485961.79324367654\n",
      "Episode  303 : Reward =  -493149.187811058\n",
      "Episode  304 : Reward =  -477611.5597256548\n",
      "Saving better model at episode 304 with reward -477611.5597256548\n",
      "Episode  305 : Reward =  -463184.21428417205\n",
      "Saving better model at episode 305 with reward -463184.21428417205\n",
      "Episode  306 : Reward =  -479272.3111206811\n",
      "Episode  307 : Reward =  -498112.7263949312\n",
      "Episode  308 : Reward =  -484237.34016649984\n",
      "Episode  309 : Reward =  -484800.493467891\n",
      "Episode  310 : Reward =  -485880.543509096\n",
      "Episode  311 : Reward =  -493093.78030030057\n",
      "Episode  312 : Reward =  -487550.96955616237\n",
      "Episode  313 : Reward =  -478686.4563211987\n",
      "Episode  314 : Reward =  -498109.56024233473\n",
      "Episode  315 : Reward =  -507512.75851881853\n",
      "Episode  316 : Reward =  -505272.12146734283\n",
      "Episode  317 : Reward =  -495307.9498864948\n",
      "Episode  318 : Reward =  -500849.4629329101\n",
      "Episode  319 : Reward =  -488641.4650284806\n",
      "Episode  320 : Reward =  -494183.4153087016\n",
      "Episode  321 : Reward =  -496972.9138666723\n",
      "Episode  322 : Reward =  -490305.34657316946\n",
      "Episode  323 : Reward =  -494200.85532634216\n",
      "Episode  324 : Reward =  -496958.77974179725\n",
      "Episode  325 : Reward =  -494722.37639703427\n",
      "Episode  326 : Reward =  -473650.3033234085\n",
      "Episode  327 : Reward =  -474194.29096352425\n",
      "Episode  328 : Reward =  -474778.77074250265\n",
      "Episode  329 : Reward =  -484199.9528431203\n",
      "Episode  330 : Reward =  -478636.7561820934\n",
      "Episode  331 : Reward =  -476423.6537014309\n",
      "Episode  332 : Reward =  -472548.76529087045\n",
      "Episode  333 : Reward =  -478649.23511143425\n",
      "Episode  334 : Reward =  -481408.34231514216\n",
      "Episode  335 : Reward =  -475321.13358587027\n",
      "Episode  336 : Reward =  -470315.6911221162\n",
      "Episode  337 : Reward =  -460325.293308501\n",
      "Saving better model at episode 337 with reward -460325.293308501\n",
      "Episode  338 : Reward =  -459776.7604897334\n",
      "Saving better model at episode 338 with reward -459776.7604897334\n",
      "Episode  339 : Reward =  -464765.4895595609\n",
      "Episode  340 : Reward =  -433708.3836803165\n",
      "Saving better model at episode 340 with reward -433708.3836803165\n",
      "Episode  341 : Reward =  -440914.96077482286\n",
      "Episode  342 : Reward =  -421503.38333740144\n",
      "Saving better model at episode 342 with reward -421503.38333740144\n",
      "Episode  343 : Reward =  -405955.4093884771\n",
      "Saving better model at episode 343 with reward -405955.4093884771\n",
      "Episode  344 : Reward =  -448693.36471852474\n",
      "Episode  345 : Reward =  -426490.3484834051\n",
      "Episode  346 : Reward =  -413711.68239275494\n",
      "Episode  347 : Reward =  -419278.68645555817\n",
      "Episode  348 : Reward =  -467543.4426229752\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.465\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  349 : Reward =  -449217.67556023726\n",
      "Episode  350 : Reward =  -459756.22709211847\n",
      "Episode  351 : Reward =  -441457.14938791294\n",
      "Episode  352 : Reward =  -424806.13701222546\n",
      "Episode  353 : Reward =  -445356.1418485732\n",
      "Episode  354 : Reward =  -431464.6163375577\n",
      "Episode  355 : Reward =  -435896.312150285\n",
      "Episode  356 : Reward =  -425327.70951969945\n",
      "Episode  357 : Reward =  -441979.6451651356\n",
      "Episode  358 : Reward =  -428116.12475371466\n",
      "Episode  359 : Reward =  -423130.64294481534\n",
      "Episode  360 : Reward =  -387611.8062205117\n",
      "Saving better model at episode 360 with reward -387611.8062205117\n",
      "Episode  361 : Reward =  -414798.6465648265\n",
      "Episode  362 : Reward =  -408150.97286880726\n",
      "Episode  363 : Reward =  -398728.4683977796\n",
      "Episode  364 : Reward =  -412615.9491447533\n",
      "Episode  365 : Reward =  -400972.4807277878\n",
      "Episode  366 : Reward =  -419280.7184183701\n",
      "Episode  367 : Reward =  -403731.33104668243\n",
      "Episode  368 : Reward =  -388756.87638907274\n",
      "Episode  369 : Reward =  -414832.89061795187\n",
      "Episode  370 : Reward =  -413721.0117878703\n",
      "Episode  371 : Reward =  -394871.4518241795\n",
      "Episode  372 : Reward =  -394314.66147555714\n",
      "Episode  373 : Reward =  -397630.2213857542\n",
      "Episode  374 : Reward =  -377667.52536241524\n",
      "Saving better model at episode 374 with reward -377667.52536241524\n",
      "Episode  375 : Reward =  -383195.1579737214\n",
      "Episode  376 : Reward =  -389316.3384893135\n",
      "Episode  377 : Reward =  -414281.01090641017\n",
      "Episode  378 : Reward =  -389289.0799417094\n",
      "Episode  379 : Reward =  -387127.37142712565\n",
      "Episode  380 : Reward =  -387129.36119807453\n",
      "Episode  381 : Reward =  -444239.58022755664\n",
      "Episode  382 : Reward =  -432620.3845902347\n",
      "Episode  383 : Reward =  -452630.43425871956\n",
      "Episode  384 : Reward =  -457631.8258158751\n",
      "Episode  385 : Reward =  -443855.21532103384\n",
      "Episode  386 : Reward =  -437773.7767235884\n",
      "Episode  387 : Reward =  -404539.2877013237\n",
      "Episode  388 : Reward =  -427820.23012235557\n",
      "Episode  389 : Reward =  -444388.44209873956\n",
      "Episode  390 : Reward =  -472124.5561830213\n",
      "Episode  391 : Reward =  -447160.2773281819\n",
      "Episode  392 : Reward =  -452162.8963564506\n",
      "Episode  393 : Reward =  -446599.59435053216\n",
      "Episode  394 : Reward =  -473188.4739915007\n",
      "Episode  395 : Reward =  -455406.42455453286\n",
      "Episode  396 : Reward =  -453754.76666876336\n",
      "Episode  397 : Reward =  -457069.1350086188\n",
      "Episode  398 : Reward =  -453173.5513305003\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.46\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  399 : Reward =  -453182.3957109386\n",
      "Episode  400 : Reward =  -434270.36630267487\n",
      "Episode  401 : Reward =  -447042.4429998881\n",
      "Episode  402 : Reward =  -412596.896740588\n",
      "Episode  403 : Reward =  -444773.7115003824\n",
      "Episode  404 : Reward =  -429235.9838610365\n",
      "Episode  405 : Reward =  -450879.1453153896\n",
      "Episode  406 : Reward =  -366656.84771356964\n",
      "Saving better model at episode 406 with reward -366656.84771356964\n",
      "Episode  407 : Reward =  -378295.9439216418\n",
      "Episode  408 : Reward =  -351673.406388625\n",
      "Saving better model at episode 408 with reward -351673.406388625\n",
      "Episode  409 : Reward =  -392156.1769076043\n",
      "Episode  410 : Reward =  -377293.5892962913\n",
      "Episode  411 : Reward =  -366788.6561569372\n",
      "Episode  412 : Reward =  -375102.5547528241\n",
      "Episode  413 : Reward =  -414512.99990381004\n",
      "Episode  414 : Reward =  -417772.388862879\n",
      "Episode  415 : Reward =  -416669.61273100437\n",
      "Episode  416 : Reward =  -431553.0462898811\n",
      "Episode  417 : Reward =  -442079.86317627644\n",
      "Episode  418 : Reward =  -395938.3908543562\n",
      "Episode  419 : Reward =  -419248.02003569447\n",
      "Episode  420 : Reward =  -125338.75308395851\n",
      "Saving better model at episode 420 with reward -125338.75308395851\n",
      "Episode  421 : Reward =  -209010.05416373193\n",
      "Episode  422 : Reward =  -109336.33653788378\n",
      "Saving better model at episode 422 with reward -109336.33653788378\n",
      "Episode  423 : Reward =  -116526.71768700783\n",
      "Episode  424 : Reward =  -108275.14763806244\n",
      "Saving better model at episode 424 with reward -108275.14763806244\n",
      "Episode  425 : Reward =  -104890.6904865711\n",
      "Saving better model at episode 425 with reward -104890.6904865711\n",
      "Episode  426 : Reward =  -93811.50017960659\n",
      "Saving better model at episode 426 with reward -93811.50017960659\n",
      "Episode  427 : Reward =  -92717.73136545382\n",
      "Saving better model at episode 427 with reward -92717.73136545382\n",
      "Episode  428 : Reward =  -117072.308455378\n",
      "Episode  429 : Reward =  -87233.27052466087\n",
      "Saving better model at episode 429 with reward -87233.27052466087\n",
      "Episode  430 : Reward =  -82221.12066815475\n",
      "Saving better model at episode 430 with reward -82221.12066815475\n",
      "Episode  431 : Reward =  -126502.45247673366\n",
      "Episode  432 : Reward =  -98210.3712653946\n",
      "Episode  433 : Reward =  -121493.31019693155\n",
      "Episode  434 : Reward =  -94923.68424930594\n",
      "Episode  435 : Reward =  -105322.87760173684\n",
      "Episode  436 : Reward =  -105927.17426380237\n",
      "Episode  437 : Reward =  -85959.06361094497\n",
      "Episode  438 : Reward =  -107574.8068562216\n",
      "Episode  439 : Reward =  -99359.68387781522\n",
      "Episode  440 : Reward =  -95400.02416592574\n",
      "Episode  441 : Reward =  -108171.42185215135\n",
      "Episode  442 : Reward =  -110925.49381956016\n",
      "Episode  443 : Reward =  -103250.62940416878\n",
      "Episode  444 : Reward =  -98774.54203249639\n",
      "Episode  445 : Reward =  -103772.21125085614\n",
      "Episode  446 : Reward =  -84451.9011117164\n",
      "Episode  447 : Reward =  -117605.59076315496\n",
      "Episode  448 : Reward =  -100569.26997112801\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.455\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  449 : Reward =  -78302.62062292272\n",
      "Saving better model at episode 449 with reward -78302.62062292272\n",
      "Episode  450 : Reward =  -93292.60617308295\n",
      "Episode  451 : Reward =  -79453.7768385967\n",
      "Episode  452 : Reward =  -87256.85341409854\n",
      "Episode  453 : Reward =  -93276.66529796994\n",
      "Episode  454 : Reward =  -98789.19045759863\n",
      "Episode  455 : Reward =  -102671.37259466281\n",
      "Episode  456 : Reward =  -102681.91462368598\n",
      "Episode  457 : Reward =  -100526.30643152764\n",
      "Episode  458 : Reward =  -78275.44919650728\n",
      "Saving better model at episode 458 with reward -78275.44919650728\n",
      "Episode  459 : Reward =  -93884.11073418253\n",
      "Episode  460 : Reward =  -81092.20609704204\n",
      "Episode  461 : Reward =  -77711.69073076705\n",
      "Saving better model at episode 461 with reward -77711.69073076705\n",
      "Episode  462 : Reward =  -81628.42101068163\n",
      "Episode  463 : Reward =  -89431.00551878683\n",
      "Episode  464 : Reward =  -101609.04330146512\n",
      "Episode  465 : Reward =  -84957.8031469857\n",
      "Episode  466 : Reward =  -100461.17479848435\n",
      "Episode  467 : Reward =  -95547.71949904895\n",
      "Episode  468 : Reward =  -88829.53690447367\n",
      "Episode  469 : Reward =  -119794.2339780489\n",
      "Episode  470 : Reward =  -124715.8025048517\n",
      "Episode  471 : Reward =  -117527.18181073997\n",
      "Episode  472 : Reward =  -132458.55131119324\n",
      "Episode  473 : Reward =  -114223.72398041133\n",
      "Episode  474 : Reward =  -115893.63921674479\n",
      "Episode  475 : Reward =  -121463.06032287616\n",
      "Episode  476 : Reward =  -108207.99077955862\n",
      "Episode  477 : Reward =  -113143.90267143463\n",
      "Episode  478 : Reward =  -150325.45165941978\n",
      "Episode  479 : Reward =  -161366.28213511044\n",
      "Episode  480 : Reward =  -120319.45308249105\n",
      "Episode  481 : Reward =  -140850.08878870343\n",
      "Episode  482 : Reward =  -111982.89420691316\n",
      "Episode  483 : Reward =  -115334.03614275728\n",
      "Episode  484 : Reward =  -119177.25974021632\n",
      "Episode  485 : Reward =  -108154.35807887693\n",
      "Episode  486 : Reward =  -119216.6044627257\n",
      "Episode  487 : Reward =  -98185.03748081437\n",
      "Episode  488 : Reward =  -119235.3084038325\n",
      "Episode  489 : Reward =  -119251.2475746699\n",
      "Episode  490 : Reward =  -123117.14988026503\n",
      "Episode  491 : Reward =  -122579.09504604507\n",
      "Episode  492 : Reward =  -133663.79696059684\n",
      "Episode  493 : Reward =  -125395.48383234683\n",
      "Episode  494 : Reward =  -125442.9483471984\n",
      "Episode  495 : Reward =  -140433.77099691055\n",
      "Episode  496 : Reward =  -158765.8810816364\n",
      "Episode  497 : Reward =  -142673.69044184164\n",
      "Episode  498 : Reward =  -87351.12926969938\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.45\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  499 : Reward =  -112739.27201509972\n",
      "Episode  500 : Reward =  -111059.152888085\n",
      "Episode  501 : Reward =  -130470.95947061556\n",
      "Episode  502 : Reward =  -89449.13601892463\n",
      "Episode  503 : Reward =  -118787.20122689966\n",
      "Episode  504 : Reward =  -106646.42184257542\n",
      "Episode  505 : Reward =  -102150.38126406586\n",
      "Episode  506 : Reward =  -101109.55872055775\n",
      "Episode  507 : Reward =  -114366.06663010959\n",
      "Episode  508 : Reward =  -124339.55631111178\n",
      "Episode  509 : Reward =  -120484.86400352824\n",
      "Episode  510 : Reward =  -109325.80666785051\n",
      "Episode  511 : Reward =  -116467.59427874986\n",
      "Episode  512 : Reward =  -115444.26555030618\n",
      "Episode  513 : Reward =  -113180.79130557989\n",
      "Episode  514 : Reward =  -101509.96240920028\n",
      "Episode  515 : Reward =  -129141.80767754662\n",
      "Episode  516 : Reward =  -94961.92561295054\n",
      "Episode  517 : Reward =  -95469.46126073337\n",
      "Episode  518 : Reward =  -116449.02118950788\n",
      "Episode  519 : Reward =  -110989.64597984706\n",
      "Episode  520 : Reward =  -126997.28957339811\n",
      "Episode  521 : Reward =  -90986.88875362492\n",
      "Episode  522 : Reward =  -102043.91177049791\n",
      "Episode  523 : Reward =  -115339.61427246605\n",
      "Episode  524 : Reward =  -110934.41855081473\n",
      "Episode  525 : Reward =  -108168.6323115029\n",
      "Episode  526 : Reward =  -96569.65266466505\n",
      "Episode  527 : Reward =  -108734.48165507411\n",
      "Episode  528 : Reward =  -119291.94502989728\n",
      "Episode  529 : Reward =  -88327.77831708036\n",
      "Episode  530 : Reward =  -109963.54920109038\n",
      "Episode  531 : Reward =  -100517.37034374049\n",
      "Episode  532 : Reward =  -88897.25565369881\n",
      "Episode  533 : Reward =  -116559.08493613903\n",
      "Episode  534 : Reward =  -103835.093114629\n",
      "Episode  535 : Reward =  -62134.52869714828\n",
      "Saving better model at episode 535 with reward -62134.52869714828\n",
      "Episode  536 : Reward =  -63251.27873345375\n",
      "Episode  537 : Reward =  -57789.66521351554\n",
      "Saving better model at episode 537 with reward -57789.66521351554\n",
      "Episode  538 : Reward =  -59553.94715735277\n",
      "Episode  539 : Reward =  -59671.843328776704\n",
      "Episode  540 : Reward =  -54483.6271874353\n",
      "Saving better model at episode 540 with reward -54483.6271874353\n",
      "Episode  541 : Reward =  -65705.18863291274\n",
      "Episode  542 : Reward =  -57292.138210286874\n",
      "Episode  543 : Reward =  -60666.893774578006\n",
      "Episode  544 : Reward =  -55638.686080526066\n",
      "Episode  545 : Reward =  -55063.48321978014\n",
      "Episode  546 : Reward =  -52882.444942141614\n",
      "Saving better model at episode 546 with reward -52882.444942141614\n",
      "Episode  547 : Reward =  -61760.46232874723\n",
      "Episode  548 : Reward =  -59050.33594134411\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.445\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  549 : Reward =  -55191.116507329156\n",
      "Episode  550 : Reward =  -58578.75048130399\n",
      "Episode  551 : Reward =  -52827.11438032492\n",
      "Saving better model at episode 551 with reward -52827.11438032492\n",
      "Episode  552 : Reward =  -51136.95524571897\n",
      "Saving better model at episode 552 with reward -51136.95524571897\n",
      "Episode  553 : Reward =  -57377.47491817691\n",
      "Episode  554 : Reward =  -59608.05456072365\n",
      "Episode  555 : Reward =  -68473.66642331387\n",
      "Episode  556 : Reward =  -56779.82375683093\n",
      "Episode  557 : Reward =  -57849.49046888284\n",
      "Episode  558 : Reward =  -62265.89866654918\n",
      "Episode  559 : Reward =  -61212.3226404609\n",
      "Episode  560 : Reward =  -54545.210693244604\n",
      "Episode  561 : Reward =  -59603.641830208646\n",
      "Episode  562 : Reward =  -58509.02536189205\n",
      "Episode  563 : Reward =  -54560.18818819967\n",
      "Episode  564 : Reward =  -60198.547040617355\n",
      "Episode  565 : Reward =  -53037.68255528315\n",
      "Episode  566 : Reward =  -55816.78848565693\n",
      "Episode  567 : Reward =  -57417.47766398408\n",
      "Episode  568 : Reward =  -51882.16731746868\n",
      "Episode  569 : Reward =  -60176.16071549643\n",
      "Episode  570 : Reward =  -54045.91137400401\n",
      "Episode  571 : Reward =  -57503.856415798444\n",
      "Episode  572 : Reward =  -58445.44541185743\n",
      "Episode  573 : Reward =  -59046.05730214676\n",
      "Episode  574 : Reward =  -56880.46715291047\n",
      "Episode  575 : Reward =  -50788.981387508386\n",
      "Saving better model at episode 575 with reward -50788.981387508386\n",
      "Episode  576 : Reward =  -59525.629819515096\n",
      "Episode  577 : Reward =  -52308.70434974819\n",
      "Episode  578 : Reward =  -49503.16669411082\n",
      "Saving better model at episode 578 with reward -49503.16669411082\n",
      "Episode  579 : Reward =  -47257.48788314424\n",
      "Saving better model at episode 579 with reward -47257.48788314424\n",
      "Episode  580 : Reward =  -56587.721314506765\n",
      "Episode  581 : Reward =  -52607.64926883086\n",
      "Episode  582 : Reward =  -48841.69654438202\n",
      "Episode  583 : Reward =  -55536.905501674366\n",
      "Episode  584 : Reward =  -49907.160079220266\n",
      "Episode  585 : Reward =  -54962.252102710416\n",
      "Episode  586 : Reward =  -53755.651193292266\n",
      "Episode  587 : Reward =  -57759.980530225555\n",
      "Episode  588 : Reward =  -57141.159568002004\n",
      "Episode  589 : Reward =  -56547.62356730008\n",
      "Episode  590 : Reward =  -53914.44178322089\n",
      "Episode  591 : Reward =  -52172.94544254929\n",
      "Episode  592 : Reward =  -54161.09677800668\n",
      "Episode  593 : Reward =  -51292.25688247444\n",
      "Episode  594 : Reward =  -55369.49301920097\n",
      "Episode  595 : Reward =  -48340.701827254656\n",
      "Episode  596 : Reward =  -42074.24444874346\n",
      "Saving better model at episode 596 with reward -42074.24444874346\n",
      "Episode  597 : Reward =  -45352.31017987038\n",
      "Episode  598 : Reward =  -46588.708360778626\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.44\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  599 : Reward =  -48791.61779975882\n",
      "Episode  600 : Reward =  -51896.22758950666\n",
      "Episode  601 : Reward =  -49110.76812687819\n",
      "Episode  602 : Reward =  -44684.84585929703\n",
      "Episode  603 : Reward =  -48029.858904447916\n",
      "Episode  604 : Reward =  -56406.15657220671\n",
      "Episode  605 : Reward =  -50785.329942417615\n",
      "Episode  606 : Reward =  -48094.708733883264\n",
      "Episode  607 : Reward =  -46979.17959161647\n",
      "Episode  608 : Reward =  -44812.126320191135\n",
      "Episode  609 : Reward =  -51909.69740023092\n",
      "Episode  610 : Reward =  -46899.224937161285\n",
      "Episode  611 : Reward =  -47502.038332336764\n",
      "Episode  612 : Reward =  -50277.9784647021\n",
      "Episode  613 : Reward =  -44355.41419783708\n",
      "Episode  614 : Reward =  -48731.26886290302\n",
      "Episode  615 : Reward =  -51955.93372233585\n",
      "Episode  616 : Reward =  -49633.15944666285\n",
      "Episode  617 : Reward =  -53054.03118761881\n",
      "Episode  618 : Reward =  -59122.417914062346\n",
      "Episode  619 : Reward =  -51822.22694154457\n",
      "Episode  620 : Reward =  -50081.198458770246\n",
      "Episode  621 : Reward =  -51376.14015327455\n",
      "Episode  622 : Reward =  -56345.95668898413\n",
      "Episode  623 : Reward =  -50877.128263009065\n",
      "Episode  624 : Reward =  -54201.29513111842\n",
      "Episode  625 : Reward =  -46850.49409480937\n",
      "Episode  626 : Reward =  -48432.735560715104\n",
      "Episode  627 : Reward =  -60213.751593625435\n",
      "Episode  628 : Reward =  -51156.569818124786\n",
      "Episode  629 : Reward =  -48919.911609291936\n",
      "Episode  630 : Reward =  -55614.64761850994\n",
      "Episode  631 : Reward =  -57114.19685031676\n",
      "Episode  632 : Reward =  -53831.52418327151\n",
      "Episode  633 : Reward =  -55521.31095383327\n",
      "Episode  634 : Reward =  -59957.38893187319\n",
      "Episode  635 : Reward =  -62796.357367623306\n",
      "Episode  636 : Reward =  -56116.36739255066\n",
      "Episode  637 : Reward =  -60640.90899053801\n",
      "Episode  638 : Reward =  -60692.494249915966\n",
      "Episode  639 : Reward =  -55699.01064620178\n",
      "Episode  640 : Reward =  -58486.063380443375\n",
      "Episode  641 : Reward =  -56234.26279921408\n",
      "Episode  642 : Reward =  -52252.21759249643\n",
      "Episode  643 : Reward =  -57288.76914407515\n",
      "Episode  644 : Reward =  -52735.637389771044\n",
      "Episode  645 : Reward =  -56220.864445399\n",
      "Episode  646 : Reward =  -53384.20801558598\n",
      "Episode  647 : Reward =  -48250.065562096\n",
      "Episode  648 : Reward =  -52747.912097326815\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.435\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  649 : Reward =  -53480.46220662697\n",
      "Episode  650 : Reward =  -52233.183352906264\n",
      "Episode  651 : Reward =  -49493.94444635813\n",
      "Episode  652 : Reward =  -52873.13254003912\n",
      "Episode  653 : Reward =  -47850.57914208732\n",
      "Episode  654 : Reward =  -50662.500480273695\n",
      "Episode  655 : Reward =  -57956.48500006415\n",
      "Episode  656 : Reward =  -50609.99235651824\n",
      "Episode  657 : Reward =  -56304.08988643761\n",
      "Episode  658 : Reward =  -47640.570256942134\n",
      "Episode  659 : Reward =  -46530.78527330094\n",
      "Episode  660 : Reward =  -51571.232209668175\n",
      "Episode  661 : Reward =  -44860.69521117996\n",
      "Episode  662 : Reward =  -47127.875736495334\n",
      "Episode  663 : Reward =  -50427.93412772748\n",
      "Episode  664 : Reward =  -50953.54431076097\n",
      "Episode  665 : Reward =  -43657.32494384212\n",
      "Episode  666 : Reward =  -50358.09981481168\n",
      "Episode  667 : Reward =  -48586.97797679892\n",
      "Episode  668 : Reward =  -52649.301866404116\n",
      "Episode  669 : Reward =  -45223.57605437542\n",
      "Episode  670 : Reward =  -47585.03372424207\n",
      "Episode  671 : Reward =  -50351.18597523305\n",
      "Episode  672 : Reward =  -51979.07040949539\n",
      "Episode  673 : Reward =  -52557.34744720846\n",
      "Episode  674 : Reward =  -50240.027964035005\n",
      "Episode  675 : Reward =  -49043.688088092254\n",
      "Episode  676 : Reward =  -51226.30398486616\n",
      "Episode  677 : Reward =  -47407.21020536981\n",
      "Episode  678 : Reward =  -48105.638460543516\n",
      "Episode  679 : Reward =  -47545.580541544776\n",
      "Episode  680 : Reward =  -48167.02023556507\n",
      "Episode  681 : Reward =  -47676.9050826963\n",
      "Episode  682 : Reward =  -42484.58073985114\n",
      "Episode  683 : Reward =  -43094.150666145964\n",
      "Episode  684 : Reward =  -40979.031692163066\n",
      "Saving better model at episode 684 with reward -40979.031692163066\n",
      "Episode  685 : Reward =  -42686.18081759944\n",
      "Episode  686 : Reward =  -46014.53022862891\n",
      "Episode  687 : Reward =  -50526.01720497939\n",
      "Episode  688 : Reward =  -50046.27924556155\n",
      "Episode  689 : Reward =  -43012.06144699304\n",
      "Episode  690 : Reward =  -46470.930584298905\n",
      "Episode  691 : Reward =  -44143.73601374504\n",
      "Episode  692 : Reward =  -49805.79450494666\n",
      "Episode  693 : Reward =  -46462.360964106854\n",
      "Episode  694 : Reward =  -43122.605570285006\n",
      "Episode  695 : Reward =  -48373.017911281946\n",
      "Episode  696 : Reward =  -47837.30097215734\n",
      "Episode  697 : Reward =  -49463.62612417643\n",
      "Episode  698 : Reward =  -51126.81569482135\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.43\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  699 : Reward =  -49384.27438000147\n",
      "Episode  700 : Reward =  -50480.03825126025\n",
      "Episode  701 : Reward =  -52327.42910226063\n",
      "Episode  702 : Reward =  -44484.8566964018\n",
      "Episode  703 : Reward =  -52205.481545943774\n",
      "Episode  704 : Reward =  -51118.150268149846\n",
      "Episode  705 : Reward =  -50001.52956110854\n",
      "Episode  706 : Reward =  -46598.69743143254\n",
      "Episode  707 : Reward =  -45333.32823414396\n",
      "Episode  708 : Reward =  -46344.98135866145\n",
      "Episode  709 : Reward =  -47641.502672665934\n",
      "Episode  710 : Reward =  -50380.843396523924\n",
      "Episode  711 : Reward =  -43299.92279025762\n",
      "Episode  712 : Reward =  -46655.08321736985\n",
      "Episode  713 : Reward =  -45766.24807743336\n",
      "Episode  714 : Reward =  -43618.1509579107\n",
      "Episode  715 : Reward =  -41735.44137711914\n",
      "Episode  716 : Reward =  -42645.081006847024\n",
      "Episode  717 : Reward =  -47618.74605019935\n",
      "Episode  718 : Reward =  -36116.45147882352\n",
      "Saving better model at episode 718 with reward -36116.45147882352\n",
      "Episode  719 : Reward =  -38588.995134383644\n",
      "Episode  720 : Reward =  -43645.646772472544\n",
      "Episode  721 : Reward =  -37621.20737972252\n",
      "Episode  722 : Reward =  -40902.49714682775\n",
      "Episode  723 : Reward =  -41488.3145685354\n",
      "Episode  724 : Reward =  -42820.476820490956\n",
      "Episode  725 : Reward =  -44496.19367176456\n",
      "Episode  726 : Reward =  -41839.969346419886\n",
      "Episode  727 : Reward =  -42242.19277335794\n",
      "Episode  728 : Reward =  -45299.9288195121\n",
      "Episode  729 : Reward =  -48414.73644589744\n",
      "Episode  730 : Reward =  -47286.17432140046\n",
      "Episode  731 : Reward =  -41177.93363265472\n",
      "Episode  732 : Reward =  -42232.82464288578\n",
      "Episode  733 : Reward =  -52774.740368623294\n",
      "Episode  734 : Reward =  -49946.115267071174\n",
      "Episode  735 : Reward =  -48398.75927024446\n",
      "Episode  736 : Reward =  -53208.41539960295\n",
      "Episode  737 : Reward =  -48308.92248361669\n",
      "Episode  738 : Reward =  -47889.90403916486\n",
      "Episode  739 : Reward =  -47802.075301727135\n",
      "Episode  740 : Reward =  -50797.79296592805\n",
      "Episode  741 : Reward =  -49822.76312330668\n",
      "Episode  742 : Reward =  -52654.59424646572\n",
      "Episode  743 : Reward =  -50497.99618477244\n",
      "Episode  744 : Reward =  -48697.69732680595\n",
      "Episode  745 : Reward =  -49302.13978236904\n",
      "Episode  746 : Reward =  -51160.57608989808\n",
      "Episode  747 : Reward =  -46109.866741280806\n",
      "Episode  748 : Reward =  -53910.12747665747\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.425\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  749 : Reward =  -49821.15080789034\n",
      "Episode  750 : Reward =  -47872.113423487026\n",
      "Episode  751 : Reward =  -51640.75101722526\n",
      "Episode  752 : Reward =  -49947.47050783341\n",
      "Episode  753 : Reward =  -46642.267610921655\n",
      "Episode  754 : Reward =  -43640.25491610019\n",
      "Episode  755 : Reward =  -50945.896867493124\n",
      "Episode  756 : Reward =  -50518.74182779212\n",
      "Episode  757 : Reward =  -47186.611525284585\n",
      "Episode  758 : Reward =  -46536.42788757304\n",
      "Episode  759 : Reward =  -49437.70953774443\n",
      "Episode  760 : Reward =  -48447.54846184812\n",
      "Episode  761 : Reward =  -56846.94158036585\n",
      "Episode  762 : Reward =  -45983.969981916656\n",
      "Episode  763 : Reward =  -48761.321063631396\n",
      "Episode  764 : Reward =  -50673.61071164031\n",
      "Episode  765 : Reward =  -50772.67937571425\n",
      "Episode  766 : Reward =  -49788.28907054029\n",
      "Episode  767 : Reward =  -44780.43355986325\n",
      "Episode  768 : Reward =  -43921.19594302623\n",
      "Episode  769 : Reward =  -46796.17664475659\n",
      "Episode  770 : Reward =  -47659.65198930152\n",
      "Episode  771 : Reward =  -44711.801362039274\n",
      "Episode  772 : Reward =  -44946.01152205629\n",
      "Episode  773 : Reward =  -40939.78623968695\n",
      "Episode  774 : Reward =  -47561.94100151564\n",
      "Episode  775 : Reward =  -38903.91815748207\n",
      "Episode  776 : Reward =  -39735.43429783007\n",
      "Episode  777 : Reward =  -41815.43964321378\n",
      "Episode  778 : Reward =  -41221.67771235753\n",
      "Episode  779 : Reward =  -38509.010559251685\n",
      "Episode  780 : Reward =  -44410.86659973397\n",
      "Episode  781 : Reward =  -40528.377949956404\n",
      "Episode  782 : Reward =  -44194.711524481914\n",
      "Episode  783 : Reward =  -43016.78312789307\n",
      "Episode  784 : Reward =  -47368.625991027606\n",
      "Episode  785 : Reward =  -47491.53220497304\n",
      "Episode  786 : Reward =  -42970.29743971646\n",
      "Episode  787 : Reward =  -41315.5366501637\n",
      "Episode  788 : Reward =  -42338.36401860819\n",
      "Episode  789 : Reward =  -43047.21488134966\n",
      "Episode  790 : Reward =  -44671.331014396375\n",
      "Episode  791 : Reward =  -48991.89789723716\n",
      "Episode  792 : Reward =  -43784.7349274379\n",
      "Episode  793 : Reward =  -47137.24872795845\n",
      "Episode  794 : Reward =  -43906.8832597357\n",
      "Episode  795 : Reward =  -44578.61221784515\n",
      "Episode  796 : Reward =  -43656.477796278596\n",
      "Episode  797 : Reward =  -43430.04892554104\n",
      "Episode  798 : Reward =  -39981.27920016667\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.42\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  799 : Reward =  -43811.068924860076\n",
      "Episode  800 : Reward =  -34594.754653466814\n",
      "Saving better model at episode 800 with reward -34594.754653466814\n",
      "Episode  801 : Reward =  -42257.90817678307\n",
      "Episode  802 : Reward =  -37738.85651964453\n",
      "Episode  803 : Reward =  -34057.25105441291\n",
      "Saving better model at episode 803 with reward -34057.25105441291\n",
      "Episode  804 : Reward =  -33690.66151824956\n",
      "Saving better model at episode 804 with reward -33690.66151824956\n",
      "Episode  805 : Reward =  -28869.631277715533\n",
      "Saving better model at episode 805 with reward -28869.631277715533\n",
      "Episode  806 : Reward =  -35081.30223358976\n",
      "Episode  807 : Reward =  -29578.605547648323\n",
      "Episode  808 : Reward =  -32283.83249127915\n",
      "Episode  809 : Reward =  -26247.81755843043\n",
      "Saving better model at episode 809 with reward -26247.81755843043\n",
      "Episode  810 : Reward =  -28553.360857673993\n",
      "Episode  811 : Reward =  -21219.346296480675\n",
      "Saving better model at episode 811 with reward -21219.346296480675\n",
      "Episode  812 : Reward =  -19697.23690284486\n",
      "Saving better model at episode 812 with reward -19697.23690284486\n",
      "Episode  813 : Reward =  -35153.23075826899\n",
      "Episode  814 : Reward =  -22796.623502735245\n",
      "Episode  815 : Reward =  -24399.836717291048\n",
      "Episode  816 : Reward =  -19863.175574082372\n",
      "Episode  817 : Reward =  -26457.49473002462\n",
      "Episode  818 : Reward =  -19935.65072013135\n",
      "Episode  819 : Reward =  -19832.719966635203\n",
      "Episode  820 : Reward =  -19557.32026512618\n",
      "Saving better model at episode 820 with reward -19557.32026512618\n",
      "Episode  821 : Reward =  -19016.513784891038\n",
      "Saving better model at episode 821 with reward -19016.513784891038\n",
      "Episode  822 : Reward =  -20186.786469623537\n",
      "Episode  823 : Reward =  -18964.357184150627\n",
      "Saving better model at episode 823 with reward -18964.357184150627\n",
      "Episode  824 : Reward =  -26232.100125991106\n",
      "Episode  825 : Reward =  -20054.591884479018\n",
      "Episode  826 : Reward =  -19426.23149410765\n",
      "Episode  827 : Reward =  -19708.148685109565\n",
      "Episode  828 : Reward =  -17730.18478596149\n",
      "Saving better model at episode 828 with reward -17730.18478596149\n",
      "Episode  829 : Reward =  -18883.372759884267\n",
      "Episode  830 : Reward =  -19185.756535926274\n",
      "Episode  831 : Reward =  -17687.07895052372\n",
      "Saving better model at episode 831 with reward -17687.07895052372\n",
      "Episode  832 : Reward =  -17149.713827278454\n",
      "Saving better model at episode 832 with reward -17149.713827278454\n",
      "Episode  833 : Reward =  -20851.63132320354\n",
      "Episode  834 : Reward =  -20824.262318059897\n",
      "Episode  835 : Reward =  -20612.69924874301\n",
      "Episode  836 : Reward =  -23600.33763465365\n",
      "Episode  837 : Reward =  -23874.458884421932\n",
      "Episode  838 : Reward =  -26112.90176613779\n",
      "Episode  839 : Reward =  -20956.264395818205\n",
      "Episode  840 : Reward =  -19793.053699439435\n",
      "Episode  841 : Reward =  -20233.206201651505\n",
      "Episode  842 : Reward =  -19256.157236608393\n",
      "Episode  843 : Reward =  -20740.26876554768\n",
      "Episode  844 : Reward =  -22880.543585119307\n",
      "Episode  845 : Reward =  -22072.673608148612\n",
      "Episode  846 : Reward =  -19630.65041769114\n",
      "Episode  847 : Reward =  -19333.98924908293\n",
      "Episode  848 : Reward =  -19475.74704751623\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.415\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  849 : Reward =  -19778.51544714537\n",
      "Episode  850 : Reward =  -19374.69323558178\n",
      "Episode  851 : Reward =  -18726.46544688879\n",
      "Episode  852 : Reward =  -19247.12334186402\n",
      "Episode  853 : Reward =  -19115.064553054697\n",
      "Episode  854 : Reward =  -18512.194086994965\n",
      "Episode  855 : Reward =  -19471.01588514698\n",
      "Episode  856 : Reward =  -19526.55291071785\n",
      "Episode  857 : Reward =  -20262.95545003693\n",
      "Episode  858 : Reward =  -18497.235248565063\n",
      "Episode  859 : Reward =  -17096.089392681875\n",
      "Saving better model at episode 859 with reward -17096.089392681875\n",
      "Episode  860 : Reward =  -18728.114235519748\n",
      "Episode  861 : Reward =  -18906.884029805045\n",
      "Episode  862 : Reward =  -17219.710470013917\n",
      "Episode  863 : Reward =  -17327.658045430933\n",
      "Episode  864 : Reward =  -19358.529257866267\n",
      "Episode  865 : Reward =  -16853.784884413042\n",
      "Saving better model at episode 865 with reward -16853.784884413042\n",
      "Episode  866 : Reward =  -17093.000840326105\n",
      "Episode  867 : Reward =  -18014.414015319187\n",
      "Episode  868 : Reward =  -18234.579290714108\n",
      "Episode  869 : Reward =  -17915.76279601081\n",
      "Episode  870 : Reward =  -17314.262280934152\n",
      "Episode  871 : Reward =  -18481.07869535623\n",
      "Episode  872 : Reward =  -17276.041009717283\n",
      "Episode  873 : Reward =  -16718.05666818217\n",
      "Saving better model at episode 873 with reward -16718.05666818217\n",
      "Episode  874 : Reward =  -17970.37912895902\n",
      "Episode  875 : Reward =  -16074.52751068951\n",
      "Saving better model at episode 875 with reward -16074.52751068951\n",
      "Episode  876 : Reward =  -17099.83424186021\n",
      "Episode  877 : Reward =  -17959.13143023475\n",
      "Episode  878 : Reward =  -14747.461383648106\n",
      "Saving better model at episode 878 with reward -14747.461383648106\n",
      "Episode  879 : Reward =  -15212.115741233556\n",
      "Episode  880 : Reward =  -16024.971116231694\n",
      "Episode  881 : Reward =  -17536.69264623149\n",
      "Episode  882 : Reward =  -15116.569449438324\n",
      "Episode  883 : Reward =  -15039.16144914793\n",
      "Episode  884 : Reward =  -14862.808278302877\n",
      "Episode  885 : Reward =  -14656.24998296041\n",
      "Saving better model at episode 885 with reward -14656.24998296041\n",
      "Episode  886 : Reward =  -16197.831427593983\n",
      "Episode  887 : Reward =  -14793.802419285505\n",
      "Episode  888 : Reward =  -13785.098326869196\n",
      "Saving better model at episode 888 with reward -13785.098326869196\n",
      "Episode  889 : Reward =  -16500.52575128585\n",
      "Episode  890 : Reward =  -14576.208578236288\n",
      "Episode  891 : Reward =  -15064.166777922384\n",
      "Episode  892 : Reward =  -14646.575878958432\n",
      "Episode  893 : Reward =  -15536.613107873669\n",
      "Episode  894 : Reward =  -14612.00173960182\n",
      "Episode  895 : Reward =  -14499.488535802095\n",
      "Episode  896 : Reward =  -16124.8545842965\n",
      "Episode  897 : Reward =  -15168.67841566967\n",
      "Episode  898 : Reward =  -15109.29567105936\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.41\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  899 : Reward =  -13317.269691560909\n",
      "Saving better model at episode 899 with reward -13317.269691560909\n",
      "Episode  900 : Reward =  -14485.101084689826\n",
      "Episode  901 : Reward =  -14725.550178150861\n",
      "Episode  902 : Reward =  -13401.080442191267\n",
      "Episode  903 : Reward =  -13862.496831066794\n",
      "Episode  904 : Reward =  -13698.940102644152\n",
      "Episode  905 : Reward =  -12737.929262818001\n",
      "Saving better model at episode 905 with reward -12737.929262818001\n",
      "Episode  906 : Reward =  -13371.6741435868\n",
      "Episode  907 : Reward =  -12730.474775732659\n",
      "Saving better model at episode 907 with reward -12730.474775732659\n",
      "Episode  908 : Reward =  -15132.42575032877\n",
      "Episode  909 : Reward =  -14098.16912178251\n",
      "Episode  910 : Reward =  -14180.739318291871\n",
      "Episode  911 : Reward =  -12960.002708555363\n",
      "Episode  912 : Reward =  -13500.429019875712\n",
      "Episode  913 : Reward =  -11896.396459666848\n",
      "Saving better model at episode 913 with reward -11896.396459666848\n",
      "Episode  914 : Reward =  -12402.268819690848\n",
      "Episode  915 : Reward =  -12314.858408869408\n",
      "Episode  916 : Reward =  -11145.343816036799\n",
      "Saving better model at episode 916 with reward -11145.343816036799\n",
      "Episode  917 : Reward =  -14171.426756806559\n",
      "Episode  918 : Reward =  -13726.443552945302\n",
      "Episode  919 : Reward =  -14325.257683794229\n",
      "Episode  920 : Reward =  -13977.499039571016\n",
      "Episode  921 : Reward =  -12317.47258916919\n",
      "Episode  922 : Reward =  -13651.779494027822\n",
      "Episode  923 : Reward =  -15194.850933836713\n",
      "Episode  924 : Reward =  -12595.684880946324\n",
      "Episode  925 : Reward =  -11945.984733192086\n",
      "Episode  926 : Reward =  -12959.223064993068\n",
      "Episode  927 : Reward =  -11041.774053747275\n",
      "Saving better model at episode 927 with reward -11041.774053747275\n",
      "Episode  928 : Reward =  -11198.34813126719\n",
      "Episode  929 : Reward =  -12229.786738814018\n",
      "Episode  930 : Reward =  -12493.360718430185\n",
      "Episode  931 : Reward =  -12012.342496992253\n",
      "Episode  932 : Reward =  -12344.118762673044\n",
      "Episode  933 : Reward =  -11927.388288677834\n",
      "Episode  934 : Reward =  -12451.49920171609\n",
      "Episode  935 : Reward =  -8436.114148420344\n",
      "Saving better model at episode 935 with reward -8436.114148420344\n",
      "Episode  936 : Reward =  -10192.321149132327\n",
      "Episode  937 : Reward =  -12419.249266300842\n",
      "Episode  938 : Reward =  -10793.584738845446\n",
      "Episode  939 : Reward =  -10628.693470651724\n",
      "Episode  940 : Reward =  -9395.725434649521\n",
      "Episode  941 : Reward =  -10435.209615225413\n",
      "Episode  942 : Reward =  -8099.513319382178\n",
      "Saving better model at episode 942 with reward -8099.513319382178\n",
      "Episode  943 : Reward =  -7828.99808333541\n",
      "Saving better model at episode 943 with reward -7828.99808333541\n",
      "Episode  944 : Reward =  -8528.951177281391\n",
      "Episode  945 : Reward =  -8726.34107978681\n",
      "Episode  946 : Reward =  -9686.913718092972\n",
      "Episode  947 : Reward =  -10034.86667968996\n",
      "Episode  948 : Reward =  -8111.83789191867\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.405\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  949 : Reward =  -8370.548284069093\n",
      "Episode  950 : Reward =  -8349.938206211124\n",
      "Episode  951 : Reward =  -8460.547755939016\n",
      "Episode  952 : Reward =  -7810.367445179927\n",
      "Saving better model at episode 952 with reward -7810.367445179927\n",
      "Episode  953 : Reward =  -8686.188384846242\n",
      "Episode  954 : Reward =  -10456.705251867394\n",
      "Episode  955 : Reward =  -9319.71662323528\n",
      "Episode  956 : Reward =  -9461.542712498243\n",
      "Episode  957 : Reward =  -11000.73177545748\n",
      "Episode  958 : Reward =  -8720.714794293435\n",
      "Episode  959 : Reward =  -11957.212898288413\n",
      "Episode  960 : Reward =  -7977.843561631689\n",
      "Episode  961 : Reward =  -10343.146884078602\n",
      "Episode  962 : Reward =  -9930.324709079341\n",
      "Episode  963 : Reward =  -8449.821994379552\n",
      "Episode  964 : Reward =  -9946.439620754794\n",
      "Episode  965 : Reward =  -7828.716139000902\n",
      "Episode  966 : Reward =  -9043.593217924627\n",
      "Episode  967 : Reward =  -9388.11223088556\n",
      "Episode  968 : Reward =  -10490.636183614351\n",
      "Episode  969 : Reward =  -6838.271063789598\n",
      "Saving better model at episode 969 with reward -6838.271063789598\n",
      "Episode  970 : Reward =  -7420.931026944626\n",
      "Episode  971 : Reward =  -9218.99481098705\n",
      "Episode  972 : Reward =  -7493.643815678606\n",
      "Episode  973 : Reward =  -8640.361268118413\n",
      "Episode  974 : Reward =  -8065.405832153807\n",
      "Episode  975 : Reward =  -7486.86655036832\n",
      "Episode  976 : Reward =  -7376.015295037734\n",
      "Episode  977 : Reward =  -6363.464490509505\n",
      "Saving better model at episode 977 with reward -6363.464490509505\n",
      "Episode  978 : Reward =  -6387.709298825231\n",
      "Episode  979 : Reward =  -5956.912972554437\n",
      "Saving better model at episode 979 with reward -5956.912972554437\n",
      "Episode  980 : Reward =  -9265.439916989879\n",
      "Episode  981 : Reward =  -6089.725950941316\n",
      "Episode  982 : Reward =  -6167.966340875592\n",
      "Episode  983 : Reward =  -6253.580385404437\n",
      "Episode  984 : Reward =  -5811.909512743413\n",
      "Saving better model at episode 984 with reward -5811.909512743413\n",
      "Episode  985 : Reward =  -6151.103544271464\n",
      "Episode  986 : Reward =  -5897.3752041904845\n",
      "Episode  987 : Reward =  -5448.8775806427\n",
      "Saving better model at episode 987 with reward -5448.8775806427\n",
      "Episode  988 : Reward =  -5148.488750673751\n",
      "Saving better model at episode 988 with reward -5148.488750673751\n",
      "Episode  989 : Reward =  -6372.00995481919\n",
      "Episode  990 : Reward =  -6055.16985641426\n",
      "Episode  991 : Reward =  -5894.202162846983\n",
      "Episode  992 : Reward =  -5907.312051272864\n",
      "Episode  993 : Reward =  -5685.976333595733\n",
      "Episode  994 : Reward =  -6806.552136132228\n",
      "Episode  995 : Reward =  -5716.0416669336655\n",
      "Episode  996 : Reward =  -5557.002154413523\n",
      "Episode  997 : Reward =  -5720.177235964598\n",
      "Episode  998 : Reward =  -5734.000097641121\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.4\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  999 : Reward =  -5248.703809499741\n",
      "Episode  1000 : Reward =  -5999.242736265123\n",
      "Episode  1001 : Reward =  -5396.197222062718\n",
      "Episode  1002 : Reward =  -5556.371527180136\n",
      "Episode  1003 : Reward =  -5199.957192364993\n",
      "Episode  1004 : Reward =  -5394.777175608935\n",
      "Episode  1005 : Reward =  -5128.030946019949\n",
      "Saving better model at episode 1005 with reward -5128.030946019949\n",
      "Episode  1006 : Reward =  -5374.228441417217\n",
      "Episode  1007 : Reward =  -5421.878865960898\n",
      "Episode  1008 : Reward =  -5458.104871634306\n",
      "Episode  1009 : Reward =  -5318.843292716803\n",
      "Episode  1010 : Reward =  -5314.596801105799\n",
      "Episode  1011 : Reward =  -5489.420106686573\n",
      "Episode  1012 : Reward =  -5373.08654952413\n",
      "Episode  1013 : Reward =  -5100.459883216681\n",
      "Saving better model at episode 1013 with reward -5100.459883216681\n",
      "Episode  1014 : Reward =  -5224.039970099926\n",
      "Episode  1015 : Reward =  -5341.480513192634\n",
      "Episode  1016 : Reward =  -4937.9932725429535\n",
      "Saving better model at episode 1016 with reward -4937.9932725429535\n",
      "Episode  1017 : Reward =  -5512.928746676917\n",
      "Episode  1018 : Reward =  -5095.845121625723\n",
      "Episode  1019 : Reward =  -5211.063413441181\n",
      "Episode  1020 : Reward =  -5674.707933846774\n",
      "Episode  1021 : Reward =  -5156.845726791681\n",
      "Episode  1022 : Reward =  -5562.004430875242\n",
      "Episode  1023 : Reward =  -5094.568493851792\n",
      "Episode  1024 : Reward =  -5013.327699816698\n",
      "Episode  1025 : Reward =  -5346.753553453746\n",
      "Episode  1026 : Reward =  -5021.902341131033\n",
      "Episode  1027 : Reward =  -5271.508607336651\n",
      "Episode  1028 : Reward =  -5125.750170592131\n",
      "Episode  1029 : Reward =  -4915.188966013412\n",
      "Saving better model at episode 1029 with reward -4915.188966013412\n",
      "Episode  1030 : Reward =  -5011.225693047047\n",
      "Episode  1031 : Reward =  -5016.625101331533\n",
      "Episode  1032 : Reward =  -5210.545959719788\n",
      "Episode  1033 : Reward =  -5162.735004254948\n",
      "Episode  1034 : Reward =  -4978.378662172617\n",
      "Episode  1035 : Reward =  -4810.706464413466\n",
      "Saving better model at episode 1035 with reward -4810.706464413466\n",
      "Episode  1036 : Reward =  -4836.195161998272\n",
      "Episode  1037 : Reward =  -4894.01152468599\n",
      "Episode  1038 : Reward =  -4945.323981881142\n",
      "Episode  1039 : Reward =  -5046.22059071064\n",
      "Episode  1040 : Reward =  -5155.690495349388\n",
      "Episode  1041 : Reward =  -5019.068203270435\n",
      "Episode  1042 : Reward =  -4692.055310428143\n",
      "Saving better model at episode 1042 with reward -4692.055310428143\n",
      "Episode  1043 : Reward =  -4787.359956741333\n",
      "Episode  1044 : Reward =  -4928.421990036964\n",
      "Episode  1045 : Reward =  -5046.980380717578\n",
      "Episode  1046 : Reward =  -4689.982761323452\n",
      "Saving better model at episode 1046 with reward -4689.982761323452\n",
      "Episode  1047 : Reward =  -4669.918020367622\n",
      "Saving better model at episode 1047 with reward -4669.918020367622\n",
      "Episode  1048 : Reward =  -4653.741629719734\n",
      "Saving better model at episode 1048 with reward -4653.741629719734\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.395\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1049 : Reward =  -4978.62523573637\n",
      "Episode  1050 : Reward =  -4676.253512740135\n",
      "Episode  1051 : Reward =  -4918.220539093018\n",
      "Episode  1052 : Reward =  -4643.2648876309395\n",
      "Saving better model at episode 1052 with reward -4643.2648876309395\n",
      "Episode  1053 : Reward =  -4851.599458754063\n",
      "Episode  1054 : Reward =  -4698.801225244999\n",
      "Episode  1055 : Reward =  -4633.316635191441\n",
      "Saving better model at episode 1055 with reward -4633.316635191441\n",
      "Episode  1056 : Reward =  -5036.1498856544495\n",
      "Episode  1057 : Reward =  -5089.484765410423\n",
      "Episode  1058 : Reward =  -4604.131356418133\n",
      "Saving better model at episode 1058 with reward -4604.131356418133\n",
      "Episode  1059 : Reward =  -4607.665198624134\n",
      "Episode  1060 : Reward =  -4716.606446921825\n",
      "Episode  1061 : Reward =  -4694.141828775406\n",
      "Episode  1062 : Reward =  -4784.129446983337\n",
      "Episode  1063 : Reward =  -4444.865291535854\n",
      "Saving better model at episode 1063 with reward -4444.865291535854\n",
      "Episode  1064 : Reward =  -4716.971358060837\n",
      "Episode  1065 : Reward =  -4666.202581167221\n",
      "Episode  1066 : Reward =  -4434.768028795719\n",
      "Saving better model at episode 1066 with reward -4434.768028795719\n",
      "Episode  1067 : Reward =  -4671.084261238575\n",
      "Episode  1068 : Reward =  -4732.8337017297745\n",
      "Episode  1069 : Reward =  -4778.5212968587875\n",
      "Episode  1070 : Reward =  -4544.743368864059\n",
      "Episode  1071 : Reward =  -4599.678831338882\n",
      "Episode  1072 : Reward =  -4428.503134965897\n",
      "Saving better model at episode 1072 with reward -4428.503134965897\n",
      "Episode  1073 : Reward =  -4529.7320192456245\n",
      "Episode  1074 : Reward =  -4588.804656565189\n",
      "Episode  1075 : Reward =  -4470.635588288307\n",
      "Episode  1076 : Reward =  -4507.745912015438\n",
      "Episode  1077 : Reward =  -4349.029010891914\n",
      "Saving better model at episode 1077 with reward -4349.029010891914\n",
      "Episode  1078 : Reward =  -4440.436219334602\n",
      "Episode  1079 : Reward =  -4706.857360422611\n",
      "Episode  1080 : Reward =  -4305.890632748604\n",
      "Saving better model at episode 1080 with reward -4305.890632748604\n",
      "Episode  1081 : Reward =  -4410.791741907597\n",
      "Episode  1082 : Reward =  -4295.891326725483\n",
      "Saving better model at episode 1082 with reward -4295.891326725483\n",
      "Episode  1083 : Reward =  -4981.804881013851\n",
      "Episode  1084 : Reward =  -4665.157177507877\n",
      "Episode  1085 : Reward =  -4805.20313668251\n",
      "Episode  1086 : Reward =  -4744.09266269207\n",
      "Episode  1087 : Reward =  -4329.283946812153\n",
      "Episode  1088 : Reward =  -4527.374367061915\n",
      "Episode  1089 : Reward =  -4534.366384446621\n",
      "Episode  1090 : Reward =  -4485.81136224411\n",
      "Episode  1091 : Reward =  -4333.427838087082\n",
      "Episode  1092 : Reward =  -4583.682767570019\n",
      "Episode  1093 : Reward =  -4398.458533644676\n",
      "Episode  1094 : Reward =  -4453.332545638084\n",
      "Episode  1095 : Reward =  -4521.270905375481\n",
      "Episode  1096 : Reward =  -4465.211664199829\n",
      "Episode  1097 : Reward =  -4565.392882227898\n",
      "Episode  1098 : Reward =  -4279.686192333698\n",
      "Saving better model at episode 1098 with reward -4279.686192333698\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.39\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1099 : Reward =  -4417.528326153755\n",
      "Episode  1100 : Reward =  -4828.576147675514\n",
      "Episode  1101 : Reward =  -4456.384534060955\n",
      "Episode  1102 : Reward =  -4409.169539928436\n",
      "Episode  1103 : Reward =  -4807.920527040958\n",
      "Episode  1104 : Reward =  -4688.467149972916\n",
      "Episode  1105 : Reward =  -4626.184314131737\n",
      "Episode  1106 : Reward =  -4389.432542204857\n",
      "Episode  1107 : Reward =  -4457.522918879986\n",
      "Episode  1108 : Reward =  -4341.21782296896\n",
      "Episode  1109 : Reward =  -4236.583719730377\n",
      "Saving better model at episode 1109 with reward -4236.583719730377\n",
      "Episode  1110 : Reward =  -4333.996203482151\n",
      "Episode  1111 : Reward =  -4255.867397248745\n",
      "Episode  1112 : Reward =  -4160.089065670967\n",
      "Saving better model at episode 1112 with reward -4160.089065670967\n",
      "Episode  1113 : Reward =  -4426.32037627697\n",
      "Episode  1114 : Reward =  -4233.407462596893\n",
      "Episode  1115 : Reward =  -4345.646702293219\n",
      "Episode  1116 : Reward =  -4231.88682359457\n",
      "Episode  1117 : Reward =  -4232.2106229662895\n",
      "Episode  1118 : Reward =  -4696.271038651466\n",
      "Episode  1119 : Reward =  -4366.825607717037\n",
      "Episode  1120 : Reward =  -4483.957655966282\n",
      "Episode  1121 : Reward =  -4209.316347241402\n",
      "Episode  1122 : Reward =  -4538.00143378973\n",
      "Episode  1123 : Reward =  -4302.880983710289\n",
      "Episode  1124 : Reward =  -4327.578763663769\n",
      "Episode  1125 : Reward =  -4330.06106877327\n",
      "Episode  1126 : Reward =  -4361.545482873917\n",
      "Episode  1127 : Reward =  -4283.884401321411\n",
      "Episode  1128 : Reward =  -4332.222996652126\n",
      "Episode  1129 : Reward =  -4554.115870773792\n",
      "Episode  1130 : Reward =  -4380.548785805702\n",
      "Episode  1131 : Reward =  -4351.678385317326\n",
      "Episode  1132 : Reward =  -4544.735821008682\n",
      "Episode  1133 : Reward =  -4340.558456003666\n",
      "Episode  1134 : Reward =  -4413.078017115593\n",
      "Episode  1135 : Reward =  -4274.920988082886\n",
      "Episode  1136 : Reward =  -4272.938019037247\n",
      "Episode  1137 : Reward =  -4257.261168003082\n",
      "Episode  1138 : Reward =  -4211.607255280018\n",
      "Episode  1139 : Reward =  -4385.132082879543\n",
      "Episode  1140 : Reward =  -4105.497605025768\n",
      "Saving better model at episode 1140 with reward -4105.497605025768\n",
      "Episode  1141 : Reward =  -4319.868408501148\n",
      "Episode  1142 : Reward =  -4339.0491099357605\n",
      "Episode  1143 : Reward =  -4136.943544149399\n",
      "Episode  1144 : Reward =  -4243.325663805008\n",
      "Episode  1145 : Reward =  -4241.567603230476\n",
      "Episode  1146 : Reward =  -4181.296948552132\n",
      "Episode  1147 : Reward =  -4175.0032979846\n",
      "Episode  1148 : Reward =  -4192.970414698124\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.385\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1149 : Reward =  -4173.738539457321\n",
      "Episode  1150 : Reward =  -4155.470029652119\n",
      "Episode  1151 : Reward =  -3948.41963994503\n",
      "Saving better model at episode 1151 with reward -3948.41963994503\n",
      "Episode  1152 : Reward =  -4215.844204723835\n",
      "Episode  1153 : Reward =  -4194.713275849819\n",
      "Episode  1154 : Reward =  -4210.0458958745\n",
      "Episode  1155 : Reward =  -4177.122245490551\n",
      "Episode  1156 : Reward =  -4124.119877576828\n",
      "Episode  1157 : Reward =  -4038.864874780178\n",
      "Episode  1158 : Reward =  -3984.3944295048714\n",
      "Episode  1159 : Reward =  -4019.887659609318\n",
      "Episode  1160 : Reward =  -4129.236089587212\n",
      "Episode  1161 : Reward =  -4273.4496284127235\n",
      "Episode  1162 : Reward =  -4085.8705002069473\n",
      "Episode  1163 : Reward =  -4171.710150241852\n",
      "Episode  1164 : Reward =  -4039.4307312965393\n",
      "Episode  1165 : Reward =  -4012.5947772860527\n",
      "Episode  1166 : Reward =  -4204.451145350933\n",
      "Episode  1167 : Reward =  -3962.7404129505157\n",
      "Episode  1168 : Reward =  -4037.870936155319\n",
      "Episode  1169 : Reward =  -4120.390728831291\n",
      "Episode  1170 : Reward =  -4143.588821351528\n",
      "Episode  1171 : Reward =  -3956.921275138855\n",
      "Episode  1172 : Reward =  -4167.519900918007\n",
      "Episode  1173 : Reward =  -4153.187332212925\n",
      "Episode  1174 : Reward =  -4169.046212792397\n",
      "Episode  1175 : Reward =  -4189.029632091522\n",
      "Episode  1176 : Reward =  -4129.094604551792\n",
      "Episode  1177 : Reward =  -4020.0037442445755\n",
      "Episode  1178 : Reward =  -4127.157866120338\n",
      "Episode  1179 : Reward =  -4063.792235970497\n",
      "Episode  1180 : Reward =  -4073.697430431843\n",
      "Episode  1181 : Reward =  -4208.17491286993\n",
      "Episode  1182 : Reward =  -4103.315433263779\n",
      "Episode  1183 : Reward =  -4062.6651648283005\n",
      "Episode  1184 : Reward =  -4285.779071394267\n",
      "Episode  1185 : Reward =  -4030.064672231674\n",
      "Episode  1186 : Reward =  -4369.499065577984\n",
      "Episode  1187 : Reward =  -4056.01155179739\n",
      "Episode  1188 : Reward =  -4173.938017606735\n",
      "Episode  1189 : Reward =  -4138.617425620556\n",
      "Episode  1190 : Reward =  -4182.282607078552\n",
      "Episode  1191 : Reward =  -4045.6728557384627\n",
      "Episode  1192 : Reward =  -4158.143816292286\n",
      "Episode  1193 : Reward =  -4209.488055884838\n",
      "Episode  1194 : Reward =  -4267.6036049723625\n",
      "Episode  1195 : Reward =  -4126.133356869221\n",
      "Episode  1196 : Reward =  -4100.258834421635\n",
      "Episode  1197 : Reward =  -4008.7362176775932\n",
      "Episode  1198 : Reward =  -4049.791072666645\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.38\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1199 : Reward =  -3793.039087355137\n",
      "Saving better model at episode 1199 with reward -3793.039087355137\n",
      "Episode  1200 : Reward =  -4020.229560315609\n",
      "Episode  1201 : Reward =  -4021.268692970276\n",
      "Episode  1202 : Reward =  -3827.243390381336\n",
      "Episode  1203 : Reward =  -3841.609315097332\n",
      "Episode  1204 : Reward =  -3929.2603760994093\n",
      "Episode  1205 : Reward =  -3912.7910475730896\n",
      "Episode  1206 : Reward =  -3854.1537331938744\n",
      "Episode  1207 : Reward =  -4035.770204603672\n",
      "Episode  1208 : Reward =  -3812.057986199856\n",
      "Episode  1209 : Reward =  -3831.629612982273\n",
      "Episode  1210 : Reward =  -3991.309735774994\n",
      "Episode  1211 : Reward =  -3955.7021686434746\n",
      "Episode  1212 : Reward =  -3962.372375547886\n",
      "Episode  1213 : Reward =  -4075.7758902311325\n",
      "Episode  1214 : Reward =  -3910.0050582289696\n",
      "Episode  1215 : Reward =  -4099.696885108948\n",
      "Episode  1216 : Reward =  -3850.4666526317596\n",
      "Episode  1217 : Reward =  -4005.286276638508\n",
      "Episode  1218 : Reward =  -4046.0951798558235\n",
      "Episode  1219 : Reward =  -4001.611682653427\n",
      "Episode  1220 : Reward =  -4106.897789418697\n",
      "Episode  1221 : Reward =  -4102.9351007938385\n",
      "Episode  1222 : Reward =  -4075.8763803839684\n",
      "Episode  1223 : Reward =  -3971.195644557476\n",
      "Episode  1224 : Reward =  -3936.5596176981926\n",
      "Episode  1225 : Reward =  -3938.942152917385\n",
      "Episode  1226 : Reward =  -4006.2798515558243\n",
      "Episode  1227 : Reward =  -4024.0086283683777\n",
      "Episode  1228 : Reward =  -4138.000398159027\n",
      "Episode  1229 : Reward =  -3975.5442004799843\n",
      "Episode  1230 : Reward =  -4117.799949586391\n",
      "Episode  1231 : Reward =  -4115.7175624370575\n",
      "Episode  1232 : Reward =  -4007.9769982099533\n",
      "Episode  1233 : Reward =  -3978.1083860993385\n",
      "Episode  1234 : Reward =  -3950.0617067813873\n",
      "Episode  1235 : Reward =  -3855.0283604860306\n",
      "Episode  1236 : Reward =  -4146.7542543411255\n",
      "Episode  1237 : Reward =  -3961.6726648807526\n",
      "Episode  1238 : Reward =  -4060.1514162421227\n",
      "Episode  1239 : Reward =  -3967.4734978079796\n",
      "Episode  1240 : Reward =  -4043.2519015073776\n",
      "Episode  1241 : Reward =  -4113.630360487761\n",
      "Episode  1242 : Reward =  -4076.846391439438\n",
      "Episode  1243 : Reward =  -4003.6051418817656\n",
      "Episode  1244 : Reward =  -4120.841049381863\n",
      "Episode  1245 : Reward =  -4024.236294090748\n",
      "Episode  1246 : Reward =  -3991.4282410740852\n",
      "Episode  1247 : Reward =  -4032.4372875094414\n",
      "Episode  1248 : Reward =  -3943.9117803013937\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.375\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1249 : Reward =  -3952.1223334670067\n",
      "Episode  1250 : Reward =  -4034.0944576859474\n",
      "Episode  1251 : Reward =  -4075.150382876396\n",
      "Episode  1252 : Reward =  -3943.492730561556\n",
      "Episode  1253 : Reward =  -4002.6504222750664\n",
      "Episode  1254 : Reward =  -3998.4275233745575\n",
      "Episode  1255 : Reward =  -3998.3422303795815\n",
      "Episode  1256 : Reward =  -3901.1162645220757\n",
      "Episode  1257 : Reward =  -3993.6912982463837\n",
      "Episode  1258 : Reward =  -3914.24892359972\n",
      "Episode  1259 : Reward =  -3942.1931431889534\n",
      "Episode  1260 : Reward =  -3839.3314781188965\n",
      "Episode  1261 : Reward =  -3956.544741511345\n",
      "Episode  1262 : Reward =  -4146.288397729397\n",
      "Episode  1263 : Reward =  -4074.468811392784\n",
      "Episode  1264 : Reward =  -4068.808176100254\n",
      "Episode  1265 : Reward =  -3899.548262000084\n",
      "Episode  1266 : Reward =  -3874.297655761242\n",
      "Episode  1267 : Reward =  -4112.14428961277\n",
      "Episode  1268 : Reward =  -3987.7657987475395\n",
      "Episode  1269 : Reward =  -3993.375940978527\n",
      "Episode  1270 : Reward =  -4021.9942548274994\n",
      "Episode  1271 : Reward =  -4116.480532705784\n",
      "Episode  1272 : Reward =  -4167.536353954445\n",
      "Episode  1273 : Reward =  -3911.316807806492\n",
      "Episode  1274 : Reward =  -4013.730186998844\n",
      "Episode  1275 : Reward =  -4054.654087662697\n",
      "Episode  1276 : Reward =  -4081.709775987925\n",
      "Episode  1277 : Reward =  -3993.9704483747482\n",
      "Episode  1278 : Reward =  -4025.777258694172\n",
      "Episode  1279 : Reward =  -4060.8730152845383\n",
      "Episode  1280 : Reward =  -4122.229181826115\n",
      "Episode  1281 : Reward =  -4020.57058519125\n",
      "Episode  1282 : Reward =  -4124.993601381779\n",
      "Episode  1283 : Reward =  -4102.269716203213\n",
      "Episode  1284 : Reward =  -4033.2384070158005\n",
      "Episode  1285 : Reward =  -4007.2677915096283\n",
      "Episode  1286 : Reward =  -4212.086050868034\n",
      "Episode  1287 : Reward =  -4174.061145424843\n",
      "Episode  1288 : Reward =  -4086.2261205911636\n",
      "Episode  1289 : Reward =  -4098.013762295246\n",
      "Episode  1290 : Reward =  -4202.710071384907\n",
      "Episode  1291 : Reward =  -4177.257059633732\n",
      "Episode  1292 : Reward =  -4165.400288701057\n",
      "Episode  1293 : Reward =  -4345.885713934898\n",
      "Episode  1294 : Reward =  -4122.99320346117\n",
      "Episode  1295 : Reward =  -4097.279096066952\n",
      "Episode  1296 : Reward =  -3942.2288261055946\n",
      "Episode  1297 : Reward =  -4118.846330881119\n",
      "Episode  1298 : Reward =  -4328.195870220661\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.37\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1299 : Reward =  -4198.221607267857\n",
      "Episode  1300 : Reward =  -3967.466075539589\n",
      "Episode  1301 : Reward =  -3962.7471776604652\n",
      "Episode  1302 : Reward =  -4090.496179640293\n",
      "Episode  1303 : Reward =  -4193.943641245365\n",
      "Episode  1304 : Reward =  -4223.501541018486\n",
      "Episode  1305 : Reward =  -4014.8465111255646\n",
      "Episode  1306 : Reward =  -4086.5542479753494\n",
      "Episode  1307 : Reward =  -4030.1702447533607\n",
      "Episode  1308 : Reward =  -4351.003036681475\n",
      "Episode  1309 : Reward =  -3853.0860114097595\n",
      "Episode  1310 : Reward =  -4091.555918931961\n",
      "Episode  1311 : Reward =  -4217.022109333338\n",
      "Episode  1312 : Reward =  -3921.1850802898407\n",
      "Episode  1313 : Reward =  -3846.1527650356293\n",
      "Episode  1314 : Reward =  -4143.16336286068\n",
      "Episode  1315 : Reward =  -4115.056124329567\n",
      "Episode  1316 : Reward =  -3986.5234461426735\n",
      "Episode  1317 : Reward =  -3864.471573472023\n",
      "Episode  1318 : Reward =  -4095.3737695217133\n",
      "Episode  1319 : Reward =  -3859.0155442357063\n",
      "Episode  1320 : Reward =  -4064.1868495345116\n",
      "Episode  1321 : Reward =  -4233.72764444715\n",
      "Episode  1322 : Reward =  -3971.819243848324\n",
      "Episode  1323 : Reward =  -4046.7813953757286\n",
      "Episode  1324 : Reward =  -4019.495651960373\n",
      "Episode  1325 : Reward =  -4096.731199264526\n",
      "Episode  1326 : Reward =  -4290.560018185439\n",
      "Episode  1327 : Reward =  -4234.5975759625435\n",
      "Episode  1328 : Reward =  -4054.1268263459206\n",
      "Episode  1329 : Reward =  -3950.9849378466606\n",
      "Episode  1330 : Reward =  -4012.0464512109756\n",
      "Episode  1331 : Reward =  -4287.412261903286\n",
      "Episode  1332 : Reward =  -4119.463917914691\n",
      "Episode  1333 : Reward =  -4124.4552028775215\n",
      "Episode  1334 : Reward =  -3867.312210202217\n",
      "Episode  1335 : Reward =  -4014.5933778373105\n",
      "Episode  1336 : Reward =  -4104.386541187763\n",
      "Episode  1337 : Reward =  -3875.149519741535\n",
      "Episode  1338 : Reward =  -4012.7575615644455\n",
      "Episode  1339 : Reward =  -3866.048364818096\n",
      "Episode  1340 : Reward =  -3754.539117872715\n",
      "Saving better model at episode 1340 with reward -3754.539117872715\n",
      "Episode  1341 : Reward =  -4044.3832547664642\n",
      "Episode  1342 : Reward =  -3906.3266036510468\n",
      "Episode  1343 : Reward =  -3943.533199131489\n",
      "Episode  1344 : Reward =  -3847.188241660595\n",
      "Episode  1345 : Reward =  -3994.06269419557\n",
      "Episode  1346 : Reward =  -4009.846801519394\n",
      "Episode  1347 : Reward =  -4230.499341762537\n",
      "Episode  1348 : Reward =  -3882.648792564869\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.365\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1349 : Reward =  -3954.9808571338654\n",
      "Episode  1350 : Reward =  -4073.6161969304085\n",
      "Episode  1351 : Reward =  -3805.9763044714928\n",
      "Episode  1352 : Reward =  -3814.288896083832\n",
      "Episode  1353 : Reward =  -3886.605630993843\n",
      "Episode  1354 : Reward =  -3980.4497353806305\n",
      "Episode  1355 : Reward =  -3886.3410615324974\n",
      "Episode  1356 : Reward =  -4014.5394675135612\n",
      "Episode  1357 : Reward =  -3945.041056096554\n",
      "Episode  1358 : Reward =  -4004.4444525874273\n",
      "Episode  1359 : Reward =  -3813.7161449193954\n",
      "Episode  1360 : Reward =  -3868.068389892578\n",
      "Episode  1361 : Reward =  -3818.493242029013\n",
      "Episode  1362 : Reward =  -3935.9148594737053\n",
      "Episode  1363 : Reward =  -3966.7920036352293\n",
      "Episode  1364 : Reward =  -4013.3875374794006\n",
      "Episode  1365 : Reward =  -3925.599191733967\n",
      "Episode  1366 : Reward =  -4021.161048654379\n",
      "Episode  1367 : Reward =  -3816.177078664303\n",
      "Episode  1368 : Reward =  -3864.7213971614838\n",
      "Episode  1369 : Reward =  -3938.600553277792\n",
      "Episode  1370 : Reward =  -3831.622620288195\n",
      "Episode  1371 : Reward =  -3720.9155264496803\n",
      "Saving better model at episode 1371 with reward -3720.9155264496803\n",
      "Episode  1372 : Reward =  -3791.038058880629\n",
      "Episode  1373 : Reward =  -3829.044990539551\n",
      "Episode  1374 : Reward =  -3903.9941251277924\n",
      "Episode  1375 : Reward =  -4025.539784137072\n",
      "Episode  1376 : Reward =  -4048.1536864674704\n",
      "Episode  1377 : Reward =  -3888.556888759136\n",
      "Episode  1378 : Reward =  -3957.024155676365\n",
      "Episode  1379 : Reward =  -3807.912853781046\n",
      "Episode  1380 : Reward =  -3997.3044096827507\n",
      "Episode  1381 : Reward =  -3951.9724721312523\n",
      "Episode  1382 : Reward =  -4013.1983284390585\n",
      "Episode  1383 : Reward =  -3850.2498217225075\n",
      "Episode  1384 : Reward =  -3826.742563009262\n",
      "Episode  1385 : Reward =  -3859.4870673418045\n",
      "Episode  1386 : Reward =  -3949.2885029911995\n",
      "Episode  1387 : Reward =  -3799.1463681459427\n",
      "Episode  1388 : Reward =  -3846.787593126297\n",
      "Episode  1389 : Reward =  -3839.6962777376175\n",
      "Episode  1390 : Reward =  -3913.45608150959\n",
      "Episode  1391 : Reward =  -3888.9219267964363\n",
      "Episode  1392 : Reward =  -4025.7620909250395\n",
      "Episode  1393 : Reward =  -3892.05710375309\n",
      "Episode  1394 : Reward =  -3891.96127474308\n",
      "Episode  1395 : Reward =  -3844.647097054781\n",
      "Episode  1396 : Reward =  -4020.040878597559\n",
      "Episode  1397 : Reward =  -3981.6004022955894\n",
      "Episode  1398 : Reward =  -4102.758760753932\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.36\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1399 : Reward =  -3945.597994685173\n",
      "Episode  1400 : Reward =  -3790.0366887301802\n",
      "Episode  1401 : Reward =  -3484.6197009458347\n",
      "Saving better model at episode 1401 with reward -3484.6197009458347\n",
      "Episode  1402 : Reward =  -3806.8800731897354\n",
      "Episode  1403 : Reward =  -3866.0470032691956\n",
      "Episode  1404 : Reward =  -4068.8198667764664\n",
      "Episode  1405 : Reward =  -3870.8226661086082\n",
      "Episode  1406 : Reward =  -3854.1519414782524\n",
      "Episode  1407 : Reward =  -3991.145265877247\n",
      "Episode  1408 : Reward =  -3924.8567138314247\n",
      "Episode  1409 : Reward =  -4071.151360332966\n",
      "Episode  1410 : Reward =  -3995.111351966858\n",
      "Episode  1411 : Reward =  -4050.61662453413\n",
      "Episode  1412 : Reward =  -4036.452132642269\n",
      "Episode  1413 : Reward =  -3982.8116407990456\n",
      "Episode  1414 : Reward =  -4025.5162350535393\n",
      "Episode  1415 : Reward =  -4093.7441486120224\n",
      "Episode  1416 : Reward =  -3937.359426319599\n",
      "Episode  1417 : Reward =  -3862.1362678445\n",
      "Episode  1418 : Reward =  -3829.685964289965\n",
      "Episode  1419 : Reward =  -3905.7008123993874\n",
      "Episode  1420 : Reward =  -3815.5044828144414\n",
      "Episode  1421 : Reward =  -3954.2824674248695\n",
      "Episode  1422 : Reward =  -3857.327776014805\n",
      "Episode  1423 : Reward =  -3981.9968370199203\n",
      "Episode  1424 : Reward =  -3959.4010152220726\n",
      "Episode  1425 : Reward =  -4066.4693999886513\n",
      "Episode  1426 : Reward =  -3951.017588853836\n",
      "Episode  1427 : Reward =  -3838.6535117030144\n",
      "Episode  1428 : Reward =  -4017.865774512291\n",
      "Episode  1429 : Reward =  -4032.8368250131607\n",
      "Episode  1430 : Reward =  -3921.299899816513\n",
      "Episode  1431 : Reward =  -4077.454311490059\n",
      "Episode  1432 : Reward =  -3937.449607849121\n",
      "Episode  1433 : Reward =  -3962.383076429367\n",
      "Episode  1434 : Reward =  -3969.2348086237907\n",
      "Episode  1435 : Reward =  -3940.184500694275\n",
      "Episode  1436 : Reward =  -3950.4793878793716\n",
      "Episode  1437 : Reward =  -3942.7497556209564\n",
      "Episode  1438 : Reward =  -4069.9359175003187\n",
      "Episode  1439 : Reward =  -3940.6325897014754\n",
      "Episode  1440 : Reward =  -4086.9108825958388\n",
      "Episode  1441 : Reward =  -3817.941363930702\n",
      "Episode  1442 : Reward =  -4001.3571689128876\n",
      "Episode  1443 : Reward =  -4257.560305718245\n",
      "Episode  1444 : Reward =  -4043.4321933984756\n",
      "Episode  1445 : Reward =  -3943.7400899020536\n",
      "Episode  1446 : Reward =  -3987.572118997574\n",
      "Episode  1447 : Reward =  -4040.500652253628\n",
      "Episode  1448 : Reward =  -3839.075965229334\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.355\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1449 : Reward =  -4012.082852372299\n",
      "Episode  1450 : Reward =  -4115.6713953614235\n",
      "Episode  1451 : Reward =  -3897.532178103924\n",
      "Episode  1452 : Reward =  -3938.950917789112\n",
      "Episode  1453 : Reward =  -3961.557907704176\n",
      "Episode  1454 : Reward =  -3870.5027333498\n",
      "Episode  1455 : Reward =  -4032.5542627573013\n",
      "Episode  1456 : Reward =  -4150.185588717461\n",
      "Episode  1457 : Reward =  -3878.7700921929495\n",
      "Episode  1458 : Reward =  -3980.0069231390953\n",
      "Episode  1459 : Reward =  -3911.7706753611565\n",
      "Episode  1460 : Reward =  -3949.704764250578\n",
      "Episode  1461 : Reward =  -3894.013653218746\n",
      "Episode  1462 : Reward =  -4037.1466882912023\n",
      "Episode  1463 : Reward =  -3938.3548777786596\n",
      "Episode  1464 : Reward =  -3891.297950208187\n",
      "Episode  1465 : Reward =  -3962.901941716671\n",
      "Episode  1466 : Reward =  -3970.5985667705536\n",
      "Episode  1467 : Reward =  -3957.6619904637337\n",
      "Episode  1468 : Reward =  -3967.727466985643\n",
      "Episode  1469 : Reward =  -4024.709214389324\n",
      "Episode  1470 : Reward =  -3950.5312706915247\n",
      "Episode  1471 : Reward =  -3898.002822458744\n",
      "Episode  1472 : Reward =  -3924.528173327446\n",
      "Episode  1473 : Reward =  -4002.782311860384\n",
      "Episode  1474 : Reward =  -4047.860118457447\n",
      "Episode  1475 : Reward =  -4110.66643255949\n",
      "Episode  1476 : Reward =  -3933.3007830381393\n",
      "Episode  1477 : Reward =  -4036.725063148798\n",
      "Episode  1478 : Reward =  -3976.495787203312\n",
      "Episode  1479 : Reward =  -4155.241364657879\n",
      "Episode  1480 : Reward =  -4000.750118613243\n",
      "Episode  1481 : Reward =  -3969.908683180809\n",
      "Episode  1482 : Reward =  -4067.303444325924\n",
      "Episode  1483 : Reward =  -4042.139012634754\n",
      "Episode  1484 : Reward =  -3769.878207632671\n",
      "Episode  1485 : Reward =  -3662.4757268515928\n",
      "Episode  1486 : Reward =  -3945.610193490982\n",
      "Episode  1487 : Reward =  -3884.221503624092\n",
      "Episode  1488 : Reward =  -3812.3030422329903\n",
      "Episode  1489 : Reward =  -3556.0323366970415\n",
      "Episode  1490 : Reward =  -3786.7664324132306\n",
      "Episode  1491 : Reward =  -3832.999145988287\n",
      "Episode  1492 : Reward =  -3612.241591967563\n",
      "Episode  1493 : Reward =  -3921.890596449375\n",
      "Episode  1494 : Reward =  -3851.109860599041\n",
      "Episode  1495 : Reward =  -3981.7146688103676\n",
      "Episode  1496 : Reward =  -3948.9056743979454\n",
      "Episode  1497 : Reward =  -3979.5070422974927\n",
      "Episode  1498 : Reward =  -4079.4937384215696\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.35\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1499 : Reward =  -3977.8213402665274\n",
      "Episode  1500 : Reward =  -3923.2134655714035\n",
      "Episode  1501 : Reward =  -3876.7016728520393\n",
      "Episode  1502 : Reward =  -3986.5023254243238\n",
      "Episode  1503 : Reward =  -4017.6313886082785\n",
      "Episode  1504 : Reward =  -3804.9491017460823\n",
      "Episode  1505 : Reward =  -3906.56064880258\n",
      "Episode  1506 : Reward =  -3767.963949657898\n",
      "Episode  1507 : Reward =  -3615.529610284935\n",
      "Episode  1508 : Reward =  -4219.573177695274\n",
      "Episode  1509 : Reward =  -4100.630036532879\n",
      "Episode  1510 : Reward =  -4006.440458714962\n",
      "Episode  1511 : Reward =  -4000.3042220509665\n",
      "Episode  1512 : Reward =  -3785.0642921415674\n",
      "Episode  1513 : Reward =  -4043.6876761317253\n",
      "Episode  1514 : Reward =  -3933.0303298271315\n",
      "Episode  1515 : Reward =  -3921.5718937552588\n",
      "Episode  1516 : Reward =  -3856.9092779842717\n",
      "Episode  1517 : Reward =  -3906.4105334369046\n",
      "Episode  1518 : Reward =  -3935.9834233522415\n",
      "Episode  1519 : Reward =  -4026.8405876755714\n",
      "Episode  1520 : Reward =  -3722.2361447986054\n",
      "Episode  1521 : Reward =  -4025.5778253165586\n",
      "Episode  1522 : Reward =  -3985.099434733391\n",
      "Episode  1523 : Reward =  -4066.287232760252\n",
      "Episode  1524 : Reward =  -3943.479867219925\n",
      "Episode  1525 : Reward =  -3981.890926539898\n",
      "Episode  1526 : Reward =  -3979.3598957657814\n",
      "Episode  1527 : Reward =  -3940.2908365762846\n",
      "Episode  1528 : Reward =  -3960.8717002272606\n",
      "Episode  1529 : Reward =  -3612.5589757327975\n",
      "Episode  1530 : Reward =  -3923.617689549923\n",
      "Episode  1531 : Reward =  -3847.2137609124184\n",
      "Episode  1532 : Reward =  -3961.7241926789284\n",
      "Episode  1533 : Reward =  -3950.6608745492117\n",
      "Episode  1534 : Reward =  -3816.5716123356624\n",
      "Episode  1535 : Reward =  -3835.85743237413\n",
      "Episode  1536 : Reward =  -4051.543600857258\n",
      "Episode  1537 : Reward =  -3893.4925838708878\n",
      "Episode  1538 : Reward =  -3911.5379480719566\n",
      "Episode  1539 : Reward =  -3923.7518694996834\n",
      "Episode  1540 : Reward =  -3885.6985080838203\n",
      "Episode  1541 : Reward =  -3838.1426211595535\n",
      "Episode  1542 : Reward =  -3825.599389232616\n",
      "Episode  1543 : Reward =  -3992.106976211071\n",
      "Episode  1544 : Reward =  -3720.4364600268705\n",
      "Episode  1545 : Reward =  -3745.521752246986\n",
      "Episode  1546 : Reward =  -3912.0255845872266\n",
      "Episode  1547 : Reward =  -4039.362568259239\n",
      "Episode  1548 : Reward =  -3929.2668052352087\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.345\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1549 : Reward =  -3971.325126171112\n",
      "Episode  1550 : Reward =  -3862.2767453193665\n",
      "Episode  1551 : Reward =  -3967.786524295807\n",
      "Episode  1552 : Reward =  -3972.278985440731\n",
      "Episode  1553 : Reward =  -3582.5861959544527\n",
      "Episode  1554 : Reward =  -3726.43311679727\n",
      "Episode  1555 : Reward =  -3890.546143177809\n",
      "Episode  1556 : Reward =  -3851.4728145599365\n",
      "Episode  1557 : Reward =  -3929.5656435489655\n",
      "Episode  1558 : Reward =  -3582.006839670162\n",
      "Episode  1559 : Reward =  -3957.003904938698\n",
      "Episode  1560 : Reward =  -3586.9649947061343\n",
      "Episode  1561 : Reward =  -3798.0165004730225\n",
      "Episode  1562 : Reward =  -3736.4801613724844\n",
      "Episode  1563 : Reward =  -3780.8700758851187\n",
      "Episode  1564 : Reward =  -3750.0946164502902\n",
      "Episode  1565 : Reward =  -3813.5549492327077\n",
      "Episode  1566 : Reward =  -3837.8598688281195\n",
      "Episode  1567 : Reward =  -3805.359482586384\n",
      "Episode  1568 : Reward =  -3937.2348789572716\n",
      "Episode  1569 : Reward =  -3840.730734590353\n",
      "Episode  1570 : Reward =  -3747.3205632939143\n",
      "Episode  1571 : Reward =  -3655.7652971831662\n",
      "Episode  1572 : Reward =  -3733.71937883264\n",
      "Episode  1573 : Reward =  -3729.253257370466\n",
      "Episode  1574 : Reward =  -3734.846594131464\n",
      "Episode  1575 : Reward =  -3763.076431453228\n",
      "Episode  1576 : Reward =  -3686.3062796629088\n",
      "Episode  1577 : Reward =  -3740.4346785632474\n",
      "Episode  1578 : Reward =  -3649.1195525614125\n",
      "Episode  1579 : Reward =  -3907.9348240531103\n",
      "Episode  1580 : Reward =  -3734.868351854305\n",
      "Episode  1581 : Reward =  -3736.7763106859343\n",
      "Episode  1582 : Reward =  -3768.1945977211\n",
      "Episode  1583 : Reward =  -3613.1013322238864\n",
      "Episode  1584 : Reward =  -3806.7061752080917\n",
      "Episode  1585 : Reward =  -3815.408522129059\n",
      "Episode  1586 : Reward =  -3737.438168287277\n",
      "Episode  1587 : Reward =  -3643.4614078438894\n",
      "Episode  1588 : Reward =  -3831.9929857290404\n",
      "Episode  1589 : Reward =  -3993.527657389641\n",
      "Episode  1590 : Reward =  -3865.710666600527\n",
      "Episode  1591 : Reward =  -3817.941382265562\n",
      "Episode  1592 : Reward =  -3659.8138505852835\n",
      "Episode  1593 : Reward =  -3947.620771709742\n",
      "Episode  1594 : Reward =  -3749.9651843941824\n",
      "Episode  1595 : Reward =  -3599.2329433336063\n",
      "Episode  1596 : Reward =  -3881.7002843618393\n",
      "Episode  1597 : Reward =  -3726.4286171793938\n",
      "Episode  1598 : Reward =  -3713.2063232100622\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.34\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1599 : Reward =  -3835.4330329298973\n",
      "Episode  1600 : Reward =  -3760.544892668724\n",
      "Episode  1601 : Reward =  -3779.0072686076164\n",
      "Episode  1602 : Reward =  -3845.4522566199303\n",
      "Episode  1603 : Reward =  -3712.218147221865\n",
      "Episode  1604 : Reward =  -3758.7263484037535\n",
      "Episode  1605 : Reward =  -3793.463789287867\n",
      "Episode  1606 : Reward =  -3680.763748828234\n",
      "Episode  1607 : Reward =  -3719.525021382938\n",
      "Episode  1608 : Reward =  -3838.033636033535\n",
      "Episode  1609 : Reward =  -3803.014728963375\n",
      "Episode  1610 : Reward =  -3760.3886628746986\n",
      "Episode  1611 : Reward =  -3814.9901182055473\n",
      "Episode  1612 : Reward =  -3667.1911807743413\n",
      "Episode  1613 : Reward =  -3675.218274542461\n",
      "Episode  1614 : Reward =  -3670.111978805536\n",
      "Episode  1615 : Reward =  -3817.997842311859\n",
      "Episode  1616 : Reward =  -3545.1648385896488\n",
      "Episode  1617 : Reward =  -3779.5371637940407\n",
      "Episode  1618 : Reward =  -3714.298588037491\n",
      "Episode  1619 : Reward =  -3795.279680252075\n",
      "Episode  1620 : Reward =  -3690.848050713539\n",
      "Episode  1621 : Reward =  -3718.8314736857224\n",
      "Episode  1622 : Reward =  -3641.1567865014076\n",
      "Episode  1623 : Reward =  -3697.182256437759\n",
      "Episode  1624 : Reward =  -3760.138699412346\n",
      "Episode  1625 : Reward =  -3759.5236673355103\n",
      "Episode  1626 : Reward =  -3684.447619336455\n",
      "Episode  1627 : Reward =  -3821.308034071098\n",
      "Episode  1628 : Reward =  -3724.9835857240064\n",
      "Episode  1629 : Reward =  -3722.8424573540688\n",
      "Episode  1630 : Reward =  -3715.318786561489\n",
      "Episode  1631 : Reward =  -3680.9496920108795\n",
      "Episode  1632 : Reward =  -3854.2785950899124\n",
      "Episode  1633 : Reward =  -3679.27971700571\n",
      "Episode  1634 : Reward =  -3628.295554459095\n",
      "Episode  1635 : Reward =  -3602.1046667099\n",
      "Episode  1636 : Reward =  -3740.551760196686\n",
      "Episode  1637 : Reward =  -3741.879374921322\n",
      "Episode  1638 : Reward =  -3632.7554583921237\n",
      "Episode  1639 : Reward =  -3727.747609913349\n",
      "Episode  1640 : Reward =  -3705.844559431076\n",
      "Episode  1641 : Reward =  -3816.5585607886314\n",
      "Episode  1642 : Reward =  -3791.14166576034\n",
      "Episode  1643 : Reward =  -3729.798185232939\n",
      "Episode  1644 : Reward =  -3720.535727146925\n",
      "Episode  1645 : Reward =  -3886.934708007942\n",
      "Episode  1646 : Reward =  -3674.9449434280396\n",
      "Episode  1647 : Reward =  -3774.016040302734\n",
      "Episode  1648 : Reward =  -3715.743854650627\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.335\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1649 : Reward =  -3596.036716259937\n",
      "Episode  1650 : Reward =  -3552.115258336067\n",
      "Episode  1651 : Reward =  -3710.8216873183055\n",
      "Episode  1652 : Reward =  -3822.360427081585\n",
      "Episode  1653 : Reward =  -3795.933262825012\n",
      "Episode  1654 : Reward =  -3753.9048105478287\n",
      "Episode  1655 : Reward =  -3682.627948641777\n",
      "Episode  1656 : Reward =  -3769.933066967787\n",
      "Episode  1657 : Reward =  -3789.259900990786\n",
      "Episode  1658 : Reward =  -3577.9584587588115\n",
      "Episode  1659 : Reward =  -3675.1683232188225\n",
      "Episode  1660 : Reward =  -3785.6307892835753\n",
      "Episode  1661 : Reward =  -3674.0395913124084\n",
      "Episode  1662 : Reward =  -3691.4142338073866\n",
      "Episode  1663 : Reward =  -3866.6764670646803\n",
      "Episode  1664 : Reward =  -3706.3654658794403\n",
      "Episode  1665 : Reward =  -3597.4209574460983\n",
      "Episode  1666 : Reward =  -3722.9807710051537\n",
      "Episode  1667 : Reward =  -3829.461341381073\n",
      "Episode  1668 : Reward =  -3823.6477311849594\n",
      "Episode  1669 : Reward =  -3539.0277110934258\n",
      "Episode  1670 : Reward =  -3678.7461128918035\n",
      "Episode  1671 : Reward =  -3761.774405479431\n",
      "Episode  1672 : Reward =  -3849.0940574443953\n",
      "Episode  1673 : Reward =  -3828.5862309336662\n",
      "Episode  1674 : Reward =  -3830.326433837414\n",
      "Episode  1675 : Reward =  -3869.1155011690275\n",
      "Episode  1676 : Reward =  -3750.881788134575\n",
      "Episode  1677 : Reward =  -3643.483703136444\n",
      "Episode  1678 : Reward =  -3690.0701543775904\n",
      "Episode  1679 : Reward =  -3700.0306113362312\n",
      "Episode  1680 : Reward =  -3684.715842604637\n",
      "Episode  1681 : Reward =  -3699.666499376297\n",
      "Episode  1682 : Reward =  -3717.054839015007\n",
      "Episode  1683 : Reward =  -3870.928990960121\n",
      "Episode  1684 : Reward =  -3688.5266467928886\n",
      "Episode  1685 : Reward =  -3843.0205910889013\n",
      "Episode  1686 : Reward =  -3827.030929449858\n",
      "Episode  1687 : Reward =  -3640.201294306578\n",
      "Episode  1688 : Reward =  -3767.405385017395\n",
      "Episode  1689 : Reward =  -3816.7514396942274\n",
      "Episode  1690 : Reward =  -3819.22576802969\n",
      "Episode  1691 : Reward =  -3778.816525641741\n",
      "Episode  1692 : Reward =  -3764.208427786827\n",
      "Episode  1693 : Reward =  -3734.7034052646773\n",
      "Episode  1694 : Reward =  -3737.8752024173737\n",
      "Episode  1695 : Reward =  -3673.9995169639587\n",
      "Episode  1696 : Reward =  -3781.5641909241676\n",
      "Episode  1697 : Reward =  -3660.1399096250534\n",
      "Episode  1698 : Reward =  -3713.3161082863808\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.33\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1699 : Reward =  -3663.644250035286\n",
      "Episode  1700 : Reward =  -3824.0548335313797\n",
      "Episode  1701 : Reward =  -3657.947166800499\n",
      "Episode  1702 : Reward =  -3884.777875432144\n",
      "Episode  1703 : Reward =  -3704.5352197885513\n",
      "Episode  1704 : Reward =  -3725.5014464855194\n",
      "Episode  1705 : Reward =  -3710.3694044387953\n",
      "Episode  1706 : Reward =  -3823.8017417788506\n",
      "Episode  1707 : Reward =  -3856.3479154706\n",
      "Episode  1708 : Reward =  -3751.0656933784485\n",
      "Episode  1709 : Reward =  -3757.546376892696\n",
      "Episode  1710 : Reward =  -3611.1063522696495\n",
      "Episode  1711 : Reward =  -3799.025732576847\n",
      "Episode  1712 : Reward =  -3793.9636563149793\n",
      "Episode  1713 : Reward =  -3824.8253964818136\n",
      "Episode  1714 : Reward =  -3775.1874675526424\n",
      "Episode  1715 : Reward =  -3806.865637365641\n",
      "Episode  1716 : Reward =  -3799.0177175439017\n",
      "Episode  1717 : Reward =  -3802.4225838780403\n",
      "Episode  1718 : Reward =  -3880.4743633270264\n",
      "Episode  1719 : Reward =  -3770.2401036024094\n",
      "Episode  1720 : Reward =  -3995.5516873089177\n",
      "Episode  1721 : Reward =  -3845.6132033467293\n",
      "Episode  1722 : Reward =  -3870.3970629013197\n",
      "Episode  1723 : Reward =  -3721.343746840954\n",
      "Episode  1724 : Reward =  -3718.9225056207792\n",
      "Episode  1725 : Reward =  -3715.2268743515015\n",
      "Episode  1726 : Reward =  -3740.86791908741\n",
      "Episode  1727 : Reward =  -3684.9708688259125\n",
      "Episode  1728 : Reward =  -3738.914708617987\n",
      "Episode  1729 : Reward =  -3778.9423970616476\n",
      "Episode  1730 : Reward =  -3759.862662911415\n",
      "Episode  1731 : Reward =  -3735.8841119408607\n",
      "Episode  1732 : Reward =  -3647.3064217939186\n",
      "Episode  1733 : Reward =  -3784.413080695929\n",
      "Episode  1734 : Reward =  -3785.9567791223526\n",
      "Episode  1735 : Reward =  -3765.5938177471103\n",
      "Episode  1736 : Reward =  -3655.8697956204414\n",
      "Episode  1737 : Reward =  -3750.5735276937485\n",
      "Episode  1738 : Reward =  -3882.543330797325\n",
      "Episode  1739 : Reward =  -3708.3593968153\n",
      "Episode  1740 : Reward =  -3636.164350518356\n",
      "Episode  1741 : Reward =  -3636.495743215084\n",
      "Episode  1742 : Reward =  -3786.9154263734818\n",
      "Episode  1743 : Reward =  -3771.958882666105\n",
      "Episode  1744 : Reward =  -3785.7828458583967\n",
      "Episode  1745 : Reward =  -3855.028976202011\n",
      "Episode  1746 : Reward =  -3817.355181336403\n",
      "Episode  1747 : Reward =  -3707.4619381427765\n",
      "Episode  1748 : Reward =  -3669.4164079514844\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.325\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1749 : Reward =  -3745.5525254011154\n",
      "Episode  1750 : Reward =  -3666.195589900017\n",
      "Episode  1751 : Reward =  -3763.219062805176\n",
      "Episode  1752 : Reward =  -3942.2808567881584\n",
      "Episode  1753 : Reward =  -3855.413082718849\n",
      "Episode  1754 : Reward =  -3775.313033401966\n",
      "Episode  1755 : Reward =  -3845.1499994397163\n",
      "Episode  1756 : Reward =  -3761.26574242115\n",
      "Episode  1757 : Reward =  -3923.1805363297462\n",
      "Episode  1758 : Reward =  -3781.192152619362\n",
      "Episode  1759 : Reward =  -3818.150606215\n",
      "Episode  1760 : Reward =  -3965.9034249186516\n",
      "Episode  1761 : Reward =  -3797.8884125351906\n",
      "Episode  1762 : Reward =  -3979.4380281007902\n",
      "Episode  1763 : Reward =  -3818.8149006962776\n",
      "Episode  1764 : Reward =  -3874.2863218188286\n",
      "Episode  1765 : Reward =  -3813.8893552422523\n",
      "Episode  1766 : Reward =  -4124.821645951237\n",
      "Episode  1767 : Reward =  -3810.3096846342087\n",
      "Episode  1768 : Reward =  -3900.1742766535895\n",
      "Episode  1769 : Reward =  -3842.484907153906\n",
      "Episode  1770 : Reward =  -3997.2807794213295\n",
      "Episode  1771 : Reward =  -3979.267534617247\n",
      "Episode  1772 : Reward =  -3732.9847488999367\n",
      "Episode  1773 : Reward =  -3798.803712785244\n",
      "Episode  1774 : Reward =  -3822.890956401825\n",
      "Episode  1775 : Reward =  -3923.0529500842094\n",
      "Episode  1776 : Reward =  -3915.843817651272\n",
      "Episode  1777 : Reward =  -3812.6612335443497\n",
      "Episode  1778 : Reward =  -3813.363667190075\n",
      "Episode  1779 : Reward =  -3724.4181774258614\n",
      "Episode  1780 : Reward =  -3835.184235751629\n",
      "Episode  1781 : Reward =  -3796.7201862335205\n",
      "Episode  1782 : Reward =  -3827.864119052887\n",
      "Episode  1783 : Reward =  -3897.634271029295\n",
      "Episode  1784 : Reward =  -3666.3828715085983\n",
      "Episode  1785 : Reward =  -3753.6293743252754\n",
      "Episode  1786 : Reward =  -3796.972926080227\n",
      "Episode  1787 : Reward =  -3810.870950102806\n",
      "Episode  1788 : Reward =  -3634.7250187397003\n",
      "Episode  1789 : Reward =  -3837.6760449409485\n",
      "Episode  1790 : Reward =  -3759.0163910388947\n",
      "Episode  1791 : Reward =  -3828.9693283438683\n",
      "Episode  1792 : Reward =  -3782.96609210968\n",
      "Episode  1793 : Reward =  -3981.330306955944\n",
      "Episode  1794 : Reward =  -3736.8172307014465\n",
      "Episode  1795 : Reward =  -3848.431711021723\n",
      "Episode  1796 : Reward =  -3869.2576297557966\n",
      "Episode  1797 : Reward =  -3689.4067630171776\n",
      "Episode  1798 : Reward =  -3856.361058715643\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.32\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1799 : Reward =  -3718.2112672924995\n",
      "Episode  1800 : Reward =  -3875.2527741230147\n",
      "Episode  1801 : Reward =  -3838.1195069587843\n",
      "Episode  1802 : Reward =  -3847.7003847956657\n",
      "Episode  1803 : Reward =  -3815.4654812812805\n",
      "Episode  1804 : Reward =  -3952.825702548027\n",
      "Episode  1805 : Reward =  -3925.0115051305906\n",
      "Episode  1806 : Reward =  -3852.4173516631126\n",
      "Episode  1807 : Reward =  -3823.5425119400024\n",
      "Episode  1808 : Reward =  -3741.1778953671455\n",
      "Episode  1809 : Reward =  -3756.782653927803\n",
      "Episode  1810 : Reward =  -4114.307779320847\n",
      "Episode  1811 : Reward =  -3797.1758559942245\n",
      "Episode  1812 : Reward =  -3823.688925206661\n",
      "Episode  1813 : Reward =  -3813.4337755441666\n",
      "Episode  1814 : Reward =  -3772.775779545307\n",
      "Episode  1815 : Reward =  -4006.8348947763443\n",
      "Episode  1816 : Reward =  -3975.621280733408\n",
      "Episode  1817 : Reward =  -3823.9591211676598\n",
      "Episode  1818 : Reward =  -3768.797580897808\n",
      "Episode  1819 : Reward =  -3924.889705002308\n",
      "Episode  1820 : Reward =  -3742.2201946377754\n",
      "Episode  1821 : Reward =  -3880.9807019233704\n",
      "Episode  1822 : Reward =  -4045.937605146231\n",
      "Episode  1823 : Reward =  -3896.2826849854605\n",
      "Episode  1824 : Reward =  -3883.8915679454803\n",
      "Episode  1825 : Reward =  -3842.109261572361\n",
      "Episode  1826 : Reward =  -3791.6616950035095\n",
      "Episode  1827 : Reward =  -3957.359146062197\n",
      "Episode  1828 : Reward =  -3674.9195581674576\n",
      "Episode  1829 : Reward =  -3588.808041214943\n",
      "Episode  1830 : Reward =  -3665.393709719181\n",
      "Episode  1831 : Reward =  -3781.4319628477097\n",
      "Episode  1832 : Reward =  -3873.735038101673\n",
      "Episode  1833 : Reward =  -3957.8622009158134\n",
      "Episode  1834 : Reward =  -3934.394533046852\n",
      "Episode  1835 : Reward =  -3658.692183792591\n",
      "Episode  1836 : Reward =  -3827.70079010725\n",
      "Episode  1837 : Reward =  -3747.0468175411224\n",
      "Episode  1838 : Reward =  -3708.035821080208\n",
      "Episode  1839 : Reward =  -3803.545324806036\n",
      "Episode  1840 : Reward =  -3590.020868718624\n",
      "Episode  1841 : Reward =  -3900.1969100869314\n",
      "Episode  1842 : Reward =  -3799.5746192968504\n",
      "Episode  1843 : Reward =  -3815.195272541517\n",
      "Episode  1844 : Reward =  -3711.22532248497\n",
      "Episode  1845 : Reward =  -3698.6774920225143\n",
      "Episode  1846 : Reward =  -3730.5387253165245\n",
      "Episode  1847 : Reward =  -3624.945730984211\n",
      "Episode  1848 : Reward =  -3674.3029978871346\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.315\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1849 : Reward =  -3850.9044593572617\n",
      "Episode  1850 : Reward =  -3868.850908705364\n",
      "Episode  1851 : Reward =  -3847.1778093612807\n",
      "Episode  1852 : Reward =  -3568.7474185824394\n",
      "Episode  1853 : Reward =  -3706.439138829708\n",
      "Episode  1854 : Reward =  -3819.471958935261\n",
      "Episode  1855 : Reward =  -3745.6649364829063\n",
      "Episode  1856 : Reward =  -3920.902851053844\n",
      "Episode  1857 : Reward =  -3919.819613882671\n",
      "Episode  1858 : Reward =  -3694.6957433223724\n",
      "Episode  1859 : Reward =  -3891.2261394945485\n",
      "Episode  1860 : Reward =  -3941.9773767356814\n",
      "Episode  1861 : Reward =  -3801.994493484497\n",
      "Episode  1862 : Reward =  -3681.5776714086533\n",
      "Episode  1863 : Reward =  -3639.4118827581406\n",
      "Episode  1864 : Reward =  -3701.370711147785\n",
      "Episode  1865 : Reward =  -3886.2538572636945\n",
      "Episode  1866 : Reward =  -3903.627099040808\n",
      "Episode  1867 : Reward =  -3933.893503788771\n",
      "Episode  1868 : Reward =  -3983.875254034996\n",
      "Episode  1869 : Reward =  -3843.970283150673\n",
      "Episode  1870 : Reward =  -3928.3854304130955\n",
      "Episode  1871 : Reward =  -3967.0572410312993\n",
      "Episode  1872 : Reward =  -3791.3290402925627\n",
      "Episode  1873 : Reward =  -3820.7769714681012\n",
      "Episode  1874 : Reward =  -4012.0516613758223\n",
      "Episode  1875 : Reward =  -3938.9660859144346\n",
      "Episode  1876 : Reward =  -3693.217097043991\n",
      "Episode  1877 : Reward =  -3651.8938336372375\n",
      "Episode  1878 : Reward =  -3782.2802061525686\n",
      "Episode  1879 : Reward =  -3878.581935712467\n",
      "Episode  1880 : Reward =  -3782.840921141128\n",
      "Episode  1881 : Reward =  -3689.91737562418\n",
      "Episode  1882 : Reward =  -3970.1358213511808\n",
      "Episode  1883 : Reward =  -3833.707072082819\n",
      "Episode  1884 : Reward =  -3890.2134354114532\n",
      "Episode  1885 : Reward =  -3737.3039613962173\n",
      "Episode  1886 : Reward =  -3863.6786971775396\n",
      "Episode  1887 : Reward =  -3691.400655630888\n",
      "Episode  1888 : Reward =  -3785.659074127674\n",
      "Episode  1889 : Reward =  -3723.564186811447\n",
      "Episode  1890 : Reward =  -3659.210406780243\n",
      "Episode  1891 : Reward =  -3831.7676857709885\n",
      "Episode  1892 : Reward =  -3813.7585079445644\n",
      "Episode  1893 : Reward =  -3860.929571688175\n",
      "Episode  1894 : Reward =  -3891.3826674222946\n",
      "Episode  1895 : Reward =  -3840.4683292359705\n",
      "Episode  1896 : Reward =  -3760.7994858388843\n",
      "Episode  1897 : Reward =  -3865.9552862644196\n",
      "Episode  1898 : Reward =  -3817.771182302298\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.31\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1899 : Reward =  -3785.3645915425436\n",
      "Episode  1900 : Reward =  -3861.418934473167\n",
      "Episode  1901 : Reward =  -3761.170342564583\n",
      "Episode  1902 : Reward =  -3830.016440964216\n",
      "Episode  1903 : Reward =  -3660.1714941859245\n",
      "Episode  1904 : Reward =  -3710.9426144361496\n",
      "Episode  1905 : Reward =  -3817.9073493567807\n",
      "Episode  1906 : Reward =  -3736.3545458999974\n",
      "Episode  1907 : Reward =  -3698.147586621265\n",
      "Episode  1908 : Reward =  -3773.337889853777\n",
      "Episode  1909 : Reward =  -3746.0986390485573\n",
      "Episode  1910 : Reward =  -3702.719385389151\n",
      "Episode  1911 : Reward =  -3706.6967757344246\n",
      "Episode  1912 : Reward =  -3640.3126887715475\n",
      "Episode  1913 : Reward =  -3867.7087529749274\n",
      "Episode  1914 : Reward =  -3862.340945184231\n",
      "Episode  1915 : Reward =  -3730.0793976783752\n",
      "Episode  1916 : Reward =  -3765.9724354184286\n",
      "Episode  1917 : Reward =  -3711.380618695082\n",
      "Episode  1918 : Reward =  -3788.0326323871554\n",
      "Episode  1919 : Reward =  -3620.8654147982597\n",
      "Episode  1920 : Reward =  -3847.5935543215887\n",
      "Episode  1921 : Reward =  -3694.9601954221725\n",
      "Episode  1922 : Reward =  -3755.4378362930433\n",
      "Episode  1923 : Reward =  -3708.8948473696655\n",
      "Episode  1924 : Reward =  -3703.5759667605753\n",
      "Episode  1925 : Reward =  -3691.5169116034313\n",
      "Episode  1926 : Reward =  -3685.8820065259933\n",
      "Episode  1927 : Reward =  -3809.2006438461644\n",
      "Episode  1928 : Reward =  -3662.6266964673996\n",
      "Episode  1929 : Reward =  -3826.615501821041\n",
      "Episode  1930 : Reward =  -3783.8055421201097\n",
      "Episode  1931 : Reward =  -3653.144928762089\n",
      "Episode  1932 : Reward =  -3674.417125940323\n",
      "Episode  1933 : Reward =  -3589.5622804164886\n",
      "Episode  1934 : Reward =  -3685.244299054146\n",
      "Episode  1935 : Reward =  -3589.2773931622505\n",
      "Episode  1936 : Reward =  -3573.648272339167\n",
      "Episode  1937 : Reward =  -3780.6888402700424\n",
      "Episode  1938 : Reward =  -3653.031823992729\n",
      "Episode  1939 : Reward =  -3732.0013281478687\n",
      "Episode  1940 : Reward =  -3792.4991878954274\n",
      "Episode  1941 : Reward =  -3612.402157366276\n",
      "Episode  1942 : Reward =  -3729.0214859247208\n",
      "Episode  1943 : Reward =  -3720.934194687666\n",
      "Episode  1944 : Reward =  -3661.035371610294\n",
      "Episode  1945 : Reward =  -3623.4379891753197\n",
      "Episode  1946 : Reward =  -3515.700218617916\n",
      "Episode  1947 : Reward =  -3713.0948405117388\n",
      "Episode  1948 : Reward =  -3800.689689016813\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.305\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1949 : Reward =  -3771.4275516954763\n",
      "Episode  1950 : Reward =  -3637.951392874181\n",
      "Episode  1951 : Reward =  -3740.503549337387\n",
      "Episode  1952 : Reward =  -3856.707942971359\n",
      "Episode  1953 : Reward =  -3810.4735520257755\n",
      "Episode  1954 : Reward =  -3800.509800621639\n",
      "Episode  1955 : Reward =  -3803.4573886246085\n",
      "Episode  1956 : Reward =  -3775.798508409323\n",
      "Episode  1957 : Reward =  -3835.449263164173\n",
      "Episode  1958 : Reward =  -3663.6119871139526\n",
      "Episode  1959 : Reward =  -3877.3443115986006\n",
      "Episode  1960 : Reward =  -3882.642893910408\n",
      "Episode  1961 : Reward =  -3816.033257842064\n",
      "Episode  1962 : Reward =  -3650.4888385534286\n",
      "Episode  1963 : Reward =  -3720.6814152002335\n",
      "Episode  1964 : Reward =  -3647.4486722386496\n",
      "Episode  1965 : Reward =  -3552.4010425806046\n",
      "Episode  1966 : Reward =  -3756.5273814833777\n",
      "Episode  1967 : Reward =  -3660.9485345482826\n",
      "Episode  1968 : Reward =  -3735.540951260696\n",
      "Episode  1969 : Reward =  -3890.5979790774686\n",
      "Episode  1970 : Reward =  -3714.954853061499\n",
      "Episode  1971 : Reward =  -3660.219965338707\n",
      "Episode  1972 : Reward =  -3673.1290287462575\n",
      "Episode  1973 : Reward =  -3734.95606136322\n",
      "Episode  1974 : Reward =  -3784.6206196633684\n",
      "Episode  1975 : Reward =  -3818.440480419765\n",
      "Episode  1976 : Reward =  -3820.8011121190207\n",
      "Episode  1977 : Reward =  -3648.325727168383\n",
      "Episode  1978 : Reward =  -3643.342658162117\n",
      "Episode  1979 : Reward =  -3693.4973464608192\n",
      "Episode  1980 : Reward =  -3943.615239147009\n",
      "Episode  1981 : Reward =  -3696.882617354393\n",
      "Episode  1982 : Reward =  -3727.3813211917877\n",
      "Episode  1983 : Reward =  -3883.650498751463\n",
      "Episode  1984 : Reward =  -3792.23790371418\n",
      "Episode  1985 : Reward =  -3714.8900738954544\n",
      "Episode  1986 : Reward =  -3709.2805281913893\n",
      "Episode  1987 : Reward =  -3613.3828036872255\n",
      "Episode  1988 : Reward =  -3773.7413316369057\n",
      "Episode  1989 : Reward =  -3771.3480403795047\n",
      "Episode  1990 : Reward =  -3693.9451974630356\n",
      "Episode  1991 : Reward =  -4035.535350629459\n",
      "Episode  1992 : Reward =  -3850.909917417826\n",
      "Episode  1993 : Reward =  -3828.8827228546143\n",
      "Episode  1994 : Reward =  -3856.0084414569246\n",
      "Episode  1995 : Reward =  -3796.577709981571\n",
      "Episode  1996 : Reward =  -3851.8845188617706\n",
      "Episode  1997 : Reward =  -3843.051263097586\n",
      "Episode  1998 : Reward =  -3741.1014208197594\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.3\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  1999 : Reward =  -3860.451402667822\n",
      "Episode  2000 : Reward =  -3824.928511418323\n",
      "Episode  2001 : Reward =  -3952.003219732414\n",
      "Episode  2002 : Reward =  -3762.5266363657133\n",
      "Episode  2003 : Reward =  -3969.421846330166\n",
      "Episode  2004 : Reward =  -3827.2528167999403\n",
      "Episode  2005 : Reward =  -3826.508970439434\n",
      "Episode  2006 : Reward =  -3857.9588136672974\n",
      "Episode  2007 : Reward =  -3822.9156128168106\n",
      "Episode  2008 : Reward =  -3829.1741029024124\n",
      "Episode  2009 : Reward =  -3784.172993659973\n",
      "Episode  2010 : Reward =  -3890.757246673107\n",
      "Episode  2011 : Reward =  -3836.7868743625986\n",
      "Episode  2012 : Reward =  -3731.793050467968\n",
      "Episode  2013 : Reward =  -3866.277743577957\n",
      "Episode  2014 : Reward =  -3850.6134063005447\n",
      "Episode  2015 : Reward =  -3864.640904668631\n",
      "Episode  2016 : Reward =  -3642.4346486330032\n",
      "Episode  2017 : Reward =  -3744.8642785549164\n",
      "Episode  2018 : Reward =  -4031.9925468564034\n",
      "Episode  2019 : Reward =  -3847.4955792427063\n",
      "Episode  2020 : Reward =  -3813.161478734488\n",
      "Episode  2021 : Reward =  -3966.060321453871\n",
      "Episode  2022 : Reward =  -3949.660343948664\n",
      "Episode  2023 : Reward =  -3875.447573542595\n",
      "Episode  2024 : Reward =  -4060.6835146037442\n",
      "Episode  2025 : Reward =  -3949.788874813686\n",
      "Episode  2026 : Reward =  -3928.87514936924\n",
      "Episode  2027 : Reward =  -3907.9494681445462\n",
      "Episode  2028 : Reward =  -3933.9412717259543\n",
      "Episode  2029 : Reward =  -3863.9241045153753\n",
      "Episode  2030 : Reward =  -3893.894563922058\n",
      "Episode  2031 : Reward =  -3728.8121519088745\n",
      "Episode  2032 : Reward =  -3696.730893611908\n",
      "Episode  2033 : Reward =  -3820.0508655905724\n",
      "Episode  2034 : Reward =  -3866.4012824980123\n",
      "Episode  2035 : Reward =  -3816.31935650474\n",
      "Episode  2036 : Reward =  -3990.3743202090263\n",
      "Episode  2037 : Reward =  -3840.9490200056835\n",
      "Episode  2038 : Reward =  -3851.411469641985\n",
      "Episode  2039 : Reward =  -3915.3821796265943\n",
      "Episode  2040 : Reward =  -3944.492931195866\n",
      "Episode  2041 : Reward =  -3861.2539939284325\n",
      "Episode  2042 : Reward =  -3917.208720088005\n",
      "Episode  2043 : Reward =  -4032.814566973509\n",
      "Episode  2044 : Reward =  -3927.468451265158\n",
      "Episode  2045 : Reward =  -4026.1953461170197\n",
      "Episode  2046 : Reward =  -3842.8496231473105\n",
      "Episode  2047 : Reward =  -4040.6882020322187\n",
      "Episode  2048 : Reward =  -3853.370199803175\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.295\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2049 : Reward =  -3760.04884493351\n",
      "Episode  2050 : Reward =  -3867.6094383969116\n",
      "Episode  2051 : Reward =  -4081.2464427984373\n",
      "Episode  2052 : Reward =  -4019.7387134208484\n",
      "Episode  2053 : Reward =  -3998.865283612074\n",
      "Episode  2054 : Reward =  -3964.37079757452\n",
      "Episode  2055 : Reward =  -3832.603570461273\n",
      "Episode  2056 : Reward =  -3850.275642756285\n",
      "Episode  2057 : Reward =  -3878.6193379250867\n",
      "Episode  2058 : Reward =  -3806.4461196660995\n",
      "Episode  2059 : Reward =  -3986.584374550642\n",
      "Episode  2060 : Reward =  -3600.473569393158\n",
      "Episode  2061 : Reward =  -3868.7663380503654\n",
      "Episode  2062 : Reward =  -3728.37896538652\n",
      "Episode  2063 : Reward =  -3896.8290809429304\n",
      "Episode  2064 : Reward =  -3785.604751530947\n",
      "Episode  2065 : Reward =  -3619.126462817192\n",
      "Episode  2066 : Reward =  -3917.5219633666384\n",
      "Episode  2067 : Reward =  -3787.3614278435707\n",
      "Episode  2068 : Reward =  -3768.5886081544263\n",
      "Episode  2069 : Reward =  -3553.8043470978737\n",
      "Episode  2070 : Reward =  -3892.55545390016\n",
      "Episode  2071 : Reward =  -3719.493620157242\n",
      "Episode  2072 : Reward =  -3716.624231815338\n",
      "Episode  2073 : Reward =  -3939.288300514221\n",
      "Episode  2074 : Reward =  -3981.8604230321066\n",
      "Episode  2075 : Reward =  -3984.1148482597487\n",
      "Episode  2076 : Reward =  -3821.2722553697927\n",
      "Episode  2077 : Reward =  -3894.854125508438\n",
      "Episode  2078 : Reward =  -3797.339299738407\n",
      "Episode  2079 : Reward =  -3794.591034054756\n",
      "Episode  2080 : Reward =  -3943.717760626139\n",
      "Episode  2081 : Reward =  -3733.7287652864266\n",
      "Episode  2082 : Reward =  -3938.850268304348\n",
      "Episode  2083 : Reward =  -3985.4249338507652\n",
      "Episode  2084 : Reward =  -3743.8089776671545\n",
      "Episode  2085 : Reward =  -3824.131714761257\n",
      "Episode  2086 : Reward =  -3726.768856406212\n",
      "Episode  2087 : Reward =  -3882.5841846241756\n",
      "Episode  2088 : Reward =  -4079.5623143947737\n",
      "Episode  2089 : Reward =  -3708.5093134641647\n",
      "Episode  2090 : Reward =  -3768.7314151525497\n",
      "Episode  2091 : Reward =  -3628.6282769441605\n",
      "Episode  2092 : Reward =  -3607.3548696041107\n",
      "Episode  2093 : Reward =  -3758.0268498659134\n",
      "Episode  2094 : Reward =  -3838.474976126017\n",
      "Episode  2095 : Reward =  -3839.2519826380117\n",
      "Episode  2096 : Reward =  -3769.3696956038475\n",
      "Episode  2097 : Reward =  -4003.819259831081\n",
      "Episode  2098 : Reward =  -3656.982373714447\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.29\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2099 : Reward =  -3740.155524432659\n",
      "Episode  2100 : Reward =  -3820.1409395337105\n",
      "Episode  2101 : Reward =  -3738.4035591483116\n",
      "Episode  2102 : Reward =  -3774.4821433461325\n",
      "Episode  2103 : Reward =  -3662.615279138088\n",
      "Episode  2104 : Reward =  -3728.935595992865\n",
      "Episode  2105 : Reward =  -3855.687118891539\n",
      "Episode  2106 : Reward =  -3719.0604197382927\n",
      "Episode  2107 : Reward =  -3691.532442510128\n",
      "Episode  2108 : Reward =  -3885.3393951094763\n",
      "Episode  2109 : Reward =  -3826.0910807339055\n",
      "Episode  2110 : Reward =  -3784.6749513185637\n",
      "Episode  2111 : Reward =  -3865.7716736829893\n",
      "Episode  2112 : Reward =  -3799.9810701048987\n",
      "Episode  2113 : Reward =  -3777.994358219127\n",
      "Episode  2114 : Reward =  -3670.6021584272385\n",
      "Episode  2115 : Reward =  -3874.0206771529333\n",
      "Episode  2116 : Reward =  -3606.5117062330246\n",
      "Episode  2117 : Reward =  -3915.5230678356306\n",
      "Episode  2118 : Reward =  -3751.2207390106337\n",
      "Episode  2119 : Reward =  -3737.1983540654182\n",
      "Episode  2120 : Reward =  -3636.4376995003836\n",
      "Episode  2121 : Reward =  -3627.013209883036\n",
      "Episode  2122 : Reward =  -3777.838308572769\n",
      "Episode  2123 : Reward =  -3722.2877772486822\n",
      "Episode  2124 : Reward =  -3766.5210165157123\n",
      "Episode  2125 : Reward =  -3657.271596852602\n",
      "Episode  2126 : Reward =  -3838.4982113278525\n",
      "Episode  2127 : Reward =  -3549.763535205187\n",
      "Episode  2128 : Reward =  -3683.6653400435252\n",
      "Episode  2129 : Reward =  -3835.721746746363\n",
      "Episode  2130 : Reward =  -3673.8699915445463\n",
      "Episode  2131 : Reward =  -3625.2056564179766\n",
      "Episode  2132 : Reward =  -3594.6008830432834\n",
      "Episode  2133 : Reward =  -3621.7240929043905\n",
      "Episode  2134 : Reward =  -3688.9919738805906\n",
      "Episode  2135 : Reward =  -3609.416251182556\n",
      "Episode  2136 : Reward =  -3800.5611555016653\n",
      "Episode  2137 : Reward =  -3573.712676882744\n",
      "Episode  2138 : Reward =  -3673.0973052418844\n",
      "Episode  2139 : Reward =  -3710.4581490159035\n",
      "Episode  2140 : Reward =  -3806.3554080165045\n",
      "Episode  2141 : Reward =  -3741.431856393814\n",
      "Episode  2142 : Reward =  -3645.0572624206543\n",
      "Episode  2143 : Reward =  -3554.052648103708\n",
      "Episode  2144 : Reward =  -3649.9816459417343\n",
      "Episode  2145 : Reward =  -3623.1714318431036\n",
      "Episode  2146 : Reward =  -3556.8000380396843\n",
      "Episode  2147 : Reward =  -3666.318419456482\n",
      "Episode  2148 : Reward =  -3674.3240094817297\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.285\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2149 : Reward =  -3579.5795882344246\n",
      "Episode  2150 : Reward =  -3720.0535263455527\n",
      "Episode  2151 : Reward =  -3758.2565963304655\n",
      "Episode  2152 : Reward =  -3404.137964248657\n",
      "Saving better model at episode 2152 with reward -3404.137964248657\n",
      "Episode  2153 : Reward =  -3722.7886122465134\n",
      "Episode  2154 : Reward =  -3617.594006896019\n",
      "Episode  2155 : Reward =  -3432.2739985585213\n",
      "Episode  2156 : Reward =  -3660.376906491737\n",
      "Episode  2157 : Reward =  -3611.7663258946554\n",
      "Episode  2158 : Reward =  -3588.0830485907895\n",
      "Episode  2159 : Reward =  -3639.1953784823418\n",
      "Episode  2160 : Reward =  -3717.6377178430557\n",
      "Episode  2161 : Reward =  -3744.4746352521283\n",
      "Episode  2162 : Reward =  -3600.5915715694427\n",
      "Episode  2163 : Reward =  -3612.4440561532974\n",
      "Episode  2164 : Reward =  -3461.8884781599045\n",
      "Episode  2165 : Reward =  -3376.3343724012375\n",
      "Saving better model at episode 2165 with reward -3376.3343724012375\n",
      "Episode  2166 : Reward =  -3477.9819948113577\n",
      "Episode  2167 : Reward =  -3634.517509698868\n",
      "Episode  2168 : Reward =  -3527.8114309398043\n",
      "Episode  2169 : Reward =  -3607.064896175037\n",
      "Episode  2170 : Reward =  -3459.477742113094\n",
      "Episode  2171 : Reward =  -3346.989917933941\n",
      "Saving better model at episode 2171 with reward -3346.989917933941\n",
      "Episode  2172 : Reward =  -3432.48388081789\n",
      "Episode  2173 : Reward =  -3520.5984528101103\n",
      "Episode  2174 : Reward =  -3396.131226837635\n",
      "Episode  2175 : Reward =  -3333.8558560050146\n",
      "Saving better model at episode 2175 with reward -3333.8558560050146\n",
      "Episode  2176 : Reward =  -3479.4960807649004\n",
      "Episode  2177 : Reward =  -3385.8270741192205\n",
      "Episode  2178 : Reward =  -3421.652733564377\n",
      "Episode  2179 : Reward =  -3512.364144810806\n",
      "Episode  2180 : Reward =  -3306.864513644348\n",
      "Saving better model at episode 2180 with reward -3306.864513644348\n",
      "Episode  2181 : Reward =  -3566.608763492579\n",
      "Episode  2182 : Reward =  -3258.649897813797\n",
      "Saving better model at episode 2182 with reward -3258.649897813797\n",
      "Episode  2183 : Reward =  -3410.490117017092\n",
      "Episode  2184 : Reward =  -3490.450958732428\n",
      "Episode  2185 : Reward =  -3298.955411709766\n",
      "Episode  2186 : Reward =  -3379.913400658737\n",
      "Episode  2187 : Reward =  -3315.516446173191\n",
      "Episode  2188 : Reward =  -3230.952606320381\n",
      "Saving better model at episode 2188 with reward -3230.952606320381\n",
      "Episode  2189 : Reward =  -3379.1265445984022\n",
      "Episode  2190 : Reward =  -3474.8483437895775\n",
      "Episode  2191 : Reward =  -3364.59147387743\n",
      "Episode  2192 : Reward =  -3421.1624250448363\n",
      "Episode  2193 : Reward =  -3411.334672931494\n",
      "Episode  2194 : Reward =  -3351.073603395285\n",
      "Episode  2195 : Reward =  -3375.1741219758987\n",
      "Episode  2196 : Reward =  -3360.441858712496\n",
      "Episode  2197 : Reward =  -3471.428397420706\n",
      "Episode  2198 : Reward =  -3449.795861542225\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.28\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2199 : Reward =  -3315.9154867566244\n",
      "Episode  2200 : Reward =  -3237.447255253792\n",
      "Episode  2201 : Reward =  -3367.2459809184074\n",
      "Episode  2202 : Reward =  -3351.4828049576895\n",
      "Episode  2203 : Reward =  -3541.3099755085127\n",
      "Episode  2204 : Reward =  -3251.2782829999924\n",
      "Episode  2205 : Reward =  -3180.1852778196335\n",
      "Saving better model at episode 2205 with reward -3180.1852778196335\n",
      "Episode  2206 : Reward =  -3507.4670992865367\n",
      "Episode  2207 : Reward =  -3350.8360956682964\n",
      "Episode  2208 : Reward =  -3161.88080483675\n",
      "Saving better model at episode 2208 with reward -3161.88080483675\n",
      "Episode  2209 : Reward =  -3053.1226157546043\n",
      "Saving better model at episode 2209 with reward -3053.1226157546043\n",
      "Episode  2210 : Reward =  -3433.18471253282\n",
      "Episode  2211 : Reward =  -3194.130658093752\n",
      "Episode  2212 : Reward =  -3122.064119875431\n",
      "Episode  2213 : Reward =  -3252.64592897892\n",
      "Episode  2214 : Reward =  -3270.2166798114777\n",
      "Episode  2215 : Reward =  -3300.221445776443\n",
      "Episode  2216 : Reward =  -3331.468954149546\n",
      "Episode  2217 : Reward =  -3015.8892829418182\n",
      "Saving better model at episode 2217 with reward -3015.8892829418182\n",
      "Episode  2218 : Reward =  -3316.7925627267973\n",
      "Episode  2219 : Reward =  -3185.2828306592123\n",
      "Episode  2220 : Reward =  -3342.1354250944273\n",
      "Episode  2221 : Reward =  -3335.104129590015\n",
      "Episode  2222 : Reward =  -3127.164728049101\n",
      "Episode  2223 : Reward =  -3135.1728965080397\n",
      "Episode  2224 : Reward =  -3428.035271767439\n",
      "Episode  2225 : Reward =  -3255.43065649271\n",
      "Episode  2226 : Reward =  -3300.6828031911655\n",
      "Episode  2227 : Reward =  -3300.366057995619\n",
      "Episode  2228 : Reward =  -3304.331750342022\n",
      "Episode  2229 : Reward =  -3295.952179945926\n",
      "Episode  2230 : Reward =  -3363.366760611534\n",
      "Episode  2231 : Reward =  -3386.548154720436\n",
      "Episode  2232 : Reward =  -3279.1875742440166\n",
      "Episode  2233 : Reward =  -3305.6823031306267\n",
      "Episode  2234 : Reward =  -3319.653544664383\n",
      "Episode  2235 : Reward =  -3294.5742092728615\n",
      "Episode  2236 : Reward =  -3332.226819038391\n",
      "Episode  2237 : Reward =  -3342.9029493098205\n",
      "Episode  2238 : Reward =  -3359.2406178153174\n",
      "Episode  2239 : Reward =  -3449.982776746213\n",
      "Episode  2240 : Reward =  -3199.6050896048546\n",
      "Episode  2241 : Reward =  -3252.9093946305616\n",
      "Episode  2242 : Reward =  -3368.7796204461856\n",
      "Episode  2243 : Reward =  -3260.976948687206\n",
      "Episode  2244 : Reward =  -3501.0731850266457\n",
      "Episode  2245 : Reward =  -3599.7815048273487\n",
      "Episode  2246 : Reward =  -3460.3755256620752\n",
      "Episode  2247 : Reward =  -3502.5524134076254\n",
      "Episode  2248 : Reward =  -3387.9141951203346\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.275\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2249 : Reward =  -3412.4912428855896\n",
      "Episode  2250 : Reward =  -3514.19668841362\n",
      "Episode  2251 : Reward =  -3445.775399092497\n",
      "Episode  2252 : Reward =  -3538.2858018911497\n",
      "Episode  2253 : Reward =  -3395.906323969364\n",
      "Episode  2254 : Reward =  -3485.774900831203\n",
      "Episode  2255 : Reward =  -3425.192918896675\n",
      "Episode  2256 : Reward =  -3470.665160394186\n",
      "Episode  2257 : Reward =  -3440.9401245153563\n",
      "Episode  2258 : Reward =  -3411.4499729908125\n",
      "Episode  2259 : Reward =  -3490.504923650394\n",
      "Episode  2260 : Reward =  -3365.168570045294\n",
      "Episode  2261 : Reward =  -3284.0317965745926\n",
      "Episode  2262 : Reward =  -3361.945245862007\n",
      "Episode  2263 : Reward =  -3294.6534671783447\n",
      "Episode  2264 : Reward =  -3443.6748964822905\n",
      "Episode  2265 : Reward =  -3558.60669911779\n",
      "Episode  2266 : Reward =  -3506.2845513857023\n",
      "Episode  2267 : Reward =  -3293.3327642679214\n",
      "Episode  2268 : Reward =  -3382.6426100171225\n",
      "Episode  2269 : Reward =  -3338.902665504585\n",
      "Episode  2270 : Reward =  -3441.816962301731\n",
      "Episode  2271 : Reward =  -3297.709258019924\n",
      "Episode  2272 : Reward =  -3317.80917561418\n",
      "Episode  2273 : Reward =  -3543.9843280351774\n",
      "Episode  2274 : Reward =  -3339.3524661660194\n",
      "Episode  2275 : Reward =  -3448.157147385101\n",
      "Episode  2276 : Reward =  -3269.3039183703763\n",
      "Episode  2277 : Reward =  -3395.972022775473\n",
      "Episode  2278 : Reward =  -3364.4329444206373\n",
      "Episode  2279 : Reward =  -3281.5137496590614\n",
      "Episode  2280 : Reward =  -3467.321573950271\n",
      "Episode  2281 : Reward =  -3439.7072268760817\n",
      "Episode  2282 : Reward =  -3529.2580139040947\n",
      "Episode  2283 : Reward =  -3349.5668624726636\n",
      "Episode  2284 : Reward =  -3394.3310544490814\n",
      "Episode  2285 : Reward =  -3311.4862236828203\n",
      "Episode  2286 : Reward =  -3441.554673561226\n",
      "Episode  2287 : Reward =  -3414.578576806845\n",
      "Episode  2288 : Reward =  -3355.631900433363\n",
      "Episode  2289 : Reward =  -3310.1516128778458\n",
      "Episode  2290 : Reward =  -3343.288900613785\n",
      "Episode  2291 : Reward =  -3282.0231410861015\n",
      "Episode  2292 : Reward =  -3321.48574757576\n",
      "Episode  2293 : Reward =  -3441.349546376528\n",
      "Episode  2294 : Reward =  -3221.7118189930916\n",
      "Episode  2295 : Reward =  -3417.0213238596916\n",
      "Episode  2296 : Reward =  -3457.544814802627\n",
      "Episode  2297 : Reward =  -3538.145090583624\n",
      "Episode  2298 : Reward =  -3460.728680798183\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.27\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2299 : Reward =  -3336.3411961197853\n",
      "Episode  2300 : Reward =  -3468.3230195641518\n",
      "Episode  2301 : Reward =  -3472.117983464064\n",
      "Episode  2302 : Reward =  -3497.3608937859535\n",
      "Episode  2303 : Reward =  -3315.92306548357\n",
      "Episode  2304 : Reward =  -3484.772604295383\n",
      "Episode  2305 : Reward =  -3538.36647731937\n",
      "Episode  2306 : Reward =  -3307.9066812992096\n",
      "Episode  2307 : Reward =  -3322.186489343643\n",
      "Episode  2308 : Reward =  -3324.9612584114075\n",
      "Episode  2309 : Reward =  -3496.3247867909777\n",
      "Episode  2310 : Reward =  -3380.9978326930805\n",
      "Episode  2311 : Reward =  -3339.8541149533407\n",
      "Episode  2312 : Reward =  -3460.6038513816015\n",
      "Episode  2313 : Reward =  -3408.946104232134\n",
      "Episode  2314 : Reward =  -3389.560798406601\n",
      "Episode  2315 : Reward =  -3533.701080000872\n",
      "Episode  2316 : Reward =  -3354.551256597042\n",
      "Episode  2317 : Reward =  -3483.9519898978574\n",
      "Episode  2318 : Reward =  -3468.5489487051964\n",
      "Episode  2319 : Reward =  -3537.927333034496\n",
      "Episode  2320 : Reward =  -3250.961941897869\n",
      "Episode  2321 : Reward =  -3387.5595468878746\n",
      "Episode  2322 : Reward =  -3281.080789268017\n",
      "Episode  2323 : Reward =  -3330.2876133322716\n",
      "Episode  2324 : Reward =  -3441.7302013075964\n",
      "Episode  2325 : Reward =  -3371.370696902275\n",
      "Episode  2326 : Reward =  -3397.655943751335\n",
      "Episode  2327 : Reward =  -3387.996333602728\n",
      "Episode  2328 : Reward =  -3262.0243914163725\n",
      "Episode  2329 : Reward =  -3373.641796115698\n",
      "Episode  2330 : Reward =  -3130.2322081923485\n",
      "Episode  2331 : Reward =  -3474.1420057452337\n",
      "Episode  2332 : Reward =  -3333.698220142494\n",
      "Episode  2333 : Reward =  -3485.8845677462923\n",
      "Episode  2334 : Reward =  -3364.7832924163954\n",
      "Episode  2335 : Reward =  -3496.4527720808983\n",
      "Episode  2336 : Reward =  -3440.7626547253744\n",
      "Episode  2337 : Reward =  -3468.370926865707\n",
      "Episode  2338 : Reward =  -3259.411408305168\n",
      "Episode  2339 : Reward =  -3409.2710322178023\n",
      "Episode  2340 : Reward =  -3429.74345266819\n",
      "Episode  2341 : Reward =  -3325.040505230427\n",
      "Episode  2342 : Reward =  -3519.0428819692747\n",
      "Episode  2343 : Reward =  -3412.7998575604574\n",
      "Episode  2344 : Reward =  -3510.6281756162643\n",
      "Episode  2345 : Reward =  -3427.692836109461\n",
      "Episode  2346 : Reward =  -3391.6783555782454\n",
      "Episode  2347 : Reward =  -3367.419700658793\n",
      "Episode  2348 : Reward =  -3489.9079126119614\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.265\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2349 : Reward =  -3333.8338968194143\n",
      "Episode  2350 : Reward =  -3439.787360016169\n",
      "Episode  2351 : Reward =  -3577.6082710710866\n",
      "Episode  2352 : Reward =  -3531.2736220396177\n",
      "Episode  2353 : Reward =  -3378.6186595595495\n",
      "Episode  2354 : Reward =  -3347.410978257656\n",
      "Episode  2355 : Reward =  -3371.821765780449\n",
      "Episode  2356 : Reward =  -3420.476532522501\n",
      "Episode  2357 : Reward =  -3393.7732291817665\n",
      "Episode  2358 : Reward =  -3432.9217220544815\n",
      "Episode  2359 : Reward =  -3534.034941378893\n",
      "Episode  2360 : Reward =  -3414.4603529063565\n",
      "Episode  2361 : Reward =  -3509.243730723858\n",
      "Episode  2362 : Reward =  -3529.6132910847664\n",
      "Episode  2363 : Reward =  -3465.2582362330572\n",
      "Episode  2364 : Reward =  -3380.5837228385312\n",
      "Episode  2365 : Reward =  -3570.247997411858\n",
      "Episode  2366 : Reward =  -3448.977724313736\n",
      "Episode  2367 : Reward =  -3486.0905877947807\n",
      "Episode  2368 : Reward =  -3237.5445027947426\n",
      "Episode  2369 : Reward =  -3449.954038921656\n",
      "Episode  2370 : Reward =  -3479.180430117907\n",
      "Episode  2371 : Reward =  -3428.11001765728\n",
      "Episode  2372 : Reward =  -3394.566517829895\n",
      "Episode  2373 : Reward =  -3232.8796447515488\n",
      "Episode  2374 : Reward =  -3368.0669263005257\n",
      "Episode  2375 : Reward =  -3383.0968031287193\n",
      "Episode  2376 : Reward =  -3413.047259513201\n",
      "Episode  2377 : Reward =  -3516.0562750188215\n",
      "Episode  2378 : Reward =  -3349.0485553741455\n",
      "Episode  2379 : Reward =  -3370.4830732381956\n",
      "Episode  2380 : Reward =  -3466.3592861890793\n",
      "Episode  2381 : Reward =  -3354.5946591532843\n",
      "Episode  2382 : Reward =  -3400.1168152777063\n",
      "Episode  2383 : Reward =  -3322.9210246801376\n",
      "Episode  2384 : Reward =  -3441.598335210146\n",
      "Episode  2385 : Reward =  -3330.446544408798\n",
      "Episode  2386 : Reward =  -3494.9042094436986\n",
      "Episode  2387 : Reward =  -3441.355745736422\n",
      "Episode  2388 : Reward =  -3442.708257082762\n",
      "Episode  2389 : Reward =  -3354.0356037653105\n",
      "Episode  2390 : Reward =  -3423.946244418621\n",
      "Episode  2391 : Reward =  -3410.0081763267517\n",
      "Episode  2392 : Reward =  -3550.7177333868162\n",
      "Episode  2393 : Reward =  -3399.908074259758\n",
      "Episode  2394 : Reward =  -3440.1237417546613\n",
      "Episode  2395 : Reward =  -3441.426518145861\n",
      "Episode  2396 : Reward =  -3457.0143252647536\n",
      "Episode  2397 : Reward =  -3542.5418197512627\n",
      "Episode  2398 : Reward =  -3438.4280288851874\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.26\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2399 : Reward =  -3506.2602418661118\n",
      "Episode  2400 : Reward =  -3708.1221344320684\n",
      "Episode  2401 : Reward =  -3396.0313539505005\n",
      "Episode  2402 : Reward =  -3579.5809865681035\n",
      "Episode  2403 : Reward =  -3452.0072130051954\n",
      "Episode  2404 : Reward =  -3498.6686862794263\n",
      "Episode  2405 : Reward =  -3437.6442529559135\n",
      "Episode  2406 : Reward =  -3413.371472064318\n",
      "Episode  2407 : Reward =  -3363.0743734872954\n",
      "Episode  2408 : Reward =  -3395.9490857720375\n",
      "Episode  2409 : Reward =  -3581.0848171151297\n",
      "Episode  2410 : Reward =  -3533.8485717773438\n",
      "Episode  2411 : Reward =  -3500.0152422276838\n",
      "Episode  2412 : Reward =  -3546.057591918768\n",
      "Episode  2413 : Reward =  -3417.279695335688\n",
      "Episode  2414 : Reward =  -3355.137883603573\n",
      "Episode  2415 : Reward =  -3465.8969870209694\n",
      "Episode  2416 : Reward =  -3480.3012970722334\n",
      "Episode  2417 : Reward =  -3754.265690669289\n",
      "Episode  2418 : Reward =  -3607.8736825585365\n",
      "Episode  2419 : Reward =  -3485.8376681295736\n",
      "Episode  2420 : Reward =  -3488.9138158596174\n",
      "Episode  2421 : Reward =  -3350.5084512233734\n",
      "Episode  2422 : Reward =  -3326.5178062319756\n",
      "Episode  2423 : Reward =  -3493.806352142157\n",
      "Episode  2424 : Reward =  -3524.821767091751\n",
      "Episode  2425 : Reward =  -3491.62857554006\n",
      "Episode  2426 : Reward =  -3478.820120581757\n",
      "Episode  2427 : Reward =  -3428.1468705534935\n",
      "Episode  2428 : Reward =  -3372.1415886319296\n",
      "Episode  2429 : Reward =  -3484.3026324510574\n",
      "Episode  2430 : Reward =  -3516.98713309444\n",
      "Episode  2431 : Reward =  -3365.0066142714636\n",
      "Episode  2432 : Reward =  -3571.0929010286136\n",
      "Episode  2433 : Reward =  -3528.409083136688\n",
      "Episode  2434 : Reward =  -3465.0156259303035\n",
      "Episode  2435 : Reward =  -3549.331888437271\n",
      "Episode  2436 : Reward =  -3599.462344178329\n",
      "Episode  2437 : Reward =  -3353.096189022064\n",
      "Episode  2438 : Reward =  -3497.7900936603546\n",
      "Episode  2439 : Reward =  -3416.54562997818\n",
      "Episode  2440 : Reward =  -3446.997710443954\n",
      "Episode  2441 : Reward =  -3395.2528662717955\n",
      "Episode  2442 : Reward =  -3460.1467664837837\n",
      "Episode  2443 : Reward =  -3327.6813839114325\n",
      "Episode  2444 : Reward =  -3453.27265346414\n",
      "Episode  2445 : Reward =  -3481.5907141938014\n",
      "Episode  2446 : Reward =  -3478.06904065609\n",
      "Episode  2447 : Reward =  -3485.5756761431694\n",
      "Episode  2448 : Reward =  -3450.328337073326\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.255\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2449 : Reward =  -3432.9065327135427\n",
      "Episode  2450 : Reward =  -3501.9394867507326\n",
      "Episode  2451 : Reward =  -3389.2649902192456\n",
      "Episode  2452 : Reward =  -3530.2507291436195\n",
      "Episode  2453 : Reward =  -3415.6170260310173\n",
      "Episode  2454 : Reward =  -3509.4737885630743\n",
      "Episode  2455 : Reward =  -3443.1043323874474\n",
      "Episode  2456 : Reward =  -3293.396217226982\n",
      "Episode  2457 : Reward =  -3332.533605992794\n",
      "Episode  2458 : Reward =  -3531.001769963564\n",
      "Episode  2459 : Reward =  -3348.785296320915\n",
      "Episode  2460 : Reward =  -3582.797175705433\n",
      "Episode  2461 : Reward =  -3711.0265841931696\n",
      "Episode  2462 : Reward =  -3383.1945185748446\n",
      "Episode  2463 : Reward =  -3352.1577454209328\n",
      "Episode  2464 : Reward =  -3364.3190885818617\n",
      "Episode  2465 : Reward =  -3411.8976137404384\n",
      "Episode  2466 : Reward =  -3519.502368569374\n",
      "Episode  2467 : Reward =  -3433.4904533028603\n",
      "Episode  2468 : Reward =  -3465.574322053562\n",
      "Episode  2469 : Reward =  -3550.398618400097\n",
      "Episode  2470 : Reward =  -3399.6197471022606\n",
      "Episode  2471 : Reward =  -3297.808109678249\n",
      "Episode  2472 : Reward =  -3303.562967070709\n",
      "Episode  2473 : Reward =  -3436.338944554329\n",
      "Episode  2474 : Reward =  -3478.8501839637756\n",
      "Episode  2475 : Reward =  -3449.027114748955\n",
      "Episode  2476 : Reward =  -3580.195128083229\n",
      "Episode  2477 : Reward =  -3303.718096021475\n",
      "Episode  2478 : Reward =  -3494.3293944597244\n",
      "Episode  2479 : Reward =  -3495.4164729154722\n",
      "Episode  2480 : Reward =  -3272.312797188759\n",
      "Episode  2481 : Reward =  -3333.3099462389946\n",
      "Episode  2482 : Reward =  -3278.0671845674515\n",
      "Episode  2483 : Reward =  -3363.068775240244\n",
      "Episode  2484 : Reward =  -3497.60769916452\n",
      "Episode  2485 : Reward =  -3453.146857559681\n",
      "Episode  2486 : Reward =  -3340.385498523712\n",
      "Episode  2487 : Reward =  -3403.539572894573\n",
      "Episode  2488 : Reward =  -3377.023458778858\n",
      "Episode  2489 : Reward =  -3506.989380363287\n",
      "Episode  2490 : Reward =  -3429.109198987484\n",
      "Episode  2491 : Reward =  -3441.7753933668137\n",
      "Episode  2492 : Reward =  -3300.6070314645767\n",
      "Episode  2493 : Reward =  -3463.036390877241\n",
      "Episode  2494 : Reward =  -3515.9001919031143\n",
      "Episode  2495 : Reward =  -3485.23366945982\n",
      "Episode  2496 : Reward =  -3565.5202497839928\n",
      "Episode  2497 : Reward =  -3446.6326100826263\n",
      "Episode  2498 : Reward =  -3396.369770470919\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.25\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2499 : Reward =  -3184.5918380618095\n",
      "Episode  2500 : Reward =  -3362.5464235544205\n",
      "Episode  2501 : Reward =  -3296.113305091858\n",
      "Episode  2502 : Reward =  -3266.1287163496017\n",
      "Episode  2503 : Reward =  -3258.522268894972\n",
      "Episode  2504 : Reward =  -3239.279196444811\n",
      "Episode  2505 : Reward =  -3455.401067916216\n",
      "Episode  2506 : Reward =  -3333.335903171362\n",
      "Episode  2507 : Reward =  -3491.4449778199196\n",
      "Episode  2508 : Reward =  -3352.9999619722366\n",
      "Episode  2509 : Reward =  -3394.28601012371\n",
      "Episode  2510 : Reward =  -3518.8531327843666\n",
      "Episode  2511 : Reward =  -3591.6472151727075\n",
      "Episode  2512 : Reward =  -3271.946460965933\n",
      "Episode  2513 : Reward =  -3496.5392207590444\n",
      "Episode  2514 : Reward =  -3294.912140671076\n",
      "Episode  2515 : Reward =  -3622.5082570314407\n",
      "Episode  2516 : Reward =  -3320.387146357359\n",
      "Episode  2517 : Reward =  -3549.009631872177\n",
      "Episode  2518 : Reward =  -3775.024506732881\n",
      "Episode  2519 : Reward =  -3213.273616978298\n",
      "Episode  2520 : Reward =  -3253.5638337135315\n",
      "Episode  2521 : Reward =  -3349.413863250385\n",
      "Episode  2522 : Reward =  -3510.8125011324883\n",
      "Episode  2523 : Reward =  -3548.475594341755\n",
      "Episode  2524 : Reward =  -3237.985238671303\n",
      "Episode  2525 : Reward =  -3279.2270070997583\n",
      "Episode  2526 : Reward =  -3285.5530977881567\n",
      "Episode  2527 : Reward =  -3363.2308379411697\n",
      "Episode  2528 : Reward =  -3519.168095588684\n",
      "Episode  2529 : Reward =  -3333.9608737266676\n",
      "Episode  2530 : Reward =  -3402.3285678625107\n",
      "Episode  2531 : Reward =  -3688.4433699846268\n",
      "Episode  2532 : Reward =  -3671.243052482605\n",
      "Episode  2533 : Reward =  -3598.627917408943\n",
      "Episode  2534 : Reward =  -3706.9651924967766\n",
      "Episode  2535 : Reward =  -3675.625310599804\n",
      "Episode  2536 : Reward =  -3656.678634941578\n",
      "Episode  2537 : Reward =  -3636.798096358776\n",
      "Episode  2538 : Reward =  -3581.2849942445755\n",
      "Episode  2539 : Reward =  -3578.9296844005585\n",
      "Episode  2540 : Reward =  -3457.7780243754387\n",
      "Episode  2541 : Reward =  -3513.800006687641\n",
      "Episode  2542 : Reward =  -3537.154412508011\n",
      "Episode  2543 : Reward =  -3511.7018545866013\n",
      "Episode  2544 : Reward =  -3415.91537630558\n",
      "Episode  2545 : Reward =  -3484.0552369131847\n",
      "Episode  2546 : Reward =  -3326.214960757555\n",
      "Episode  2547 : Reward =  -3718.481989622116\n",
      "Episode  2548 : Reward =  -3495.9703791737556\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.245\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2549 : Reward =  -3546.2033487558365\n",
      "Episode  2550 : Reward =  -3634.8830165863037\n",
      "Episode  2551 : Reward =  -3354.6007297075407\n",
      "Episode  2552 : Reward =  -3710.5150359869003\n",
      "Episode  2553 : Reward =  -3380.7645716667175\n",
      "Episode  2554 : Reward =  -3523.4033025539534\n",
      "Episode  2555 : Reward =  -3272.768834710121\n",
      "Episode  2556 : Reward =  -3673.149144411087\n",
      "Episode  2557 : Reward =  -3413.019128203392\n",
      "Episode  2558 : Reward =  -3226.895114339809\n",
      "Episode  2559 : Reward =  -3557.239967226982\n",
      "Episode  2560 : Reward =  -3606.567336022854\n",
      "Episode  2561 : Reward =  -3467.177794703613\n",
      "Episode  2562 : Reward =  -3417.7077423966543\n",
      "Episode  2563 : Reward =  -3432.8091813101573\n",
      "Episode  2564 : Reward =  -3287.0038559808536\n",
      "Episode  2565 : Reward =  -3477.6327029553754\n",
      "Episode  2566 : Reward =  -3233.500764787197\n",
      "Episode  2567 : Reward =  -3323.1217227949905\n",
      "Episode  2568 : Reward =  -3107.628137946129\n",
      "Episode  2569 : Reward =  -3561.264098227024\n",
      "Episode  2570 : Reward =  -3192.0905690789223\n",
      "Episode  2571 : Reward =  -3174.418463885784\n",
      "Episode  2572 : Reward =  -3584.32412225008\n",
      "Episode  2573 : Reward =  -3303.742761973204\n",
      "Episode  2574 : Reward =  -3279.3124499320984\n",
      "Episode  2575 : Reward =  -3307.3656952156825\n",
      "Episode  2576 : Reward =  -3341.387679911131\n",
      "Episode  2577 : Reward =  -3461.338556179176\n",
      "Episode  2578 : Reward =  -3178.7102655208723\n",
      "Episode  2579 : Reward =  -3343.46205205089\n",
      "Episode  2580 : Reward =  -3408.1685815489905\n",
      "Episode  2581 : Reward =  -3583.230132997036\n",
      "Episode  2582 : Reward =  -3208.9096339381354\n",
      "Episode  2583 : Reward =  -3223.213048160076\n",
      "Episode  2584 : Reward =  -3549.628417491913\n",
      "Episode  2585 : Reward =  -3194.394296292128\n",
      "Episode  2586 : Reward =  -3603.908306602301\n",
      "Episode  2587 : Reward =  -3458.904680618416\n",
      "Episode  2588 : Reward =  -3612.1098887324333\n",
      "Episode  2589 : Reward =  -3437.6318098939078\n",
      "Episode  2590 : Reward =  -3344.943161070347\n",
      "Episode  2591 : Reward =  -3638.2915282845497\n",
      "Episode  2592 : Reward =  -3400.930438998999\n",
      "Episode  2593 : Reward =  -3303.508105456829\n",
      "Episode  2594 : Reward =  -3348.997414895664\n",
      "Episode  2595 : Reward =  -3343.8867056406157\n",
      "Episode  2596 : Reward =  -3560.225289747178\n",
      "Episode  2597 : Reward =  -3665.966320037842\n",
      "Episode  2598 : Reward =  -3571.9744930267334\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.24\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2599 : Reward =  -3424.17541087545\n",
      "Episode  2600 : Reward =  -3457.9476079381125\n",
      "Episode  2601 : Reward =  -3444.697330657305\n",
      "Episode  2602 : Reward =  -3377.25021434194\n",
      "Episode  2603 : Reward =  -3412.6041616797447\n",
      "Episode  2604 : Reward =  -3434.350255250931\n",
      "Episode  2605 : Reward =  -3526.4933128356934\n",
      "Episode  2606 : Reward =  -3543.539380527014\n",
      "Episode  2607 : Reward =  -3602.7435107267515\n",
      "Episode  2608 : Reward =  -3591.1439707962377\n",
      "Episode  2609 : Reward =  -3393.6371921337263\n",
      "Episode  2610 : Reward =  -3481.764638400549\n",
      "Episode  2611 : Reward =  -3289.8934279716627\n",
      "Episode  2612 : Reward =  -3443.0142408385086\n",
      "Episode  2613 : Reward =  -3569.1704419255257\n",
      "Episode  2614 : Reward =  -3609.98311291641\n",
      "Episode  2615 : Reward =  -3461.034703195095\n",
      "Episode  2616 : Reward =  -3485.9147596359253\n",
      "Episode  2617 : Reward =  -3659.391818881035\n",
      "Episode  2618 : Reward =  -3634.3336731231825\n",
      "Episode  2619 : Reward =  -3645.8356173038483\n",
      "Episode  2620 : Reward =  -3465.7222133278847\n",
      "Episode  2621 : Reward =  -3611.6633000410216\n",
      "Episode  2622 : Reward =  -3500.6073381391866\n",
      "Episode  2623 : Reward =  -3352.747279945673\n",
      "Episode  2624 : Reward =  -3602.4809427348478\n",
      "Episode  2625 : Reward =  -3613.598316669464\n",
      "Episode  2626 : Reward =  -3581.2406022548676\n",
      "Episode  2627 : Reward =  -3526.2855129241943\n",
      "Episode  2628 : Reward =  -3623.2270252791745\n",
      "Episode  2629 : Reward =  -3474.9155458807945\n",
      "Episode  2630 : Reward =  -3707.6631955504417\n",
      "Episode  2631 : Reward =  -3355.9648034659726\n",
      "Episode  2632 : Reward =  -3728.3171380758286\n",
      "Episode  2633 : Reward =  -3439.7948934435844\n",
      "Episode  2634 : Reward =  -3417.2896041906492\n",
      "Episode  2635 : Reward =  -3423.060745605598\n",
      "Episode  2636 : Reward =  -3650.853530585766\n",
      "Episode  2637 : Reward =  -3509.785265505314\n",
      "Episode  2638 : Reward =  -3461.602903792034\n",
      "Episode  2639 : Reward =  -3522.0938344038145\n",
      "Episode  2640 : Reward =  -3554.841296195984\n",
      "Episode  2641 : Reward =  -3421.675667706789\n",
      "Episode  2642 : Reward =  -3528.168991509737\n",
      "Episode  2643 : Reward =  -3574.1495087742805\n",
      "Episode  2644 : Reward =  -3499.325209915638\n",
      "Episode  2645 : Reward =  -3485.8140751719475\n",
      "Episode  2646 : Reward =  -3526.2557550109045\n",
      "Episode  2647 : Reward =  -3475.10890263319\n",
      "Episode  2648 : Reward =  -3336.918208781542\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.235\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2649 : Reward =  -3372.897031132044\n",
      "Episode  2650 : Reward =  -3508.391665816307\n",
      "Episode  2651 : Reward =  -3454.291482034983\n",
      "Episode  2652 : Reward =  -3259.6864488720894\n",
      "Episode  2653 : Reward =  -3634.213141679764\n",
      "Episode  2654 : Reward =  -3519.470906087528\n",
      "Episode  2655 : Reward =  -3550.044827878475\n",
      "Episode  2656 : Reward =  -3535.585157752037\n",
      "Episode  2657 : Reward =  -3461.0321282744408\n",
      "Episode  2658 : Reward =  -3433.7114400863647\n",
      "Episode  2659 : Reward =  -3566.9745149612427\n",
      "Episode  2660 : Reward =  -3687.2946086525917\n",
      "Episode  2661 : Reward =  -3375.6009177005903\n",
      "Episode  2662 : Reward =  -3436.650398799549\n",
      "Episode  2663 : Reward =  -3621.2181019186974\n",
      "Episode  2664 : Reward =  -3375.9333715438843\n",
      "Episode  2665 : Reward =  -3314.667053580284\n",
      "Episode  2666 : Reward =  -3396.023477557959\n",
      "Episode  2667 : Reward =  -3521.03349506855\n",
      "Episode  2668 : Reward =  -3271.0451700127737\n",
      "Episode  2669 : Reward =  -3314.0511372685432\n",
      "Episode  2670 : Reward =  -3395.607250162731\n",
      "Episode  2671 : Reward =  -3226.847101904373\n",
      "Episode  2672 : Reward =  -3276.7289325957245\n",
      "Episode  2673 : Reward =  -3250.222928859215\n",
      "Episode  2674 : Reward =  -3424.530326999645\n",
      "Episode  2675 : Reward =  -3635.821265757084\n",
      "Episode  2676 : Reward =  -3452.3868746197836\n",
      "Episode  2677 : Reward =  -3332.888732589702\n",
      "Episode  2678 : Reward =  -3622.227250277996\n",
      "Episode  2679 : Reward =  -3142.5716798341887\n",
      "Episode  2680 : Reward =  -3189.2347534982073\n",
      "Episode  2681 : Reward =  -3140.0782775654598\n",
      "Episode  2682 : Reward =  -3649.0138157606125\n",
      "Episode  2683 : Reward =  -3502.49917400247\n",
      "Episode  2684 : Reward =  -3387.639894284229\n",
      "Episode  2685 : Reward =  -3400.179461658001\n",
      "Episode  2686 : Reward =  -3356.4002602732794\n",
      "Episode  2687 : Reward =  -3125.1769170201437\n",
      "Episode  2688 : Reward =  -3626.4134076833725\n",
      "Episode  2689 : Reward =  -3352.5985716072423\n",
      "Episode  2690 : Reward =  -3096.1915943658964\n",
      "Episode  2691 : Reward =  -3503.5103317586286\n",
      "Episode  2692 : Reward =  -3465.6277641654015\n",
      "Episode  2693 : Reward =  -3219.8515927791595\n",
      "Episode  2694 : Reward =  -3284.581025660038\n",
      "Episode  2695 : Reward =  -3240.406467982899\n",
      "Episode  2696 : Reward =  -3315.6165381757123\n",
      "Episode  2697 : Reward =  -3191.076966702938\n",
      "Episode  2698 : Reward =  -3313.4519143736975\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.23\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2699 : Reward =  -3490.950374606909\n",
      "Episode  2700 : Reward =  -3308.398393997322\n",
      "Episode  2701 : Reward =  -3547.956828121008\n",
      "Episode  2702 : Reward =  -3283.258962158026\n",
      "Episode  2703 : Reward =  -3535.39500105381\n",
      "Episode  2704 : Reward =  -3438.0952227748053\n",
      "Episode  2705 : Reward =  -3441.894665941655\n",
      "Episode  2706 : Reward =  -3303.225577775301\n",
      "Episode  2707 : Reward =  -3147.728913370432\n",
      "Episode  2708 : Reward =  -3210.459162570457\n",
      "Episode  2709 : Reward =  -3728.978703856468\n",
      "Episode  2710 : Reward =  -3730.47689473629\n",
      "Episode  2711 : Reward =  -3310.7195082393987\n",
      "Episode  2712 : Reward =  -3603.1138444309177\n",
      "Episode  2713 : Reward =  -3684.910478413105\n",
      "Episode  2714 : Reward =  -3218.131511665802\n",
      "Episode  2715 : Reward =  -3543.5104561448097\n",
      "Episode  2716 : Reward =  -3307.1661734021322\n",
      "Episode  2717 : Reward =  -3231.97559094429\n",
      "Episode  2718 : Reward =  -3712.8058508634567\n",
      "Episode  2719 : Reward =  -3318.283541390072\n",
      "Episode  2720 : Reward =  -3606.897233310999\n",
      "Episode  2721 : Reward =  -3439.3441108465195\n",
      "Episode  2722 : Reward =  -3194.2900926842494\n",
      "Episode  2723 : Reward =  -3576.279056373896\n",
      "Episode  2724 : Reward =  -3521.978250145912\n",
      "Episode  2725 : Reward =  -3134.240820232691\n",
      "Episode  2726 : Reward =  -3326.9493278636737\n",
      "Episode  2727 : Reward =  -3482.8156641162054\n",
      "Episode  2728 : Reward =  -3223.0889962402684\n",
      "Episode  2729 : Reward =  -3716.3280215859413\n",
      "Episode  2730 : Reward =  -3513.0151875986858\n",
      "Episode  2731 : Reward =  -3346.736216667952\n",
      "Episode  2732 : Reward =  -3201.636114701688\n",
      "Episode  2733 : Reward =  -3382.001637586723\n",
      "Episode  2734 : Reward =  -3713.7499812841415\n",
      "Episode  2735 : Reward =  -3182.140438079834\n",
      "Episode  2736 : Reward =  -3695.9125796556473\n",
      "Episode  2737 : Reward =  -3168.925178114237\n",
      "Episode  2738 : Reward =  -3231.7470233527524\n",
      "Episode  2739 : Reward =  -3708.296242058277\n",
      "Episode  2740 : Reward =  -3379.118051268081\n",
      "Episode  2741 : Reward =  -3635.2531958818436\n",
      "Episode  2742 : Reward =  -3054.425771240057\n",
      "Episode  2743 : Reward =  -3494.2285418510437\n",
      "Episode  2744 : Reward =  -3705.8594959378242\n",
      "Episode  2745 : Reward =  -3347.8188756108284\n",
      "Episode  2746 : Reward =  -3684.926465213299\n",
      "Episode  2747 : Reward =  -3309.5639427900314\n",
      "Episode  2748 : Reward =  -3290.6543998493953\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.225\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2749 : Reward =  -3566.8039541840553\n",
      "Episode  2750 : Reward =  -3517.704553726973\n",
      "Episode  2751 : Reward =  -3283.6493215051996\n",
      "Episode  2752 : Reward =  -3638.267917215824\n",
      "Episode  2753 : Reward =  -3343.0689680016653\n",
      "Episode  2754 : Reward =  -3428.20432097591\n",
      "Episode  2755 : Reward =  -3665.3561774492264\n",
      "Episode  2756 : Reward =  -3575.9146248698235\n",
      "Episode  2757 : Reward =  -3475.240628004074\n",
      "Episode  2758 : Reward =  -3485.24946975708\n",
      "Episode  2759 : Reward =  -3243.4332550168037\n",
      "Episode  2760 : Reward =  -3418.0217880372943\n",
      "Episode  2761 : Reward =  -3274.4226027167456\n",
      "Episode  2762 : Reward =  -3269.11224556333\n",
      "Episode  2763 : Reward =  -3350.1522019592626\n",
      "Episode  2764 : Reward =  -3426.440415620804\n",
      "Episode  2765 : Reward =  -3504.652471009554\n",
      "Episode  2766 : Reward =  -3279.6243022680283\n",
      "Episode  2767 : Reward =  -3550.098330795765\n",
      "Episode  2768 : Reward =  -3540.2733284235\n",
      "Episode  2769 : Reward =  -3502.8963900208473\n",
      "Episode  2770 : Reward =  -3526.150675177574\n",
      "Episode  2771 : Reward =  -3080.800949820648\n",
      "Episode  2772 : Reward =  -3147.0429834214556\n",
      "Episode  2773 : Reward =  -3252.5956126227184\n",
      "Episode  2774 : Reward =  -3501.2676638401167\n",
      "Episode  2775 : Reward =  -3322.6591877192855\n",
      "Episode  2776 : Reward =  -3298.008555269713\n",
      "Episode  2777 : Reward =  -3399.585161805153\n",
      "Episode  2778 : Reward =  -3239.671583775343\n",
      "Episode  2779 : Reward =  -3362.319898847403\n",
      "Episode  2780 : Reward =  -3392.8824780670507\n",
      "Episode  2781 : Reward =  -3299.484352473082\n",
      "Episode  2782 : Reward =  -3314.5839730872913\n",
      "Episode  2783 : Reward =  -3196.613794839853\n",
      "Episode  2784 : Reward =  -3469.93283867836\n",
      "Episode  2785 : Reward =  -3398.30419150638\n",
      "Episode  2786 : Reward =  -3310.313281416893\n",
      "Episode  2787 : Reward =  -3685.979215502739\n",
      "Episode  2788 : Reward =  -3576.202397584915\n",
      "Episode  2789 : Reward =  -3588.0906101465225\n",
      "Episode  2790 : Reward =  -3416.128086209297\n",
      "Episode  2791 : Reward =  -3334.451461791992\n",
      "Episode  2792 : Reward =  -3467.302160322666\n",
      "Episode  2793 : Reward =  -3586.666106402874\n",
      "Episode  2794 : Reward =  -3226.9240163055765\n",
      "Episode  2795 : Reward =  -3193.647210776806\n",
      "Episode  2796 : Reward =  -3428.895557943644\n",
      "Episode  2797 : Reward =  -3240.3327887094633\n",
      "Episode  2798 : Reward =  -3712.908859372139\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.22\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2799 : Reward =  -3461.717644814314\n",
      "Episode  2800 : Reward =  -3625.871686462225\n",
      "Episode  2801 : Reward =  -3561.967165648937\n",
      "Episode  2802 : Reward =  -3464.9780344738765\n",
      "Episode  2803 : Reward =  -3220.106892466545\n",
      "Episode  2804 : Reward =  -3435.1584049550397\n",
      "Episode  2805 : Reward =  -3570.3270568847656\n",
      "Episode  2806 : Reward =  -3617.967715382576\n",
      "Episode  2807 : Reward =  -3339.2721505536842\n",
      "Episode  2808 : Reward =  -3629.442831516266\n",
      "Episode  2809 : Reward =  -3724.8145623207092\n",
      "Episode  2810 : Reward =  -3725.356861948967\n",
      "Episode  2811 : Reward =  -3367.9641004291875\n",
      "Episode  2812 : Reward =  -3358.9507701248526\n",
      "Episode  2813 : Reward =  -3345.2216995358467\n",
      "Episode  2814 : Reward =  -3379.6911752820015\n",
      "Episode  2815 : Reward =  -3756.003945350647\n",
      "Episode  2816 : Reward =  -3302.475382813583\n",
      "Episode  2817 : Reward =  -3367.7731524146216\n",
      "Episode  2818 : Reward =  -3414.0615972280502\n",
      "Episode  2819 : Reward =  -3138.6912475264685\n",
      "Episode  2820 : Reward =  -3540.339975655079\n",
      "Episode  2821 : Reward =  -3436.4108897447586\n",
      "Episode  2822 : Reward =  -3755.316457390785\n",
      "Episode  2823 : Reward =  -3737.9795347452164\n",
      "Episode  2824 : Reward =  -3420.1343227028847\n",
      "Episode  2825 : Reward =  -3603.337900519371\n",
      "Episode  2826 : Reward =  -3252.0363593137877\n",
      "Episode  2827 : Reward =  -3867.6962171196938\n",
      "Episode  2828 : Reward =  -3374.9626648513186\n",
      "Episode  2829 : Reward =  -3277.58044517404\n",
      "Episode  2830 : Reward =  -3631.7884469628334\n",
      "Episode  2831 : Reward =  -3305.567171394825\n",
      "Episode  2832 : Reward =  -3611.5830181241035\n",
      "Episode  2833 : Reward =  -3678.7815348505974\n",
      "Episode  2834 : Reward =  -3696.8829513192177\n",
      "Episode  2835 : Reward =  -3352.500807825388\n",
      "Episode  2836 : Reward =  -3624.3265857696533\n",
      "Episode  2837 : Reward =  -3324.112202167511\n",
      "Episode  2838 : Reward =  -3494.5826874375343\n",
      "Episode  2839 : Reward =  -3683.8716576099396\n",
      "Episode  2840 : Reward =  -3722.629068493843\n",
      "Episode  2841 : Reward =  -3454.9302405802114\n",
      "Episode  2842 : Reward =  -3580.9415165222304\n",
      "Episode  2843 : Reward =  -3425.1535918152945\n",
      "Episode  2844 : Reward =  -3683.718151509762\n",
      "Episode  2845 : Reward =  -3297.675767544569\n",
      "Episode  2846 : Reward =  -3276.386376389633\n",
      "Episode  2847 : Reward =  -3756.600348651409\n",
      "Episode  2848 : Reward =  -3339.2859511411802\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.215\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2849 : Reward =  -3206.9187255353327\n",
      "Episode  2850 : Reward =  -3223.9511344519956\n",
      "Episode  2851 : Reward =  -3308.960452437401\n",
      "Episode  2852 : Reward =  -3369.9409336214007\n",
      "Episode  2853 : Reward =  -3164.0303441373217\n",
      "Episode  2854 : Reward =  -3451.735787510872\n",
      "Episode  2855 : Reward =  -3517.3321521878242\n",
      "Episode  2856 : Reward =  -3388.5941482782364\n",
      "Episode  2857 : Reward =  -3348.808966521086\n",
      "Episode  2858 : Reward =  -3297.738186005415\n",
      "Episode  2859 : Reward =  -3220.772763797413\n",
      "Episode  2860 : Reward =  -3683.876192688942\n",
      "Episode  2861 : Reward =  -3416.798601040016\n",
      "Episode  2862 : Reward =  -3604.159348666668\n",
      "Episode  2863 : Reward =  -3522.887908164324\n",
      "Episode  2864 : Reward =  -3711.290832877159\n",
      "Episode  2865 : Reward =  -3135.9137986985547\n",
      "Episode  2866 : Reward =  -3376.3902159929276\n",
      "Episode  2867 : Reward =  -3310.573871589178\n",
      "Episode  2868 : Reward =  -3307.02994001783\n",
      "Episode  2869 : Reward =  -3467.2603284156935\n",
      "Episode  2870 : Reward =  -3597.6231959462166\n",
      "Episode  2871 : Reward =  -3157.5069478837354\n",
      "Episode  2872 : Reward =  -3668.3596093654633\n",
      "Episode  2873 : Reward =  -3331.9543258547783\n",
      "Episode  2874 : Reward =  -3551.2484273997648\n",
      "Episode  2875 : Reward =  -3573.1015482035978\n",
      "Episode  2876 : Reward =  -3700.9434936642647\n",
      "Episode  2877 : Reward =  -3524.8560716596944\n",
      "Episode  2878 : Reward =  -3710.501055955887\n",
      "Episode  2879 : Reward =  -3233.9786878824234\n",
      "Episode  2880 : Reward =  -3173.4960818886757\n",
      "Episode  2881 : Reward =  -3361.9608217840137\n",
      "Episode  2882 : Reward =  -3661.0081275701523\n",
      "Episode  2883 : Reward =  -3587.2115916609764\n",
      "Episode  2884 : Reward =  -3525.203897961746\n",
      "Episode  2885 : Reward =  -3318.749717060389\n",
      "Episode  2886 : Reward =  -3638.017504930496\n",
      "Episode  2887 : Reward =  -3486.1581797451377\n",
      "Episode  2888 : Reward =  -3472.198561012745\n",
      "Episode  2889 : Reward =  -3185.4978334344046\n",
      "Episode  2890 : Reward =  -3602.2117414474487\n",
      "Episode  2891 : Reward =  -3488.5835621989386\n",
      "Episode  2892 : Reward =  -3669.55761448192\n",
      "Episode  2893 : Reward =  -3397.813847009005\n",
      "Episode  2894 : Reward =  -3309.0800404996276\n",
      "Episode  2895 : Reward =  -3639.16409188509\n",
      "Episode  2896 : Reward =  -3308.933997396292\n",
      "Episode  2897 : Reward =  -3278.09713149942\n",
      "Episode  2898 : Reward =  -3491.797279715538\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.21\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2899 : Reward =  -3626.223383307457\n",
      "Episode  2900 : Reward =  -3266.9198817647116\n",
      "Episode  2901 : Reward =  -3378.504320148291\n",
      "Episode  2902 : Reward =  -3310.273850032459\n",
      "Episode  2903 : Reward =  -3128.0917071191175\n",
      "Episode  2904 : Reward =  -3332.415865842165\n",
      "Episode  2905 : Reward =  -3260.0128522887035\n",
      "Episode  2906 : Reward =  -3231.387855538498\n",
      "Episode  2907 : Reward =  -3483.003633916378\n",
      "Episode  2908 : Reward =  -3461.163213133812\n",
      "Episode  2909 : Reward =  -3241.3485306873126\n",
      "Episode  2910 : Reward =  -3279.909969095053\n",
      "Episode  2911 : Reward =  -3468.390370854507\n",
      "Episode  2912 : Reward =  -3677.11672604084\n",
      "Episode  2913 : Reward =  -3497.293082535267\n",
      "Episode  2914 : Reward =  -3071.408183578314\n",
      "Episode  2915 : Reward =  -3476.425758012901\n",
      "Episode  2916 : Reward =  -3137.427354279818\n",
      "Episode  2917 : Reward =  -3134.833659052849\n",
      "Episode  2918 : Reward =  -3375.194197654724\n",
      "Episode  2919 : Reward =  -3730.409785926342\n",
      "Episode  2920 : Reward =  -3198.919799603443\n",
      "Episode  2921 : Reward =  -3447.2577978372574\n",
      "Episode  2922 : Reward =  -3275.6487300395966\n",
      "Episode  2923 : Reward =  -3193.7291306293623\n",
      "Episode  2924 : Reward =  -3154.0328279770033\n",
      "Episode  2925 : Reward =  -3394.2176297307014\n",
      "Episode  2926 : Reward =  -3182.332921329798\n",
      "Episode  2927 : Reward =  -3214.240808018814\n",
      "Episode  2928 : Reward =  -3099.5969211495535\n",
      "Episode  2929 : Reward =  -3339.377747774124\n",
      "Episode  2930 : Reward =  -3278.1636949181557\n",
      "Episode  2931 : Reward =  -3098.8027955976827\n",
      "Episode  2932 : Reward =  -3243.7523983157294\n",
      "Episode  2933 : Reward =  -3138.756002608599\n",
      "Episode  2934 : Reward =  -3091.0763092724187\n",
      "Episode  2935 : Reward =  -3305.689934316935\n",
      "Episode  2936 : Reward =  -3299.44339799881\n",
      "Episode  2937 : Reward =  -3224.693507262836\n",
      "Episode  2938 : Reward =  -3338.046339869499\n",
      "Episode  2939 : Reward =  -3199.7228444580974\n",
      "Episode  2940 : Reward =  -3366.1796165741102\n",
      "Episode  2941 : Reward =  -3325.369366058479\n",
      "Episode  2942 : Reward =  -3016.8509479201452\n",
      "Episode  2943 : Reward =  -3064.3209792375565\n",
      "Episode  2944 : Reward =  -3308.8076975381987\n",
      "Episode  2945 : Reward =  -3322.4513019695087\n",
      "Episode  2946 : Reward =  -3607.80667334795\n",
      "Episode  2947 : Reward =  -3423.284397546114\n",
      "Episode  2948 : Reward =  -3313.118533358037\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.205\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2949 : Reward =  -3587.022870361805\n",
      "Episode  2950 : Reward =  -3285.0013356245177\n",
      "Episode  2951 : Reward =  -3348.800355888824\n",
      "Episode  2952 : Reward =  -3328.24362114715\n",
      "Episode  2953 : Reward =  -3307.731050380836\n",
      "Episode  2954 : Reward =  -3359.068811484943\n",
      "Episode  2955 : Reward =  -3464.939020637335\n",
      "Episode  2956 : Reward =  -3291.343936897735\n",
      "Episode  2957 : Reward =  -3422.5744044955654\n",
      "Episode  2958 : Reward =  -3493.7044565677643\n",
      "Episode  2959 : Reward =  -3218.1700481772423\n",
      "Episode  2960 : Reward =  -3213.0326838855685\n",
      "Episode  2961 : Reward =  -3398.6288459300995\n",
      "Episode  2962 : Reward =  -3181.72404933847\n",
      "Episode  2963 : Reward =  -3308.8887355327606\n",
      "Episode  2964 : Reward =  -3249.5594373707713\n",
      "Episode  2965 : Reward =  -3227.7002338542743\n",
      "Episode  2966 : Reward =  -3150.8857906547887\n",
      "Episode  2967 : Reward =  -3215.465340256691\n",
      "Episode  2968 : Reward =  -3497.5434108376503\n",
      "Episode  2969 : Reward =  -3327.9468753709602\n",
      "Episode  2970 : Reward =  -3185.8476642370224\n",
      "Episode  2971 : Reward =  -3517.9379447459833\n",
      "Episode  2972 : Reward =  -3143.3600932359695\n",
      "Episode  2973 : Reward =  -3407.0225291027828\n",
      "Episode  2974 : Reward =  -3141.844996648638\n",
      "Episode  2975 : Reward =  -3253.0308306217194\n",
      "Episode  2976 : Reward =  -3289.395833492279\n",
      "Episode  2977 : Reward =  -3233.7328180111067\n",
      "Episode  2978 : Reward =  -3560.075762450695\n",
      "Episode  2979 : Reward =  -3375.9509198701994\n",
      "Episode  2980 : Reward =  -3948.307791718948\n",
      "Episode  2981 : Reward =  -3358.0637236833572\n",
      "Episode  2982 : Reward =  -3297.4181739775045\n",
      "Episode  2983 : Reward =  -3292.6632400751114\n",
      "Episode  2984 : Reward =  -3544.2270831502096\n",
      "Episode  2985 : Reward =  -3417.2552272081375\n",
      "Episode  2986 : Reward =  -3396.555641889572\n",
      "Episode  2987 : Reward =  -3489.27464145422\n",
      "Episode  2988 : Reward =  -3180.78955037273\n",
      "Episode  2989 : Reward =  -3315.3228232860565\n",
      "Episode  2990 : Reward =  -3367.6973217725754\n",
      "Episode  2991 : Reward =  -3210.377452112655\n",
      "Episode  2992 : Reward =  -3316.3647500128145\n",
      "Episode  2993 : Reward =  -3506.8217186927795\n",
      "Episode  2994 : Reward =  -3185.902330759825\n",
      "Episode  2995 : Reward =  -3164.3374833230914\n",
      "Episode  2996 : Reward =  -3244.5118623463018\n",
      "Episode  2997 : Reward =  -3165.288592461409\n",
      "Episode  2998 : Reward =  -3207.362767401995\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.2\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  2999 : Reward =  -3353.3663031310434\n",
      "Episode  3000 : Reward =  -3468.930671516718\n",
      "Episode  3001 : Reward =  -3289.483112871647\n",
      "Episode  3002 : Reward =  -3436.038298252882\n",
      "Episode  3003 : Reward =  -3357.5669873952866\n",
      "Episode  3004 : Reward =  -3134.368643641472\n",
      "Episode  3005 : Reward =  -3419.923352956772\n",
      "Episode  3006 : Reward =  -3403.198465117584\n",
      "Episode  3007 : Reward =  -3560.9904918670654\n",
      "Episode  3008 : Reward =  -3581.5721732378006\n",
      "Episode  3009 : Reward =  -3501.950607895851\n",
      "Episode  3010 : Reward =  -3299.433804282318\n",
      "Episode  3011 : Reward =  -3386.7308415174484\n",
      "Episode  3012 : Reward =  -3232.4043024778366\n",
      "Episode  3013 : Reward =  -3387.163906097412\n",
      "Episode  3014 : Reward =  -3281.028367880644\n",
      "Episode  3015 : Reward =  -3423.0006228089333\n",
      "Episode  3016 : Reward =  -3278.6020854115486\n",
      "Episode  3017 : Reward =  -3459.658847574057\n",
      "Episode  3018 : Reward =  -3330.8094395399094\n",
      "Episode  3019 : Reward =  -3454.314089000225\n",
      "Episode  3020 : Reward =  -3538.201809167862\n",
      "Episode  3021 : Reward =  -3356.9756863204343\n",
      "Episode  3022 : Reward =  -3398.3773604122503\n",
      "Episode  3023 : Reward =  -3590.1618698239326\n",
      "Episode  3024 : Reward =  -3403.5744320190565\n",
      "Episode  3025 : Reward =  -3261.8533061829908\n",
      "Episode  3026 : Reward =  -3514.1847615093584\n",
      "Episode  3027 : Reward =  -3468.1571859121323\n",
      "Episode  3028 : Reward =  -3198.0853949785233\n",
      "Episode  3029 : Reward =  -3206.203887439245\n",
      "Episode  3030 : Reward =  -3157.7582458023967\n",
      "Episode  3031 : Reward =  -3487.5266839948995\n",
      "Episode  3032 : Reward =  -3478.2730691432953\n",
      "Episode  3033 : Reward =  -3336.4942687749863\n",
      "Episode  3034 : Reward =  -3152.1110222376005\n",
      "Episode  3035 : Reward =  -3377.331505417824\n",
      "Episode  3036 : Reward =  -3347.2205027787595\n",
      "Episode  3037 : Reward =  -3525.563243008131\n",
      "Episode  3038 : Reward =  -3101.0263738719327\n",
      "Episode  3039 : Reward =  -3270.4996000304027\n",
      "Episode  3040 : Reward =  -3378.6925058216448\n",
      "Episode  3041 : Reward =  -3484.580829143524\n",
      "Episode  3042 : Reward =  -3267.419754031958\n",
      "Episode  3043 : Reward =  -3337.4962442368865\n",
      "Episode  3044 : Reward =  -3096.6227078204097\n",
      "Episode  3045 : Reward =  -3293.9215723312514\n",
      "Episode  3046 : Reward =  -3305.9504434502737\n",
      "Episode  3047 : Reward =  -3161.419658518309\n",
      "Episode  3048 : Reward =  -3197.380729261698\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.195\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3049 : Reward =  -3262.181155451904\n",
      "Episode  3050 : Reward =  -3299.255237340927\n",
      "Episode  3051 : Reward =  -3384.6093631834387\n",
      "Episode  3052 : Reward =  -3233.552298940639\n",
      "Episode  3053 : Reward =  -3297.314139664173\n",
      "Episode  3054 : Reward =  -3064.3372063673155\n",
      "Episode  3055 : Reward =  -3145.724971596064\n",
      "Episode  3056 : Reward =  -3304.15773586916\n",
      "Episode  3057 : Reward =  -3318.6731867194176\n",
      "Episode  3058 : Reward =  -3347.159492135048\n",
      "Episode  3059 : Reward =  -3225.4762051192624\n",
      "Episode  3060 : Reward =  -3161.9431875123782\n",
      "Episode  3061 : Reward =  -3418.891172683205\n",
      "Episode  3062 : Reward =  -3274.048642194742\n",
      "Episode  3063 : Reward =  -3935.6104015202404\n",
      "Episode  3064 : Reward =  -3302.6424381136894\n",
      "Episode  3065 : Reward =  -3384.326291060414\n",
      "Episode  3066 : Reward =  -3392.386616408825\n",
      "Episode  3067 : Reward =  -3158.1967355696065\n",
      "Episode  3068 : Reward =  -3155.186408258896\n",
      "Episode  3069 : Reward =  -3130.182146438728\n",
      "Episode  3070 : Reward =  -3152.1227149542256\n",
      "Episode  3071 : Reward =  -3488.750560462475\n",
      "Episode  3072 : Reward =  -3167.0318514195783\n",
      "Episode  3073 : Reward =  -3318.765601579012\n",
      "Episode  3074 : Reward =  -3384.647246424021\n",
      "Episode  3075 : Reward =  -3092.3946417745037\n",
      "Episode  3076 : Reward =  -3249.846586987436\n",
      "Episode  3077 : Reward =  -3244.8663984116\n",
      "Episode  3078 : Reward =  -3188.8976871458394\n",
      "Episode  3079 : Reward =  -3171.404276117554\n",
      "Episode  3080 : Reward =  -3276.417802274227\n",
      "Episode  3081 : Reward =  -3143.5818117036624\n",
      "Episode  3082 : Reward =  -3271.113012024532\n",
      "Episode  3083 : Reward =  -3115.4535427864475\n",
      "Episode  3084 : Reward =  -3142.0863665118027\n",
      "Episode  3085 : Reward =  -3147.7567260115056\n",
      "Episode  3086 : Reward =  -2987.1403191176755\n",
      "Saving better model at episode 3086 with reward -2987.1403191176755\n",
      "Episode  3087 : Reward =  -3063.7915933168547\n",
      "Episode  3088 : Reward =  -4014.64201993655\n",
      "Episode  3089 : Reward =  -3018.9101543192805\n",
      "Episode  3090 : Reward =  -3403.715205669403\n",
      "Episode  3091 : Reward =  -3441.079811811447\n",
      "Episode  3092 : Reward =  -3227.361522614956\n",
      "Episode  3093 : Reward =  -3203.013407624239\n",
      "Episode  3094 : Reward =  -3093.6661387718336\n",
      "Episode  3095 : Reward =  -3155.2421235529287\n",
      "Episode  3096 : Reward =  -3186.088316000919\n",
      "Episode  3097 : Reward =  -3343.863334417343\n",
      "Episode  3098 : Reward =  -3097.029953364195\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.19\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3099 : Reward =  -3307.97726461884\n",
      "Episode  3100 : Reward =  -3373.6691810249945\n",
      "Episode  3101 : Reward =  -3207.894762414305\n",
      "Episode  3102 : Reward =  -3082.764247453684\n",
      "Episode  3103 : Reward =  -3174.740993953222\n",
      "Episode  3104 : Reward =  -3136.763602146278\n",
      "Episode  3105 : Reward =  -3260.3739857449336\n",
      "Episode  3106 : Reward =  -3261.9329944427895\n",
      "Episode  3107 : Reward =  -3183.464691913599\n",
      "Episode  3108 : Reward =  -3146.2431361711638\n",
      "Episode  3109 : Reward =  -3235.710706926803\n",
      "Episode  3110 : Reward =  -3304.553198315124\n",
      "Episode  3111 : Reward =  -3314.8814802206175\n",
      "Episode  3112 : Reward =  -3149.3185756293637\n",
      "Episode  3113 : Reward =  -3269.188909567814\n",
      "Episode  3114 : Reward =  -3494.819269835949\n",
      "Episode  3115 : Reward =  -3308.4267290234566\n",
      "Episode  3116 : Reward =  -3333.375239908695\n",
      "Episode  3117 : Reward =  -3220.8528275861545\n",
      "Episode  3118 : Reward =  -3364.3446558117867\n",
      "Episode  3119 : Reward =  -3124.832533515911\n",
      "Episode  3120 : Reward =  -3526.0954285025255\n",
      "Episode  3121 : Reward =  -3325.9108079758985\n",
      "Episode  3122 : Reward =  -3435.4372777938843\n",
      "Episode  3123 : Reward =  -3373.2939461506026\n",
      "Episode  3124 : Reward =  -3323.01761674881\n",
      "Episode  3125 : Reward =  -3324.194152835669\n",
      "Episode  3126 : Reward =  -3407.6233741045\n",
      "Episode  3127 : Reward =  -3174.9354218876974\n",
      "Episode  3128 : Reward =  -3411.596744775772\n",
      "Episode  3129 : Reward =  -3365.0134260690825\n",
      "Episode  3130 : Reward =  -3343.465031005363\n",
      "Episode  3131 : Reward =  -3315.034116510214\n",
      "Episode  3132 : Reward =  -3260.2229832186504\n",
      "Episode  3133 : Reward =  -3207.392734238277\n",
      "Episode  3134 : Reward =  -3216.5216323820455\n",
      "Episode  3135 : Reward =  -3482.5381646752357\n",
      "Episode  3136 : Reward =  -3508.090296626091\n",
      "Episode  3137 : Reward =  -3384.394657350058\n",
      "Episode  3138 : Reward =  -3551.391147315502\n",
      "Episode  3139 : Reward =  -3510.3431557416916\n",
      "Episode  3140 : Reward =  -3448.2273955345154\n",
      "Episode  3141 : Reward =  -3138.2521886601253\n",
      "Episode  3142 : Reward =  -3406.8490427732468\n",
      "Episode  3143 : Reward =  -3302.6735221743584\n",
      "Episode  3144 : Reward =  -3140.096794072451\n",
      "Episode  3145 : Reward =  -3265.9944189823286\n",
      "Episode  3146 : Reward =  -3373.7086176872253\n",
      "Episode  3147 : Reward =  -3519.7250824927946\n",
      "Episode  3148 : Reward =  -3282.8632524609566\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.185\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3149 : Reward =  -3309.23614436388\n",
      "Episode  3150 : Reward =  -3161.8442780141772\n",
      "Episode  3151 : Reward =  -3441.618850827217\n",
      "Episode  3152 : Reward =  -3448.5204522013664\n",
      "Episode  3153 : Reward =  -3113.6190811395645\n",
      "Episode  3154 : Reward =  -3412.206754386425\n",
      "Episode  3155 : Reward =  -3465.2497286200523\n",
      "Episode  3156 : Reward =  -3328.480889260769\n",
      "Episode  3157 : Reward =  -3325.1250360012054\n",
      "Episode  3158 : Reward =  -3183.059826469893\n",
      "Episode  3159 : Reward =  -3084.7566421628\n",
      "Episode  3160 : Reward =  -3203.6572462916374\n",
      "Episode  3161 : Reward =  -3282.174408555031\n",
      "Episode  3162 : Reward =  -3368.2238523364067\n",
      "Episode  3163 : Reward =  -3458.9218578338623\n",
      "Episode  3164 : Reward =  -3415.68193590641\n",
      "Episode  3165 : Reward =  -3463.6120125055313\n",
      "Episode  3166 : Reward =  -3278.732562661171\n",
      "Episode  3167 : Reward =  -3262.6997331156535\n",
      "Episode  3168 : Reward =  -3179.9379119873047\n",
      "Episode  3169 : Reward =  -3423.4032629728317\n",
      "Episode  3170 : Reward =  -3171.1347026600642\n",
      "Episode  3171 : Reward =  -3415.631058692932\n",
      "Episode  3172 : Reward =  -3446.3575568199158\n",
      "Episode  3173 : Reward =  -3241.475867986679\n",
      "Episode  3174 : Reward =  -3329.439407646656\n",
      "Episode  3175 : Reward =  -3191.3367070927425\n",
      "Episode  3176 : Reward =  -3425.6539846658707\n",
      "Episode  3177 : Reward =  -3428.08395588398\n",
      "Episode  3178 : Reward =  -3484.8371888399124\n",
      "Episode  3179 : Reward =  -3491.0155956745148\n",
      "Episode  3180 : Reward =  -3404.4093408584595\n",
      "Episode  3181 : Reward =  -3156.747407913208\n",
      "Episode  3182 : Reward =  -3317.5369589328766\n",
      "Episode  3183 : Reward =  -3437.36623108387\n",
      "Episode  3184 : Reward =  -3280.2500512599945\n",
      "Episode  3185 : Reward =  -3155.520430803299\n",
      "Episode  3186 : Reward =  -3425.6255655288696\n",
      "Episode  3187 : Reward =  -3323.8985094464438\n",
      "Episode  3188 : Reward =  -3330.9058043956757\n",
      "Episode  3189 : Reward =  -3328.7892090678215\n",
      "Episode  3190 : Reward =  -3151.5399428606033\n",
      "Episode  3191 : Reward =  -3178.538888335228\n",
      "Episode  3192 : Reward =  -3369.2873333096504\n",
      "Episode  3193 : Reward =  -3261.9150158166885\n",
      "Episode  3194 : Reward =  -3172.2672068476677\n",
      "Episode  3195 : Reward =  -3416.6271481513977\n",
      "Episode  3196 : Reward =  -3494.9451746940613\n",
      "Episode  3197 : Reward =  -3469.064263820648\n",
      "Episode  3198 : Reward =  -3425.7345099449158\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.18\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3199 : Reward =  -3409.6623193061964\n",
      "Episode  3200 : Reward =  -3443.6892652511597\n",
      "Episode  3201 : Reward =  -3325.9445745944977\n",
      "Episode  3202 : Reward =  -3450.3251930475235\n",
      "Episode  3203 : Reward =  -3497.7802516222\n",
      "Episode  3204 : Reward =  -3383.426174759865\n",
      "Episode  3205 : Reward =  -3256.541025161743\n",
      "Episode  3206 : Reward =  -3496.9337082505226\n",
      "Episode  3207 : Reward =  -3367.8701182044165\n",
      "Episode  3208 : Reward =  -3282.259352982044\n",
      "Episode  3209 : Reward =  -3213.0294432640076\n",
      "Episode  3210 : Reward =  -3429.4230391979218\n",
      "Episode  3211 : Reward =  -3469.955349445343\n",
      "Episode  3212 : Reward =  -3371.7638396657126\n",
      "Episode  3213 : Reward =  -3311.952434003353\n",
      "Episode  3214 : Reward =  -3320.1308668255806\n",
      "Episode  3215 : Reward =  -3231.459507226944\n",
      "Episode  3216 : Reward =  -3321.236416041851\n",
      "Episode  3217 : Reward =  -3274.0633947849274\n",
      "Episode  3218 : Reward =  -3450.9967522621155\n",
      "Episode  3219 : Reward =  -3320.6282007694244\n",
      "Episode  3220 : Reward =  -3446.774855732918\n",
      "Episode  3221 : Reward =  -3268.1556238532066\n",
      "Episode  3222 : Reward =  -3439.2743591070175\n",
      "Episode  3223 : Reward =  -3176.1146424412727\n",
      "Episode  3224 : Reward =  -3412.5826019644737\n",
      "Episode  3225 : Reward =  -3234.4298653006554\n",
      "Episode  3226 : Reward =  -3281.089824140072\n",
      "Episode  3227 : Reward =  -3263.5954665628774\n",
      "Episode  3228 : Reward =  -3277.000347137451\n",
      "Episode  3229 : Reward =  -3337.7856379151344\n",
      "Episode  3230 : Reward =  -3390.732374191284\n",
      "Episode  3231 : Reward =  -3341.157257914543\n",
      "Episode  3232 : Reward =  -3396.2697216272354\n",
      "Episode  3233 : Reward =  -3349.59677451849\n",
      "Episode  3234 : Reward =  -3321.8376339114325\n",
      "Episode  3235 : Reward =  -3202.686600304121\n",
      "Episode  3236 : Reward =  -3507.470561027527\n",
      "Episode  3237 : Reward =  -3288.731676284136\n",
      "Episode  3238 : Reward =  -3387.388013601303\n",
      "Episode  3239 : Reward =  -3258.1666525638716\n",
      "Episode  3240 : Reward =  -3454.4101256132126\n",
      "Episode  3241 : Reward =  -3315.3141056895256\n",
      "Episode  3242 : Reward =  -3254.424356997013\n",
      "Episode  3243 : Reward =  -3328.756896138191\n",
      "Episode  3244 : Reward =  -3300.987176784645\n",
      "Episode  3245 : Reward =  -3414.2710348963737\n",
      "Episode  3246 : Reward =  -3541.4855915904045\n",
      "Episode  3247 : Reward =  -3162.272386528473\n",
      "Episode  3248 : Reward =  -3397.8202703682286\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.175\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3249 : Reward =  -3500.879204750061\n",
      "Episode  3250 : Reward =  -3343.1260087526457\n",
      "Episode  3251 : Reward =  -3322.967545747757\n",
      "Episode  3252 : Reward =  -3312.7816308140755\n",
      "Episode  3253 : Reward =  -3387.453009724617\n",
      "Episode  3254 : Reward =  -3418.0679893493652\n",
      "Episode  3255 : Reward =  -3433.466914895834\n",
      "Episode  3256 : Reward =  -3377.363765656948\n",
      "Episode  3257 : Reward =  -3471.4195572137833\n",
      "Episode  3258 : Reward =  -3253.0769995450974\n",
      "Episode  3259 : Reward =  -3433.747728049755\n",
      "Episode  3260 : Reward =  -3252.2809907285077\n",
      "Episode  3261 : Reward =  -3393.152334812941\n",
      "Episode  3262 : Reward =  -3387.9349251389503\n",
      "Episode  3263 : Reward =  -3134.7876066005842\n",
      "Episode  3264 : Reward =  -3236.8600981235504\n",
      "Episode  3265 : Reward =  -3302.0820516347885\n",
      "Episode  3266 : Reward =  -3258.873111009598\n",
      "Episode  3267 : Reward =  -3299.049338519573\n",
      "Episode  3268 : Reward =  -3268.0075966715813\n",
      "Episode  3269 : Reward =  -3246.2650479078293\n",
      "Episode  3270 : Reward =  -3259.6437775529043\n",
      "Episode  3271 : Reward =  -3355.0661917328835\n",
      "Episode  3272 : Reward =  -3402.1268181204796\n",
      "Episode  3273 : Reward =  -3310.889751791954\n",
      "Episode  3274 : Reward =  -3309.7036005854607\n",
      "Episode  3275 : Reward =  -3298.1098088026047\n",
      "Episode  3276 : Reward =  -3253.8804851174355\n",
      "Episode  3277 : Reward =  -3416.226131796837\n",
      "Episode  3278 : Reward =  -3228.022622823715\n",
      "Episode  3279 : Reward =  -3385.2793875336647\n",
      "Episode  3280 : Reward =  -3394.1694355607033\n",
      "Episode  3281 : Reward =  -3135.5173695087433\n",
      "Episode  3282 : Reward =  -3203.545463625254\n",
      "Episode  3283 : Reward =  -3304.948274433613\n",
      "Episode  3284 : Reward =  -3321.657382309437\n",
      "Episode  3285 : Reward =  -3262.4708958268166\n",
      "Episode  3286 : Reward =  -3393.9722719192505\n",
      "Episode  3287 : Reward =  -3355.1899479031563\n",
      "Episode  3288 : Reward =  -3360.4569712281227\n",
      "Episode  3289 : Reward =  -3195.110496286215\n",
      "Episode  3290 : Reward =  -3388.597532272339\n",
      "Episode  3291 : Reward =  -3225.7375530040877\n",
      "Episode  3292 : Reward =  -3231.2527004256053\n",
      "Episode  3293 : Reward =  -3448.8376434532506\n",
      "Episode  3294 : Reward =  -3428.5770991444588\n",
      "Episode  3295 : Reward =  -3306.2226256132126\n",
      "Episode  3296 : Reward =  -3163.1022365129606\n",
      "Episode  3297 : Reward =  -3313.243635058403\n",
      "Episode  3298 : Reward =  -3309.226829648018\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.17\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3299 : Reward =  -3392.7179554737227\n",
      "Episode  3300 : Reward =  -3362.4984781742096\n",
      "Episode  3301 : Reward =  -3431.5272660291807\n",
      "Episode  3302 : Reward =  -3284.6270808017866\n",
      "Episode  3303 : Reward =  -3229.921378469938\n",
      "Episode  3304 : Reward =  -3162.9102481603622\n",
      "Episode  3305 : Reward =  -3412.3048318064825\n",
      "Episode  3306 : Reward =  -3378.430924654007\n",
      "Episode  3307 : Reward =  -3333.840689122677\n",
      "Episode  3308 : Reward =  -3331.984259545803\n",
      "Episode  3309 : Reward =  -3383.563937906088\n",
      "Episode  3310 : Reward =  -3316.5129786133766\n",
      "Episode  3311 : Reward =  -3344.5438215172903\n",
      "Episode  3312 : Reward =  -3282.841380894184\n",
      "Episode  3313 : Reward =  -3114.763760927977\n",
      "Episode  3314 : Reward =  -3226.3000901937485\n",
      "Episode  3315 : Reward =  -3164.6362017429487\n",
      "Episode  3316 : Reward =  -3229.8148831129074\n",
      "Episode  3317 : Reward =  -3103.7871758937836\n",
      "Episode  3318 : Reward =  -3256.913163188757\n",
      "Episode  3319 : Reward =  -3300.687803506851\n",
      "Episode  3320 : Reward =  -3236.09495395422\n",
      "Episode  3321 : Reward =  -3273.488248705864\n",
      "Episode  3322 : Reward =  -3233.4470291137695\n",
      "Episode  3323 : Reward =  -3411.861949622631\n",
      "Episode  3324 : Reward =  -3438.092693209648\n",
      "Episode  3325 : Reward =  -3321.956702172756\n",
      "Episode  3326 : Reward =  -3160.5648190379143\n",
      "Episode  3327 : Reward =  -3166.7590629458427\n",
      "Episode  3328 : Reward =  -3254.7099655866623\n",
      "Episode  3329 : Reward =  -3322.72257655859\n",
      "Episode  3330 : Reward =  -3058.9738913810866\n",
      "Episode  3331 : Reward =  -3406.078585445881\n",
      "Episode  3332 : Reward =  -3313.1270483136177\n",
      "Episode  3333 : Reward =  -3215.7726721799986\n",
      "Episode  3334 : Reward =  -3207.9968671798706\n",
      "Episode  3335 : Reward =  -3357.271980404854\n",
      "Episode  3336 : Reward =  -3267.197841346264\n",
      "Episode  3337 : Reward =  -3141.5447877049446\n",
      "Episode  3338 : Reward =  -3172.7132371068\n",
      "Episode  3339 : Reward =  -3160.4292262828963\n",
      "Episode  3340 : Reward =  -3353.971588075161\n",
      "Episode  3341 : Reward =  -3358.112337294878\n",
      "Episode  3342 : Reward =  -3140.552630070509\n",
      "Episode  3343 : Reward =  -3283.4946038126945\n",
      "Episode  3344 : Reward =  -3131.957083526911\n",
      "Episode  3345 : Reward =  -3121.2051829099655\n",
      "Episode  3346 : Reward =  -3165.246264997782\n",
      "Episode  3347 : Reward =  -3372.2132838368416\n",
      "Episode  3348 : Reward =  -3318.679374694824\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.165\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3349 : Reward =  -3323.668845951557\n",
      "Episode  3350 : Reward =  -3161.9991169338173\n",
      "Episode  3351 : Reward =  -3089.4237599372864\n",
      "Episode  3352 : Reward =  -3200.778419557871\n",
      "Episode  3353 : Reward =  -3283.693747997284\n",
      "Episode  3354 : Reward =  -3115.904044866562\n",
      "Episode  3355 : Reward =  -3169.8446267843246\n",
      "Episode  3356 : Reward =  -3087.108255032362\n",
      "Episode  3357 : Reward =  -3082.0073786973953\n",
      "Episode  3358 : Reward =  -3333.779610514641\n",
      "Episode  3359 : Reward =  -3261.292105257511\n",
      "Episode  3360 : Reward =  -3149.7104301031513\n",
      "Episode  3361 : Reward =  -3333.749987009825\n",
      "Episode  3362 : Reward =  -3096.2849057912827\n",
      "Episode  3363 : Reward =  -3391.601771771908\n",
      "Episode  3364 : Reward =  -3258.1840367913246\n",
      "Episode  3365 : Reward =  -3156.620854381384\n",
      "Episode  3366 : Reward =  -3129.919784963131\n",
      "Episode  3367 : Reward =  -3259.2661520838737\n",
      "Episode  3368 : Reward =  -3037.836825489998\n",
      "Episode  3369 : Reward =  -3219.5987119674683\n",
      "Episode  3370 : Reward =  -3166.979331612587\n",
      "Episode  3371 : Reward =  -3436.0365154183523\n",
      "Episode  3372 : Reward =  -3302.2626425623894\n",
      "Episode  3373 : Reward =  -3179.9701850414276\n",
      "Episode  3374 : Reward =  -3176.0103125572205\n",
      "Episode  3375 : Reward =  -3202.518271446228\n",
      "Episode  3376 : Reward =  -3206.370079636574\n",
      "Episode  3377 : Reward =  -3203.685541331768\n",
      "Episode  3378 : Reward =  -3212.4834010004997\n",
      "Episode  3379 : Reward =  -3217.3991016781943\n",
      "Episode  3380 : Reward =  -3201.500588953495\n",
      "Episode  3381 : Reward =  -3175.200828826899\n",
      "Episode  3382 : Reward =  -3052.678152322769\n",
      "Episode  3383 : Reward =  -3233.4175575375557\n",
      "Episode  3384 : Reward =  -3308.229055583477\n",
      "Episode  3385 : Reward =  -3014.8593535459654\n",
      "Episode  3386 : Reward =  -3107.692742526531\n",
      "Episode  3387 : Reward =  -3162.3081486821175\n",
      "Episode  3388 : Reward =  -2845.9826806783676\n",
      "Saving better model at episode 3388 with reward -2845.9826806783676\n",
      "Episode  3389 : Reward =  -3045.3513848781586\n",
      "Episode  3390 : Reward =  -3004.475224081339\n",
      "Episode  3391 : Reward =  -3145.695807911377\n",
      "Episode  3392 : Reward =  -3122.516131080608\n",
      "Episode  3393 : Reward =  -3182.898979127407\n",
      "Episode  3394 : Reward =  -3252.393465220928\n",
      "Episode  3395 : Reward =  -3145.811065554619\n",
      "Episode  3396 : Reward =  -3208.128772318363\n",
      "Episode  3397 : Reward =  -3019.7561108321547\n",
      "Episode  3398 : Reward =  -3269.7583470344543\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.16\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3399 : Reward =  -3191.7760516405106\n",
      "Episode  3400 : Reward =  -2931.011657306324\n",
      "Episode  3401 : Reward =  -2854.985262811184\n",
      "Episode  3402 : Reward =  -3183.346489727497\n",
      "Episode  3403 : Reward =  -3224.735928237438\n",
      "Episode  3404 : Reward =  -3157.828048067896\n",
      "Episode  3405 : Reward =  -3125.9349105990545\n",
      "Episode  3406 : Reward =  -3060.856488108635\n",
      "Episode  3407 : Reward =  -2900.2338998404844\n",
      "Episode  3408 : Reward =  -3258.22220236063\n",
      "Episode  3409 : Reward =  -3222.4306430220604\n",
      "Episode  3410 : Reward =  -3228.7587861418724\n",
      "Episode  3411 : Reward =  -3167.946280181408\n",
      "Episode  3412 : Reward =  -3008.3325220942497\n",
      "Episode  3413 : Reward =  -3216.7750714421272\n",
      "Episode  3414 : Reward =  -3315.237924337387\n",
      "Episode  3415 : Reward =  -3222.0515413059993\n",
      "Episode  3416 : Reward =  -3365.3696974515915\n",
      "Episode  3417 : Reward =  -3160.7335240928037\n",
      "Episode  3418 : Reward =  -3161.735164165497\n",
      "Episode  3419 : Reward =  -3155.926030099392\n",
      "Episode  3420 : Reward =  -3304.849265217781\n",
      "Episode  3421 : Reward =  -3210.177723411383\n",
      "Episode  3422 : Reward =  -3101.2195762991905\n",
      "Episode  3423 : Reward =  -3229.2915385365486\n",
      "Episode  3424 : Reward =  -3305.50523263216\n",
      "Episode  3425 : Reward =  -3152.834802865982\n",
      "Episode  3426 : Reward =  -3233.6829224824905\n",
      "Episode  3427 : Reward =  -3304.660745739937\n",
      "Episode  3428 : Reward =  -3233.2511280179024\n",
      "Episode  3429 : Reward =  -3124.4609636700766\n",
      "Episode  3430 : Reward =  -3268.9755969047546\n",
      "Episode  3431 : Reward =  -3067.5078850984573\n",
      "Episode  3432 : Reward =  -3139.499460577965\n",
      "Episode  3433 : Reward =  -3124.75610268116\n",
      "Episode  3434 : Reward =  -3112.40559142828\n",
      "Episode  3435 : Reward =  -3321.6423714756966\n",
      "Episode  3436 : Reward =  -3137.7008539438248\n",
      "Episode  3437 : Reward =  -3121.1332817077637\n",
      "Episode  3438 : Reward =  -3279.7873747981207\n",
      "Episode  3439 : Reward =  -3196.4739382267\n",
      "Episode  3440 : Reward =  -3265.957692205906\n",
      "Episode  3441 : Reward =  -3269.321822166443\n",
      "Episode  3442 : Reward =  -3260.972954336466\n",
      "Episode  3443 : Reward =  -3200.5729535222054\n",
      "Episode  3444 : Reward =  -3266.9199507832527\n",
      "Episode  3445 : Reward =  -3274.898323893547\n",
      "Episode  3446 : Reward =  -3179.765775203705\n",
      "Episode  3447 : Reward =  -3177.8660875930595\n",
      "Episode  3448 : Reward =  -3318.836712181568\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.155\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3449 : Reward =  -3222.155035197735\n",
      "Episode  3450 : Reward =  -3219.8981214165688\n",
      "Episode  3451 : Reward =  -3244.6729954852863\n",
      "Episode  3452 : Reward =  -3218.2685119509697\n",
      "Episode  3453 : Reward =  -3128.780203763308\n",
      "Episode  3454 : Reward =  -3136.884318768978\n",
      "Episode  3455 : Reward =  -3063.2574557065964\n",
      "Episode  3456 : Reward =  -3039.351961195469\n",
      "Episode  3457 : Reward =  -3093.9807224956853\n",
      "Episode  3458 : Reward =  -3138.763161301613\n",
      "Episode  3459 : Reward =  -3147.8531045913696\n",
      "Episode  3460 : Reward =  -3127.0915535092354\n",
      "Episode  3461 : Reward =  -3276.5559391975403\n",
      "Episode  3462 : Reward =  -3200.005936205387\n",
      "Episode  3463 : Reward =  -3040.027191698551\n",
      "Episode  3464 : Reward =  -3097.189754843712\n",
      "Episode  3465 : Reward =  -3249.3941336274147\n",
      "Episode  3466 : Reward =  -3136.7860457897186\n",
      "Episode  3467 : Reward =  -3044.7623029351234\n",
      "Episode  3468 : Reward =  -3152.3241087198257\n",
      "Episode  3469 : Reward =  -3109.470497318874\n",
      "Episode  3470 : Reward =  -3289.606309119524\n",
      "Episode  3471 : Reward =  -3187.2475942373276\n",
      "Episode  3472 : Reward =  -3068.8163259625435\n",
      "Episode  3473 : Reward =  -3169.6741566694395\n",
      "Episode  3474 : Reward =  -3057.7440514564514\n",
      "Episode  3475 : Reward =  -3071.0943697690964\n",
      "Episode  3476 : Reward =  -3111.6182930469513\n",
      "Episode  3477 : Reward =  -3133.888870894909\n",
      "Episode  3478 : Reward =  -3127.496300458908\n",
      "Episode  3479 : Reward =  -3098.6460593938828\n",
      "Episode  3480 : Reward =  -3049.651157501997\n",
      "Episode  3481 : Reward =  -3135.434846639633\n",
      "Episode  3482 : Reward =  -3129.8891112208366\n",
      "Episode  3483 : Reward =  -3037.5946167198526\n",
      "Episode  3484 : Reward =  -3228.725870910944\n",
      "Episode  3485 : Reward =  -3190.6248413324356\n",
      "Episode  3486 : Reward =  -3006.8656949488027\n",
      "Episode  3487 : Reward =  -3147.9888167381287\n",
      "Episode  3488 : Reward =  -3151.505500081839\n",
      "Episode  3489 : Reward =  -3101.046402014713\n",
      "Episode  3490 : Reward =  -3006.146807730198\n",
      "Episode  3491 : Reward =  -2992.809946835041\n",
      "Episode  3492 : Reward =  -3157.8614142537117\n",
      "Episode  3493 : Reward =  -3196.8293678536224\n",
      "Episode  3494 : Reward =  -3166.7343096137047\n",
      "Episode  3495 : Reward =  -3111.9942554322583\n",
      "Episode  3496 : Reward =  -3213.6872215867043\n",
      "Episode  3497 : Reward =  -3353.872010830702\n",
      "Episode  3498 : Reward =  -3200.611751973629\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.15\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3499 : Reward =  -3178.261392891407\n",
      "Episode  3500 : Reward =  -3173.3929480314255\n",
      "Episode  3501 : Reward =  -3100.8940340280533\n",
      "Episode  3502 : Reward =  -3153.2149611115456\n",
      "Episode  3503 : Reward =  -3022.3595798015594\n",
      "Episode  3504 : Reward =  -3284.1856631040573\n",
      "Episode  3505 : Reward =  -3447.321823954582\n",
      "Episode  3506 : Reward =  -3242.8949625492096\n",
      "Episode  3507 : Reward =  -3353.9277322888374\n",
      "Episode  3508 : Reward =  -3302.591730415821\n",
      "Episode  3509 : Reward =  -3292.553785741329\n",
      "Episode  3510 : Reward =  -3315.7005772590637\n",
      "Episode  3511 : Reward =  -3428.295586168766\n",
      "Episode  3512 : Reward =  -3320.10467427969\n",
      "Episode  3513 : Reward =  -3358.2983133792877\n",
      "Episode  3514 : Reward =  -3287.541629854502\n",
      "Episode  3515 : Reward =  -3326.408734858036\n",
      "Episode  3516 : Reward =  -3122.0905504859106\n",
      "Episode  3517 : Reward =  -3321.032743394375\n",
      "Episode  3518 : Reward =  -3306.2930452263968\n",
      "Episode  3519 : Reward =  -3294.8772237300873\n",
      "Episode  3520 : Reward =  -3092.0088945031166\n",
      "Episode  3521 : Reward =  -3288.4359209537506\n",
      "Episode  3522 : Reward =  -3293.705919507803\n",
      "Episode  3523 : Reward =  -3283.010042437683\n",
      "Episode  3524 : Reward =  -3318.6013829112053\n",
      "Episode  3525 : Reward =  -3353.1157788038254\n",
      "Episode  3526 : Reward =  -3366.639866411686\n",
      "Episode  3527 : Reward =  -3260.871826955448\n",
      "Episode  3528 : Reward =  -3335.803862273693\n",
      "Episode  3529 : Reward =  -3006.5782727003098\n",
      "Episode  3530 : Reward =  -3412.9307060837746\n",
      "Episode  3531 : Reward =  -3140.657144430937\n",
      "Episode  3532 : Reward =  -3173.4547414183617\n",
      "Episode  3533 : Reward =  -3154.0721198407514\n",
      "Episode  3534 : Reward =  -3308.179579973221\n",
      "Episode  3535 : Reward =  -3336.1319809556007\n",
      "Episode  3536 : Reward =  -3365.4418530464172\n",
      "Episode  3537 : Reward =  -3250.6016543507576\n",
      "Episode  3538 : Reward =  -3274.6958725452423\n",
      "Episode  3539 : Reward =  -3085.577620923519\n",
      "Episode  3540 : Reward =  -3220.9079144001007\n",
      "Episode  3541 : Reward =  -3125.1466075269086\n",
      "Episode  3542 : Reward =  -3143.742212423454\n",
      "Episode  3543 : Reward =  -3299.7196456826346\n",
      "Episode  3544 : Reward =  -3235.1630569548006\n",
      "Episode  3545 : Reward =  -3230.92301517725\n",
      "Episode  3546 : Reward =  -3194.09008613872\n",
      "Episode  3547 : Reward =  -3252.992452565493\n",
      "Episode  3548 : Reward =  -3172.64840477705\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.145\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3549 : Reward =  -3029.767936348915\n",
      "Episode  3550 : Reward =  -3168.792193055153\n",
      "Episode  3551 : Reward =  -3236.877693423401\n",
      "Episode  3552 : Reward =  -3241.4018416404724\n",
      "Episode  3553 : Reward =  -3259.462089240551\n",
      "Episode  3554 : Reward =  -3301.780609548092\n",
      "Episode  3555 : Reward =  -3251.908012151718\n",
      "Episode  3556 : Reward =  -3047.310542881489\n",
      "Episode  3557 : Reward =  -3338.1448014414923\n",
      "Episode  3558 : Reward =  -3180.0277800559998\n",
      "Episode  3559 : Reward =  -3296.5038474202156\n",
      "Episode  3560 : Reward =  -3333.732025206089\n",
      "Episode  3561 : Reward =  -3339.976292669773\n",
      "Episode  3562 : Reward =  -3172.8935173153877\n",
      "Episode  3563 : Reward =  -3104.591480731964\n",
      "Episode  3564 : Reward =  -3406.2768778800964\n",
      "Episode  3565 : Reward =  -3264.8436939803464\n",
      "Episode  3566 : Reward =  -3319.372515618801\n",
      "Episode  3567 : Reward =  -3434.9306988716125\n",
      "Episode  3568 : Reward =  -3215.672602713108\n",
      "Episode  3569 : Reward =  -3348.497129023075\n",
      "Episode  3570 : Reward =  -3379.429713487625\n",
      "Episode  3571 : Reward =  -3169.04801261425\n",
      "Episode  3572 : Reward =  -3321.4054335951805\n",
      "Episode  3573 : Reward =  -3277.1193903684616\n",
      "Episode  3574 : Reward =  -3296.8316323793547\n",
      "Episode  3575 : Reward =  -3396.078031003475\n",
      "Episode  3576 : Reward =  -3259.6525174975395\n",
      "Episode  3577 : Reward =  -3289.1820340156555\n",
      "Episode  3578 : Reward =  -2966.0380125045776\n",
      "Episode  3579 : Reward =  -2999.794612590136\n",
      "Episode  3580 : Reward =  -3301.353036761284\n",
      "Episode  3581 : Reward =  -3113.2547125307424\n",
      "Episode  3582 : Reward =  -3197.9774360693114\n",
      "Episode  3583 : Reward =  -3249.4134619235992\n",
      "Episode  3584 : Reward =  -3299.535621404648\n",
      "Episode  3585 : Reward =  -3138.4106407201903\n",
      "Episode  3586 : Reward =  -3297.331401292147\n",
      "Episode  3587 : Reward =  -3290.585158228874\n",
      "Episode  3588 : Reward =  -3170.04025340444\n",
      "Episode  3589 : Reward =  -3193.9150428175926\n",
      "Episode  3590 : Reward =  -3358.446767926216\n",
      "Episode  3591 : Reward =  -3248.27516245842\n",
      "Episode  3592 : Reward =  -3153.7243668437004\n",
      "Episode  3593 : Reward =  -3347.68462818861\n",
      "Episode  3594 : Reward =  -3336.7660012841225\n",
      "Episode  3595 : Reward =  -3244.824735347094\n",
      "Episode  3596 : Reward =  -3351.967917382717\n",
      "Episode  3597 : Reward =  -3368.543011546135\n",
      "Episode  3598 : Reward =  -3220.0311715602875\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.14\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3599 : Reward =  -3495.9090020656586\n",
      "Episode  3600 : Reward =  -3440.2346321344376\n",
      "Episode  3601 : Reward =  -3117.6621680259705\n",
      "Episode  3602 : Reward =  -3395.0459139347076\n",
      "Episode  3603 : Reward =  -3328.1668072342873\n",
      "Episode  3604 : Reward =  -3252.8660402297974\n",
      "Episode  3605 : Reward =  -3217.164165922771\n",
      "Episode  3606 : Reward =  -3072.0541887283325\n",
      "Episode  3607 : Reward =  -3375.8574585318565\n",
      "Episode  3608 : Reward =  -3234.384087204933\n",
      "Episode  3609 : Reward =  -2957.292387911449\n",
      "Episode  3610 : Reward =  -3022.4083806908743\n",
      "Episode  3611 : Reward =  -3059.9506873488426\n",
      "Episode  3612 : Reward =  -3434.008137345314\n",
      "Episode  3613 : Reward =  -3089.045409977436\n",
      "Episode  3614 : Reward =  -3372.2549092769623\n",
      "Episode  3615 : Reward =  -3103.1622529029846\n",
      "Episode  3616 : Reward =  -3266.832368373871\n",
      "Episode  3617 : Reward =  -3267.8370440006256\n",
      "Episode  3618 : Reward =  -3382.9753564596176\n",
      "Episode  3619 : Reward =  -2924.34304356575\n",
      "Episode  3620 : Reward =  -3334.4989223480225\n",
      "Episode  3621 : Reward =  -3380.7899491786957\n",
      "Episode  3622 : Reward =  -3323.7955679893494\n",
      "Episode  3623 : Reward =  -3066.7223051277506\n",
      "Episode  3624 : Reward =  -3357.7176955342293\n",
      "Episode  3625 : Reward =  -3463.5494638085365\n",
      "Episode  3626 : Reward =  -3441.502411901951\n",
      "Episode  3627 : Reward =  -3241.9847021465243\n",
      "Episode  3628 : Reward =  -3118.0239236391203\n",
      "Episode  3629 : Reward =  -3449.2795699238777\n",
      "Episode  3630 : Reward =  -3325.20294422275\n",
      "Episode  3631 : Reward =  -3358.4438601732254\n",
      "Episode  3632 : Reward =  -3475.773259460926\n",
      "Episode  3633 : Reward =  -3103.5365763902664\n",
      "Episode  3634 : Reward =  -3175.7662133946224\n",
      "Episode  3635 : Reward =  -3163.1790741086006\n",
      "Episode  3636 : Reward =  -3350.9367728269713\n",
      "Episode  3637 : Reward =  -3413.547348856926\n",
      "Episode  3638 : Reward =  -3004.293897274794\n",
      "Episode  3639 : Reward =  -3342.8887963294983\n",
      "Episode  3640 : Reward =  -3069.0929273962975\n",
      "Episode  3641 : Reward =  -3062.182911515236\n",
      "Episode  3642 : Reward =  -3386.9148715138435\n",
      "Episode  3643 : Reward =  -3459.682828247547\n",
      "Episode  3644 : Reward =  -3291.508265852928\n",
      "Episode  3645 : Reward =  -3295.17028516531\n",
      "Episode  3646 : Reward =  -3442.962566614151\n",
      "Episode  3647 : Reward =  -3106.2197139263153\n",
      "Episode  3648 : Reward =  -3108.453158020973\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.135\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3649 : Reward =  -3245.363037288189\n",
      "Episode  3650 : Reward =  -3385.938537299633\n",
      "Episode  3651 : Reward =  -3334.7187119722366\n",
      "Episode  3652 : Reward =  -3156.348499238491\n",
      "Episode  3653 : Reward =  -3113.560288608074\n",
      "Episode  3654 : Reward =  -3336.110575258732\n",
      "Episode  3655 : Reward =  -3257.245654407801\n",
      "Episode  3656 : Reward =  -3136.6618892586844\n",
      "Episode  3657 : Reward =  -3075.1507954597473\n",
      "Episode  3658 : Reward =  -3240.2110954523087\n",
      "Episode  3659 : Reward =  -3393.481152713299\n",
      "Episode  3660 : Reward =  -3272.843591272831\n",
      "Episode  3661 : Reward =  -3214.109461370768\n",
      "Episode  3662 : Reward =  -3265.502389192581\n",
      "Episode  3663 : Reward =  -3228.0372862815857\n",
      "Episode  3664 : Reward =  -3163.1620631814003\n",
      "Episode  3665 : Reward =  -3164.8672073483467\n",
      "Episode  3666 : Reward =  -3120.6940248012543\n",
      "Episode  3667 : Reward =  -3136.97551418222\n",
      "Episode  3668 : Reward =  -3178.5700340867043\n",
      "Episode  3669 : Reward =  -3087.704055249691\n",
      "Episode  3670 : Reward =  -3238.9527191519737\n",
      "Episode  3671 : Reward =  -3023.897008419037\n",
      "Episode  3672 : Reward =  -3090.914922595024\n",
      "Episode  3673 : Reward =  -3222.3843491077423\n",
      "Episode  3674 : Reward =  -3131.544488731684\n",
      "Episode  3675 : Reward =  -3129.5935241616385\n",
      "Episode  3676 : Reward =  -3200.138194680214\n",
      "Episode  3677 : Reward =  -3072.1831157579227\n",
      "Episode  3678 : Reward =  -3279.619400024414\n",
      "Episode  3679 : Reward =  -3296.954807460308\n",
      "Episode  3680 : Reward =  -3140.996279124083\n",
      "Episode  3681 : Reward =  -3206.809596180916\n",
      "Episode  3682 : Reward =  -3113.7019335627556\n",
      "Episode  3683 : Reward =  -3244.7102753556387\n",
      "Episode  3684 : Reward =  -3017.248719394207\n",
      "Episode  3685 : Reward =  -3192.706917285919\n",
      "Episode  3686 : Reward =  -3160.8129325000154\n",
      "Episode  3687 : Reward =  -2997.63107162714\n",
      "Episode  3688 : Reward =  -3198.7001878110273\n",
      "Episode  3689 : Reward =  -3320.8992471694946\n",
      "Episode  3690 : Reward =  -3142.0404699481146\n",
      "Episode  3691 : Reward =  -3062.0823355949537\n",
      "Episode  3692 : Reward =  -3096.6205302476883\n",
      "Episode  3693 : Reward =  -3118.2474081516266\n",
      "Episode  3694 : Reward =  -3244.635856449604\n",
      "Episode  3695 : Reward =  -3094.205004402767\n",
      "Episode  3696 : Reward =  -3093.8598094618933\n",
      "Episode  3697 : Reward =  -3214.4605869687216\n",
      "Episode  3698 : Reward =  -2823.5639250278473\n",
      "Saving better model at episode 3698 with reward -2823.5639250278473\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.13\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3699 : Reward =  -3055.7364776170866\n",
      "Episode  3700 : Reward =  -3092.419835269451\n",
      "Episode  3701 : Reward =  -2984.5061837471144\n",
      "Episode  3702 : Reward =  -3164.634987950325\n",
      "Episode  3703 : Reward =  -3054.5537945628166\n",
      "Episode  3704 : Reward =  -3262.1564049720764\n",
      "Episode  3705 : Reward =  -3142.1124933362007\n",
      "Episode  3706 : Reward =  -3156.481298092665\n",
      "Episode  3707 : Reward =  -3060.559254861349\n",
      "Episode  3708 : Reward =  -3132.9005329049246\n",
      "Episode  3709 : Reward =  -3188.987132370472\n",
      "Episode  3710 : Reward =  -3081.7134995236206\n",
      "Episode  3711 : Reward =  -3148.951382756233\n",
      "Episode  3712 : Reward =  -2982.0241635478155\n",
      "Episode  3713 : Reward =  -3090.1038137078285\n",
      "Episode  3714 : Reward =  -3017.669442781578\n",
      "Episode  3715 : Reward =  -3157.641513943672\n",
      "Episode  3716 : Reward =  -3120.4096168651386\n",
      "Episode  3717 : Reward =  -3045.5963525772095\n",
      "Episode  3718 : Reward =  -2976.9602743387222\n",
      "Episode  3719 : Reward =  -3106.576718994747\n",
      "Episode  3720 : Reward =  -3094.2698813117163\n",
      "Episode  3721 : Reward =  -3188.1336526907103\n",
      "Episode  3722 : Reward =  -3151.5874301195145\n",
      "Episode  3723 : Reward =  -3061.406120244326\n",
      "Episode  3724 : Reward =  -3142.984709262848\n",
      "Episode  3725 : Reward =  -3197.0298075675964\n",
      "Episode  3726 : Reward =  -3088.874017838301\n",
      "Episode  3727 : Reward =  -3194.5040782130377\n",
      "Episode  3728 : Reward =  -3108.6726046204567\n",
      "Episode  3729 : Reward =  -3013.040219426155\n",
      "Episode  3730 : Reward =  -3123.039399004454\n",
      "Episode  3731 : Reward =  -3130.168560329737\n",
      "Episode  3732 : Reward =  -3118.239288040768\n",
      "Episode  3733 : Reward =  -3036.706391397776\n",
      "Episode  3734 : Reward =  -2936.2979393041746\n",
      "Episode  3735 : Reward =  -3037.8527806401253\n",
      "Episode  3736 : Reward =  -3101.4206795183522\n",
      "Episode  3737 : Reward =  -3097.9904158711433\n",
      "Episode  3738 : Reward =  -3149.0785793153154\n",
      "Episode  3739 : Reward =  -3251.95831489563\n",
      "Episode  3740 : Reward =  -3115.3477815389633\n",
      "Episode  3741 : Reward =  -3139.0071995034023\n",
      "Episode  3742 : Reward =  -3088.3865892327444\n",
      "Episode  3743 : Reward =  -3246.412077009678\n",
      "Episode  3744 : Reward =  -3140.284046539436\n",
      "Episode  3745 : Reward =  -3063.3259244561195\n",
      "Episode  3746 : Reward =  -3101.983346915716\n",
      "Episode  3747 : Reward =  -3145.8071125745773\n",
      "Episode  3748 : Reward =  -3196.079211294651\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.125\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3749 : Reward =  -3094.2941957712173\n",
      "Episode  3750 : Reward =  -3179.297706067562\n",
      "Episode  3751 : Reward =  -2971.892568051815\n",
      "Episode  3752 : Reward =  -3184.2715145349503\n",
      "Episode  3753 : Reward =  -3116.653514921665\n",
      "Episode  3754 : Reward =  -3089.289857927622\n",
      "Episode  3755 : Reward =  -3116.8336874246597\n",
      "Episode  3756 : Reward =  -3064.1899124159618\n",
      "Episode  3757 : Reward =  -3090.9595935940742\n",
      "Episode  3758 : Reward =  -3179.34319126606\n",
      "Episode  3759 : Reward =  -2994.76711798078\n",
      "Episode  3760 : Reward =  -3100.3056098855154\n",
      "Episode  3761 : Reward =  -3165.1443988084793\n",
      "Episode  3762 : Reward =  -3115.8726032972336\n",
      "Episode  3763 : Reward =  -3152.0739915407316\n",
      "Episode  3764 : Reward =  -3289.252890352072\n",
      "Episode  3765 : Reward =  -3212.6606306433678\n",
      "Episode  3766 : Reward =  -3298.7967242598534\n",
      "Episode  3767 : Reward =  -3065.235863983631\n",
      "Episode  3768 : Reward =  -3099.8833218812943\n",
      "Episode  3769 : Reward =  -3126.591924670996\n",
      "Episode  3770 : Reward =  -3327.889249997942\n",
      "Episode  3771 : Reward =  -3243.7335745692253\n",
      "Episode  3772 : Reward =  -3117.888262871565\n",
      "Episode  3773 : Reward =  -3183.1236108903827\n",
      "Episode  3774 : Reward =  -3185.203234860073\n",
      "Episode  3775 : Reward =  -3183.0001760212285\n",
      "Episode  3776 : Reward =  -3253.4128371513502\n",
      "Episode  3777 : Reward =  -3105.833268824877\n",
      "Episode  3778 : Reward =  -3205.1300030350685\n",
      "Episode  3779 : Reward =  -3209.430994749069\n",
      "Episode  3780 : Reward =  -3237.9474013534887\n",
      "Episode  3781 : Reward =  -3172.5145971215384\n",
      "Episode  3782 : Reward =  -3255.275925695896\n",
      "Episode  3783 : Reward =  -3246.38140386343\n",
      "Episode  3784 : Reward =  -3216.137863099575\n",
      "Episode  3785 : Reward =  -3198.7393268942833\n",
      "Episode  3786 : Reward =  -3289.055072069168\n",
      "Episode  3787 : Reward =  -3123.7947751283646\n",
      "Episode  3788 : Reward =  -3142.1358367567004\n",
      "Episode  3789 : Reward =  -3097.7644045352936\n",
      "Episode  3790 : Reward =  -3045.8538221120834\n",
      "Episode  3791 : Reward =  -3069.6347759998457\n",
      "Episode  3792 : Reward =  -3141.5361526608467\n",
      "Episode  3793 : Reward =  -3139.534444037737\n",
      "Episode  3794 : Reward =  -3048.467186510563\n",
      "Episode  3795 : Reward =  -3167.2635847330093\n",
      "Episode  3796 : Reward =  -3106.612900444637\n",
      "Episode  3797 : Reward =  -3184.0155423916\n",
      "Episode  3798 : Reward =  -3200.9388575553894\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.12\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3799 : Reward =  -3088.849325597286\n",
      "Episode  3800 : Reward =  -3133.6482029332924\n",
      "Episode  3801 : Reward =  -3241.030644723545\n",
      "Episode  3802 : Reward =  -3183.0071859955788\n",
      "Episode  3803 : Reward =  -3105.616582516493\n",
      "Episode  3804 : Reward =  -2934.1292755007744\n",
      "Episode  3805 : Reward =  -3140.364802479744\n",
      "Episode  3806 : Reward =  -3274.805742207827\n",
      "Episode  3807 : Reward =  -3139.6183686292784\n",
      "Episode  3808 : Reward =  -3287.508028126234\n",
      "Episode  3809 : Reward =  -3127.5971955432697\n",
      "Episode  3810 : Reward =  -3135.191560515533\n",
      "Episode  3811 : Reward =  -3131.4194425940514\n",
      "Episode  3812 : Reward =  -3071.4188638329506\n",
      "Episode  3813 : Reward =  -3211.5506482211454\n",
      "Episode  3814 : Reward =  -3094.625816473137\n",
      "Episode  3815 : Reward =  -3070.4192224144936\n",
      "Episode  3816 : Reward =  -2928.2465385881765\n",
      "Episode  3817 : Reward =  -3056.603939652443\n",
      "Episode  3818 : Reward =  -3139.6637387041987\n",
      "Episode  3819 : Reward =  -3030.1544556617737\n",
      "Episode  3820 : Reward =  -2966.659624695778\n",
      "Episode  3821 : Reward =  -3048.241475522518\n",
      "Episode  3822 : Reward =  -3091.6078407764435\n",
      "Episode  3823 : Reward =  -3050.670184198679\n",
      "Episode  3824 : Reward =  -3076.254914045334\n",
      "Episode  3825 : Reward =  -3045.082412004471\n",
      "Episode  3826 : Reward =  -3181.3254688418524\n",
      "Episode  3827 : Reward =  -3248.669294334869\n",
      "Episode  3828 : Reward =  -3009.645494222641\n",
      "Episode  3829 : Reward =  -3176.74935860313\n",
      "Episode  3830 : Reward =  -3092.431289076805\n",
      "Episode  3831 : Reward =  -3227.189051270485\n",
      "Episode  3832 : Reward =  -3122.982099834742\n",
      "Episode  3833 : Reward =  -3074.733193874359\n",
      "Episode  3834 : Reward =  -3227.6408553755896\n",
      "Episode  3835 : Reward =  -3112.8015612363815\n",
      "Episode  3836 : Reward =  -3147.946712590675\n",
      "Episode  3837 : Reward =  -3133.595715880394\n",
      "Episode  3838 : Reward =  -3051.9967470169067\n",
      "Episode  3839 : Reward =  -3170.5828188694136\n",
      "Episode  3840 : Reward =  -2929.2463479042053\n",
      "Episode  3841 : Reward =  -3225.1914280056953\n",
      "Episode  3842 : Reward =  -3087.283026493067\n",
      "Episode  3843 : Reward =  -3125.7894726991653\n",
      "Episode  3844 : Reward =  -2937.4261746778293\n",
      "Episode  3845 : Reward =  -2987.7127016186714\n",
      "Episode  3846 : Reward =  -3132.389503836632\n",
      "Episode  3847 : Reward =  -2969.326229929924\n",
      "Episode  3848 : Reward =  -3048.464688360691\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.115\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3849 : Reward =  -3046.955545604229\n",
      "Episode  3850 : Reward =  -3098.028437682758\n",
      "Episode  3851 : Reward =  -3019.0893566099508\n",
      "Episode  3852 : Reward =  -3102.2011076248305\n",
      "Episode  3853 : Reward =  -3041.003037750721\n",
      "Episode  3854 : Reward =  -3052.706454702984\n",
      "Episode  3855 : Reward =  -3061.7165308035032\n",
      "Episode  3856 : Reward =  -3056.8583875894547\n",
      "Episode  3857 : Reward =  -3049.6932456529753\n",
      "Episode  3858 : Reward =  -3062.8074218034744\n",
      "Episode  3859 : Reward =  -3392.052775129735\n",
      "Episode  3860 : Reward =  -3210.656435374083\n",
      "Episode  3861 : Reward =  -3266.3433594703674\n",
      "Episode  3862 : Reward =  -3246.6128113902228\n",
      "Episode  3863 : Reward =  -3360.6620870008273\n",
      "Episode  3864 : Reward =  -3240.7321024537086\n",
      "Episode  3865 : Reward =  -3229.4216596484184\n",
      "Episode  3866 : Reward =  -3168.0906318462507\n",
      "Episode  3867 : Reward =  -3231.0649912444455\n",
      "Episode  3868 : Reward =  -3177.9789452552795\n",
      "Episode  3869 : Reward =  -3204.4570954813767\n",
      "Episode  3870 : Reward =  -3250.3650854601665\n",
      "Episode  3871 : Reward =  -3223.3872298373985\n",
      "Episode  3872 : Reward =  -3234.018906629557\n",
      "Episode  3873 : Reward =  -3351.5696033015056\n",
      "Episode  3874 : Reward =  -3201.2410430908203\n",
      "Episode  3875 : Reward =  -3240.3222500172956\n",
      "Episode  3876 : Reward =  -3272.8569132772786\n",
      "Episode  3877 : Reward =  -3276.877893984318\n",
      "Episode  3878 : Reward =  -3271.028815397392\n",
      "Episode  3879 : Reward =  -3176.287644326687\n",
      "Episode  3880 : Reward =  -3145.8185235857964\n",
      "Episode  3881 : Reward =  -3276.680031601252\n",
      "Episode  3882 : Reward =  -3145.019560456276\n",
      "Episode  3883 : Reward =  -3179.5555673874037\n",
      "Episode  3884 : Reward =  -3170.6438691056387\n",
      "Episode  3885 : Reward =  -3253.213540080847\n",
      "Episode  3886 : Reward =  -3203.6794544545514\n",
      "Episode  3887 : Reward =  -3188.0359947172506\n",
      "Episode  3888 : Reward =  -3305.8229676260753\n",
      "Episode  3889 : Reward =  -3445.552603500693\n",
      "Episode  3890 : Reward =  -3251.349393606186\n",
      "Episode  3891 : Reward =  -3230.297721132695\n",
      "Episode  3892 : Reward =  -3263.6885770595686\n",
      "Episode  3893 : Reward =  -3188.8181245698734\n",
      "Episode  3894 : Reward =  -3264.6779314875603\n",
      "Episode  3895 : Reward =  -3180.565418422222\n",
      "Episode  3896 : Reward =  -3161.8534089363234\n",
      "Episode  3897 : Reward =  -3201.7742741740362\n",
      "Episode  3898 : Reward =  -3252.991804841818\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.11\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3899 : Reward =  -3319.6334616913605\n",
      "Episode  3900 : Reward =  -3206.965618610382\n",
      "Episode  3901 : Reward =  -3248.5110787836416\n",
      "Episode  3902 : Reward =  -3288.8455771244185\n",
      "Episode  3903 : Reward =  -3318.484284344973\n",
      "Episode  3904 : Reward =  -3241.575712300758\n",
      "Episode  3905 : Reward =  -3203.3248118162155\n",
      "Episode  3906 : Reward =  -3148.820716559887\n",
      "Episode  3907 : Reward =  -3111.630712810816\n",
      "Episode  3908 : Reward =  -3167.786743760109\n",
      "Episode  3909 : Reward =  -3340.780856975685\n",
      "Episode  3910 : Reward =  -3304.2195525801794\n",
      "Episode  3911 : Reward =  -3298.4393956101553\n",
      "Episode  3912 : Reward =  -3231.619757536711\n",
      "Episode  3913 : Reward =  -3280.31464237846\n",
      "Episode  3914 : Reward =  -3124.0970020890236\n",
      "Episode  3915 : Reward =  -3193.1063905990736\n",
      "Episode  3916 : Reward =  -3379.7496861591144\n",
      "Episode  3917 : Reward =  -3210.8968812263624\n",
      "Episode  3918 : Reward =  -3224.616859614849\n",
      "Episode  3919 : Reward =  -3173.2331634163857\n",
      "Episode  3920 : Reward =  -3091.6829931735992\n",
      "Episode  3921 : Reward =  -3138.289958655834\n",
      "Episode  3922 : Reward =  -3173.504884302616\n",
      "Episode  3923 : Reward =  -3354.980142065655\n",
      "Episode  3924 : Reward =  -3310.0176467386586\n",
      "Episode  3925 : Reward =  -3070.8135671019554\n",
      "Episode  3926 : Reward =  -3188.413115799427\n",
      "Episode  3927 : Reward =  -3190.4752720594406\n",
      "Episode  3928 : Reward =  -3254.67305165893\n",
      "Episode  3929 : Reward =  -3275.0556628740446\n",
      "Episode  3930 : Reward =  -3277.3053996650083\n",
      "Episode  3931 : Reward =  -3210.674953520298\n",
      "Episode  3932 : Reward =  -3411.33517951137\n",
      "Episode  3933 : Reward =  -3313.1806165351672\n",
      "Episode  3934 : Reward =  -3355.5584995150566\n",
      "Episode  3935 : Reward =  -3411.5768514958722\n",
      "Episode  3936 : Reward =  -3341.6914976239204\n",
      "Episode  3937 : Reward =  -3420.86663196134\n",
      "Episode  3938 : Reward =  -3339.489768087864\n",
      "Episode  3939 : Reward =  -3369.9171558109624\n",
      "Episode  3940 : Reward =  -3369.8773358500616\n",
      "Episode  3941 : Reward =  -3324.6277765631676\n",
      "Episode  3942 : Reward =  -3445.2989603877068\n",
      "Episode  3943 : Reward =  -3382.817713443102\n",
      "Episode  3944 : Reward =  -3304.04041069746\n",
      "Episode  3945 : Reward =  -3476.928515153734\n",
      "Episode  3946 : Reward =  -3306.6293411254883\n",
      "Episode  3947 : Reward =  -3300.598156878124\n",
      "Episode  3948 : Reward =  -3181.437172719608\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to :  0.105\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3949 : Reward =  -3223.379926506342\n",
      "Episode  3950 : Reward =  -3314.906711110245\n",
      "Episode  3951 : Reward =  -3211.1346086263657\n",
      "Episode  3952 : Reward =  -3227.6783793655736\n",
      "Episode  3953 : Reward =  -3295.9206584692\n",
      "Episode  3954 : Reward =  -3380.169179681601\n",
      "Episode  3955 : Reward =  -3295.230573901306\n",
      "Episode  3956 : Reward =  -3282.758395675482\n",
      "Episode  3957 : Reward =  -3028.447154521942\n",
      "Episode  3958 : Reward =  -3341.5420468215884\n",
      "Episode  3959 : Reward =  -3253.1002607381956\n",
      "Episode  3960 : Reward =  -3165.291069686413\n",
      "Episode  3961 : Reward =  -3074.3766587376595\n",
      "Episode  3962 : Reward =  -3330.790901426138\n",
      "Episode  3963 : Reward =  -3321.93252951778\n",
      "Episode  3964 : Reward =  -3092.6757882869856\n",
      "Episode  3965 : Reward =  -3217.670116308989\n",
      "Episode  3966 : Reward =  -3279.7405863179965\n",
      "Episode  3967 : Reward =  -3294.444514044891\n",
      "Episode  3968 : Reward =  -3260.838284432888\n",
      "Episode  3969 : Reward =  -3204.590982142748\n",
      "Episode  3970 : Reward =  -3239.9115166664124\n",
      "Episode  3971 : Reward =  -3174.408260822296\n",
      "Episode  3972 : Reward =  -3191.205490001808\n",
      "Episode  3973 : Reward =  -3185.8279953598976\n",
      "Episode  3974 : Reward =  -3264.411273006262\n",
      "Episode  3975 : Reward =  -3430.9000348896384\n",
      "Episode  3976 : Reward =  -3208.598573446274\n",
      "Episode  3977 : Reward =  -3309.449360773027\n",
      "Episode  3978 : Reward =  -3296.0510268894536\n",
      "Episode  3979 : Reward =  -3358.04365963615\n",
      "Episode  3980 : Reward =  -3185.4985200799124\n",
      "Episode  3981 : Reward =  -3231.2558563947678\n",
      "Episode  3982 : Reward =  -3391.1267683272304\n",
      "Episode  3983 : Reward =  -3183.872671910892\n",
      "Episode  3984 : Reward =  -3264.4495660837574\n",
      "Episode  3985 : Reward =  -3115.533212128939\n",
      "Episode  3986 : Reward =  -3181.4126529097557\n",
      "Episode  3987 : Reward =  -3311.6215661255223\n",
      "Episode  3988 : Reward =  -3200.055148780346\n",
      "Episode  3989 : Reward =  -3182.5082142128754\n",
      "Episode  3990 : Reward =  -3293.413461881487\n",
      "Episode  3991 : Reward =  -3236.9489295482635\n",
      "Episode  3992 : Reward =  -3266.574152447204\n",
      "Episode  3993 : Reward =  -3233.5738466978073\n",
      "Episode  3994 : Reward =  -3331.7955451011658\n",
      "Episode  3995 : Reward =  -3237.347691953182\n",
      "Episode  3996 : Reward =  -3297.830890715122\n",
      "Episode  3997 : Reward =  -3139.4456707871573\n",
      "Episode  3998 : Reward =  -3225.6378035036428\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  3999 : Reward =  -3191.5161913720476\n",
      "Episode  4000 : Reward =  -3339.327046159567\n",
      "Episode  4001 : Reward =  -3247.086298406124\n",
      "Episode  4002 : Reward =  -3295.3383472052915\n",
      "Episode  4003 : Reward =  -3284.1895958556934\n",
      "Episode  4004 : Reward =  -3184.685741785826\n",
      "Episode  4005 : Reward =  -3282.8709324374004\n",
      "Episode  4006 : Reward =  -3307.1223264336586\n",
      "Episode  4007 : Reward =  -3296.721053219313\n",
      "Episode  4008 : Reward =  -3238.4205027905805\n",
      "Episode  4009 : Reward =  -3146.1223003304617\n",
      "Episode  4010 : Reward =  -3159.9698332584517\n",
      "Episode  4011 : Reward =  -3165.2317246831076\n",
      "Episode  4012 : Reward =  -3144.5677675641195\n",
      "Episode  4013 : Reward =  -3175.197664026083\n",
      "Episode  4014 : Reward =  -3187.4677036180306\n",
      "Episode  4015 : Reward =  -3065.8019093871117\n",
      "Episode  4016 : Reward =  -3022.4237026572227\n",
      "Episode  4017 : Reward =  -3139.9720546007156\n",
      "Episode  4018 : Reward =  -3217.5437869465964\n",
      "Episode  4019 : Reward =  -3254.099166929722\n",
      "Episode  4020 : Reward =  -3059.6727298498154\n",
      "Episode  4021 : Reward =  -3261.477104485035\n",
      "Episode  4022 : Reward =  -3203.62532174951\n",
      "Episode  4023 : Reward =  -3074.0790334939957\n",
      "Episode  4024 : Reward =  -3027.0626898407936\n",
      "Episode  4025 : Reward =  -3215.3516204953194\n",
      "Episode  4026 : Reward =  -3170.9782586693764\n",
      "Episode  4027 : Reward =  -3176.3641132488056\n",
      "Episode  4028 : Reward =  -3186.755826115608\n",
      "Episode  4029 : Reward =  -3255.5564137472916\n",
      "Episode  4030 : Reward =  -3120.5437538660185\n",
      "Episode  4031 : Reward =  -3281.6767206192017\n",
      "Episode  4032 : Reward =  -3261.818592309952\n",
      "Episode  4033 : Reward =  -3206.9123389161246\n",
      "Episode  4034 : Reward =  -3190.425540268421\n",
      "Episode  4035 : Reward =  -3272.00451938055\n",
      "Episode  4036 : Reward =  -3211.2017815709114\n",
      "Episode  4037 : Reward =  -3252.487655699253\n",
      "Episode  4038 : Reward =  -3271.887224916281\n",
      "Episode  4039 : Reward =  -3127.0160314477102\n",
      "Episode  4040 : Reward =  -3132.9125542640686\n",
      "Episode  4041 : Reward =  -3207.405843615532\n",
      "Episode  4042 : Reward =  -3101.919674873352\n",
      "Episode  4043 : Reward =  -3128.9245168566704\n",
      "Episode  4044 : Reward =  -3200.790312353434\n",
      "Episode  4045 : Reward =  -3228.6559978214605\n",
      "Episode  4046 : Reward =  -3246.7318628430367\n",
      "Episode  4047 : Reward =  -3287.078042305927\n",
      "Episode  4048 : Reward =  -3078.659918010235\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4049 : Reward =  -3342.814935728967\n",
      "Episode  4050 : Reward =  -3230.483331620693\n",
      "Episode  4051 : Reward =  -3233.5392150878906\n",
      "Episode  4052 : Reward =  -3191.120219349861\n",
      "Episode  4053 : Reward =  -3400.3149820602553\n",
      "Episode  4054 : Reward =  -3101.929453730583\n",
      "Episode  4055 : Reward =  -3287.320661786856\n",
      "Episode  4056 : Reward =  -3215.855346504511\n",
      "Episode  4057 : Reward =  -3213.1823586821556\n",
      "Episode  4058 : Reward =  -3276.0256959199905\n",
      "Episode  4059 : Reward =  -3060.3283719420433\n",
      "Episode  4060 : Reward =  -3115.610090970993\n",
      "Episode  4061 : Reward =  -3057.1376420942647\n",
      "Episode  4062 : Reward =  -3200.87123131752\n",
      "Episode  4063 : Reward =  -3177.7812716960907\n",
      "Episode  4064 : Reward =  -3168.742101380001\n",
      "Episode  4065 : Reward =  -3136.1591623425484\n",
      "Episode  4066 : Reward =  -3162.531815290451\n",
      "Episode  4067 : Reward =  -3043.5956122279167\n",
      "Episode  4068 : Reward =  -3190.4850535988808\n",
      "Episode  4069 : Reward =  -3433.807252172293\n",
      "Episode  4070 : Reward =  -3212.894600868225\n",
      "Episode  4071 : Reward =  -3317.7926476597786\n",
      "Episode  4072 : Reward =  -3165.1105012384755\n",
      "Episode  4073 : Reward =  -3368.4953306913376\n",
      "Episode  4074 : Reward =  -3158.6643409132957\n",
      "Episode  4075 : Reward =  -3180.884744167328\n",
      "Episode  4076 : Reward =  -3243.9290224313736\n",
      "Episode  4077 : Reward =  -3291.9371606198656\n",
      "Episode  4078 : Reward =  -3196.845322430134\n",
      "Episode  4079 : Reward =  -3253.549365524115\n",
      "Episode  4080 : Reward =  -3221.4536496400833\n",
      "Episode  4081 : Reward =  -3372.1928410108967\n",
      "Episode  4082 : Reward =  -3127.070712506771\n",
      "Episode  4083 : Reward =  -3352.3904441035406\n",
      "Episode  4084 : Reward =  -3290.4322830214305\n",
      "Episode  4085 : Reward =  -3389.321705528866\n",
      "Episode  4086 : Reward =  -3221.527548134327\n",
      "Episode  4087 : Reward =  -3289.1619731783867\n",
      "Episode  4088 : Reward =  -3211.209330443205\n",
      "Episode  4089 : Reward =  -3196.3151575922966\n",
      "Episode  4090 : Reward =  -3209.105407599272\n",
      "Episode  4091 : Reward =  -3266.102318474422\n",
      "Episode  4092 : Reward =  -3589.3626375049944\n",
      "Episode  4093 : Reward =  -3363.5873633398814\n",
      "Episode  4094 : Reward =  -3387.8778160214424\n",
      "Episode  4095 : Reward =  -3135.5522476434708\n",
      "Episode  4096 : Reward =  -3250.2406914321286\n",
      "Episode  4097 : Reward =  -3324.8552859425545\n",
      "Episode  4098 : Reward =  -3119.6241226792336\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4099 : Reward =  -3052.9811097979546\n",
      "Episode  4100 : Reward =  -3140.2509500980377\n",
      "Episode  4101 : Reward =  -3128.5960664749146\n",
      "Episode  4102 : Reward =  -3068.080609091888\n",
      "Episode  4103 : Reward =  -2969.0435518984737\n",
      "Episode  4104 : Reward =  -2885.212355732918\n",
      "Episode  4105 : Reward =  -3014.8831442966266\n",
      "Episode  4106 : Reward =  -2895.3235757438047\n",
      "Episode  4107 : Reward =  -2822.2646065950394\n",
      "Saving better model at episode 4107 with reward -2822.2646065950394\n",
      "Episode  4108 : Reward =  -2864.4613877906604\n",
      "Episode  4109 : Reward =  -2873.009506583214\n",
      "Episode  4110 : Reward =  -2995.1027000633585\n",
      "Episode  4111 : Reward =  -2969.0452545732855\n",
      "Episode  4112 : Reward =  -3010.6981912851334\n",
      "Episode  4113 : Reward =  -2888.007562223734\n",
      "Episode  4114 : Reward =  -2946.4267714706766\n",
      "Episode  4115 : Reward =  -2954.308677293281\n",
      "Episode  4116 : Reward =  -2778.9965922236443\n",
      "Saving better model at episode 4116 with reward -2778.9965922236443\n",
      "Episode  4117 : Reward =  -2947.6634354627745\n",
      "Episode  4118 : Reward =  -2898.1100750601904\n",
      "Episode  4119 : Reward =  -2883.4728900281293\n",
      "Episode  4120 : Reward =  -2824.735854446888\n",
      "Episode  4121 : Reward =  -2912.221843339424\n",
      "Episode  4122 : Reward =  -2774.6511276364326\n",
      "Saving better model at episode 4122 with reward -2774.6511276364326\n",
      "Episode  4123 : Reward =  -2820.391773823561\n",
      "Episode  4124 : Reward =  -2911.726976939808\n",
      "Episode  4125 : Reward =  -2811.961401406588\n",
      "Episode  4126 : Reward =  -2697.9237244165556\n",
      "Saving better model at episode 4126 with reward -2697.9237244165556\n",
      "Episode  4127 : Reward =  -2788.40978420652\n",
      "Episode  4128 : Reward =  -2742.235751211643\n",
      "Episode  4129 : Reward =  -2880.3839999473707\n",
      "Episode  4130 : Reward =  -2652.375330030918\n",
      "Saving better model at episode 4130 with reward -2652.375330030918\n",
      "Episode  4131 : Reward =  -2969.5242844223976\n",
      "Episode  4132 : Reward =  -2803.5110204815865\n",
      "Episode  4133 : Reward =  -2887.7917688525336\n",
      "Episode  4134 : Reward =  -2792.1641694307327\n",
      "Episode  4135 : Reward =  -2908.661101767193\n",
      "Episode  4136 : Reward =  -2828.2658901810646\n",
      "Episode  4137 : Reward =  -3006.1968988776207\n",
      "Episode  4138 : Reward =  -2694.096809566021\n",
      "Episode  4139 : Reward =  -2832.078967630863\n",
      "Episode  4140 : Reward =  -2838.6085195032465\n",
      "Episode  4141 : Reward =  -2955.791210893454\n",
      "Episode  4142 : Reward =  -2879.3531307578087\n",
      "Episode  4143 : Reward =  -2736.9111353791372\n",
      "Episode  4144 : Reward =  -2860.1037052360875\n",
      "Episode  4145 : Reward =  -2787.2335711717606\n",
      "Episode  4146 : Reward =  -2747.5726740956306\n",
      "Episode  4147 : Reward =  -2933.049679517746\n",
      "Episode  4148 : Reward =  -3000.0023842816295\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4149 : Reward =  -2719.0417459047453\n",
      "Episode  4150 : Reward =  -2816.3288570678847\n",
      "Episode  4151 : Reward =  -2641.555233478546\n",
      "Saving better model at episode 4151 with reward -2641.555233478546\n",
      "Episode  4152 : Reward =  -2742.684999346733\n",
      "Episode  4153 : Reward =  -2712.0848969853537\n",
      "Episode  4154 : Reward =  -2626.047244131565\n",
      "Saving better model at episode 4154 with reward -2626.047244131565\n",
      "Episode  4155 : Reward =  -2659.6079083456802\n",
      "Episode  4156 : Reward =  -2688.797259390354\n",
      "Episode  4157 : Reward =  -2683.7383813945157\n",
      "Episode  4158 : Reward =  -2645.92273324728\n",
      "Episode  4159 : Reward =  -2707.350839916529\n",
      "Episode  4160 : Reward =  -2835.4360924138828\n",
      "Episode  4161 : Reward =  -2742.907096633087\n",
      "Episode  4162 : Reward =  -2778.8602324760573\n",
      "Episode  4163 : Reward =  -2686.281990889372\n",
      "Episode  4164 : Reward =  -2813.7500513283117\n",
      "Episode  4165 : Reward =  -2721.9047128645284\n",
      "Episode  4166 : Reward =  -2718.6485511151654\n",
      "Episode  4167 : Reward =  -2809.7733315601154\n",
      "Episode  4168 : Reward =  -2739.18893545866\n",
      "Episode  4169 : Reward =  -2712.5422655110306\n",
      "Episode  4170 : Reward =  -2610.1136242747307\n",
      "Saving better model at episode 4170 with reward -2610.1136242747307\n",
      "Episode  4171 : Reward =  -2753.5440887895925\n",
      "Episode  4172 : Reward =  -2701.301264533173\n",
      "Episode  4173 : Reward =  -2661.3908540046828\n",
      "Episode  4174 : Reward =  -2759.79803914703\n",
      "Episode  4175 : Reward =  -2757.815638422966\n",
      "Episode  4176 : Reward =  -2672.256887737574\n",
      "Episode  4177 : Reward =  -2669.872913002968\n",
      "Episode  4178 : Reward =  -2633.429674267769\n",
      "Episode  4179 : Reward =  -2745.878811933021\n",
      "Episode  4180 : Reward =  -2682.7075085043907\n",
      "Episode  4181 : Reward =  -2638.825108528137\n",
      "Episode  4182 : Reward =  -2707.7598444223404\n",
      "Episode  4183 : Reward =  -2795.9861023513186\n",
      "Episode  4184 : Reward =  -2788.9243634379523\n",
      "Episode  4185 : Reward =  -2666.1601733652456\n",
      "Episode  4186 : Reward =  -2839.6106400489807\n",
      "Episode  4187 : Reward =  -2709.7438658563\n",
      "Episode  4188 : Reward =  -2651.9560252428055\n",
      "Episode  4189 : Reward =  -2664.081184029579\n",
      "Episode  4190 : Reward =  -2655.342272043228\n",
      "Episode  4191 : Reward =  -2793.398114860058\n",
      "Episode  4192 : Reward =  -2747.3389850854874\n",
      "Episode  4193 : Reward =  -2834.30092290687\n",
      "Episode  4194 : Reward =  -2734.949180960655\n",
      "Episode  4195 : Reward =  -2745.321110844612\n",
      "Episode  4196 : Reward =  -2788.9664672613144\n",
      "Episode  4197 : Reward =  -2836.5841109752655\n",
      "Episode  4198 : Reward =  -2823.782019674778\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4199 : Reward =  -2800.6927208304405\n",
      "Episode  4200 : Reward =  -2829.1645137107985\n",
      "Episode  4201 : Reward =  -2607.062922179699\n",
      "Saving better model at episode 4201 with reward -2607.062922179699\n",
      "Episode  4202 : Reward =  -2846.099934283556\n",
      "Episode  4203 : Reward =  -2797.396797308098\n",
      "Episode  4204 : Reward =  -2941.8732201828766\n",
      "Episode  4205 : Reward =  -2737.265190601349\n",
      "Episode  4206 : Reward =  -2736.2540174163\n",
      "Episode  4207 : Reward =  -2687.7452677488327\n",
      "Episode  4208 : Reward =  -2603.493883252144\n",
      "Saving better model at episode 4208 with reward -2603.493883252144\n",
      "Episode  4209 : Reward =  -2745.976637610565\n",
      "Episode  4210 : Reward =  -2782.6531852846088\n",
      "Episode  4211 : Reward =  -2755.8464714921133\n",
      "Episode  4212 : Reward =  -2732.4785443580763\n",
      "Episode  4213 : Reward =  -2622.8388360514446\n",
      "Episode  4214 : Reward =  -2686.544046286406\n",
      "Episode  4215 : Reward =  -2587.6778029203415\n",
      "Saving better model at episode 4215 with reward -2587.6778029203415\n",
      "Episode  4216 : Reward =  -2735.6081382072584\n",
      "Episode  4217 : Reward =  -2780.5950045585632\n",
      "Episode  4218 : Reward =  -2747.5421485304832\n",
      "Episode  4219 : Reward =  -2708.740023970604\n",
      "Episode  4220 : Reward =  -2668.3391695022583\n",
      "Episode  4221 : Reward =  -2633.463281251411\n",
      "Episode  4222 : Reward =  -2569.9282366073744\n",
      "Saving better model at episode 4222 with reward -2569.9282366073744\n",
      "Episode  4223 : Reward =  -2578.5231724381447\n",
      "Episode  4224 : Reward =  -2769.6517075671954\n",
      "Episode  4225 : Reward =  -2547.7762353420258\n",
      "Saving better model at episode 4225 with reward -2547.7762353420258\n",
      "Episode  4226 : Reward =  -2614.687598947348\n",
      "Episode  4227 : Reward =  -2611.4499370542867\n",
      "Episode  4228 : Reward =  -2646.0473769678874\n",
      "Episode  4229 : Reward =  -2581.991752423267\n",
      "Episode  4230 : Reward =  -2473.7218403816223\n",
      "Saving better model at episode 4230 with reward -2473.7218403816223\n",
      "Episode  4231 : Reward =  -2651.9526608622687\n",
      "Episode  4232 : Reward =  -2425.067195057869\n",
      "Saving better model at episode 4232 with reward -2425.067195057869\n",
      "Episode  4233 : Reward =  -2590.4839537739754\n",
      "Episode  4234 : Reward =  -2629.9174794641835\n",
      "Episode  4235 : Reward =  -2686.8639604485647\n",
      "Episode  4236 : Reward =  -2586.514905512333\n",
      "Episode  4237 : Reward =  -2576.3953650369453\n",
      "Episode  4238 : Reward =  -2519.320748269558\n",
      "Episode  4239 : Reward =  -2507.220252454281\n",
      "Episode  4240 : Reward =  -2578.1444116830826\n",
      "Episode  4241 : Reward =  -2567.1071748769896\n",
      "Episode  4242 : Reward =  -2611.002098325552\n",
      "Episode  4243 : Reward =  -2595.2452225089073\n",
      "Episode  4244 : Reward =  -2668.149191099016\n",
      "Episode  4245 : Reward =  -2652.046474222006\n",
      "Episode  4246 : Reward =  -2631.11003566152\n",
      "Episode  4247 : Reward =  -2664.744544781666\n",
      "Episode  4248 : Reward =  -2636.8093369043486\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4249 : Reward =  -2618.323038554663\n",
      "Episode  4250 : Reward =  -2683.8624624101026\n",
      "Episode  4251 : Reward =  -2610.1846436298506\n",
      "Episode  4252 : Reward =  -2590.7754500544684\n",
      "Episode  4253 : Reward =  -2722.7600666656303\n",
      "Episode  4254 : Reward =  -2596.9234643069613\n",
      "Episode  4255 : Reward =  -3608.7417317123295\n",
      "Episode  4256 : Reward =  -2605.0750587022917\n",
      "Episode  4257 : Reward =  -2622.031947800289\n",
      "Episode  4258 : Reward =  -2688.432895585954\n",
      "Episode  4259 : Reward =  -2680.366566002369\n",
      "Episode  4260 : Reward =  -2603.3484360016005\n",
      "Episode  4261 : Reward =  -2519.1893324255943\n",
      "Episode  4262 : Reward =  -2507.538031935692\n",
      "Episode  4263 : Reward =  -2575.174536406994\n",
      "Episode  4264 : Reward =  -2579.30223093174\n",
      "Episode  4265 : Reward =  -2561.583602488041\n",
      "Episode  4266 : Reward =  -2506.3299410379545\n",
      "Episode  4267 : Reward =  -2671.4166931546347\n",
      "Episode  4268 : Reward =  -2749.5971840386333\n",
      "Episode  4269 : Reward =  -2539.7280585206167\n",
      "Episode  4270 : Reward =  -2558.2644895351546\n",
      "Episode  4271 : Reward =  -2570.9544483189525\n",
      "Episode  4272 : Reward =  -2548.07972574234\n",
      "Episode  4273 : Reward =  -2734.4152103066444\n",
      "Episode  4274 : Reward =  -2591.593228340149\n",
      "Episode  4275 : Reward =  -2552.885561713348\n",
      "Episode  4276 : Reward =  -2622.7323422198237\n",
      "Episode  4277 : Reward =  -2518.8522607684135\n",
      "Episode  4278 : Reward =  -2604.461392223835\n",
      "Episode  4279 : Reward =  -2644.1034775412695\n",
      "Episode  4280 : Reward =  -2509.588111588131\n",
      "Episode  4281 : Reward =  -2590.9174702342443\n",
      "Episode  4282 : Reward =  -2557.5872674075467\n",
      "Episode  4283 : Reward =  -2540.4230524897575\n",
      "Episode  4284 : Reward =  -2570.4438378810883\n",
      "Episode  4285 : Reward =  -2828.791026867847\n",
      "Episode  4286 : Reward =  -2609.4696310162544\n",
      "Episode  4287 : Reward =  -2576.2153884259565\n",
      "Episode  4288 : Reward =  -2693.0197626203894\n",
      "Episode  4289 : Reward =  -2671.2863429560466\n",
      "Episode  4290 : Reward =  -2772.5164885883273\n",
      "Episode  4291 : Reward =  -2488.7072157263756\n",
      "Episode  4292 : Reward =  -2691.5637907161517\n",
      "Episode  4293 : Reward =  -2430.219518431793\n",
      "Episode  4294 : Reward =  -2429.052110850811\n",
      "Episode  4295 : Reward =  -2526.61375147468\n",
      "Episode  4296 : Reward =  -2574.8966806567328\n",
      "Episode  4297 : Reward =  -2477.1659316507685\n",
      "Episode  4298 : Reward =  -2403.3966940132486\n",
      "Saving better model at episode 4298 with reward -2403.3966940132486\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4299 : Reward =  -2580.7491729025787\n",
      "Episode  4300 : Reward =  -2536.312685646038\n",
      "Episode  4301 : Reward =  -2507.042700469494\n",
      "Episode  4302 : Reward =  -2545.3610586015093\n",
      "Episode  4303 : Reward =  -2397.878800905222\n",
      "Saving better model at episode 4303 with reward -2397.878800905222\n",
      "Episode  4304 : Reward =  -2526.4746304837568\n",
      "Episode  4305 : Reward =  -2418.922230698089\n",
      "Episode  4306 : Reward =  -2529.3717077970505\n",
      "Episode  4307 : Reward =  -2541.869755574833\n",
      "Episode  4308 : Reward =  -2444.043184518814\n",
      "Episode  4309 : Reward =  -2395.2421252814634\n",
      "Saving better model at episode 4309 with reward -2395.2421252814634\n",
      "Episode  4310 : Reward =  -2509.042817056179\n",
      "Episode  4311 : Reward =  -2398.36858856678\n",
      "Episode  4312 : Reward =  -2346.4074251651764\n",
      "Saving better model at episode 4312 with reward -2346.4074251651764\n",
      "Episode  4313 : Reward =  -2577.7244899309294\n",
      "Episode  4314 : Reward =  -2337.7596501744406\n",
      "Saving better model at episode 4314 with reward -2337.7596501744406\n",
      "Episode  4315 : Reward =  -2492.3077965465886\n",
      "Episode  4316 : Reward =  -2695.789970791811\n",
      "Episode  4317 : Reward =  -2581.9450714959903\n",
      "Episode  4318 : Reward =  -2380.410637739958\n",
      "Episode  4319 : Reward =  -2425.430779937567\n",
      "Episode  4320 : Reward =  -2474.4558997750282\n",
      "Episode  4321 : Reward =  -2476.2348211494786\n",
      "Episode  4322 : Reward =  -2563.100916632782\n",
      "Episode  4323 : Reward =  -2479.11933482057\n",
      "Episode  4324 : Reward =  -2498.1608026390018\n",
      "Episode  4325 : Reward =  -2495.436295926571\n",
      "Episode  4326 : Reward =  -2377.9651730060577\n",
      "Episode  4327 : Reward =  -2492.584030151367\n",
      "Episode  4328 : Reward =  -2396.102991104126\n",
      "Episode  4329 : Reward =  -2444.0631778240204\n",
      "Episode  4330 : Reward =  -2559.622320481907\n",
      "Episode  4331 : Reward =  -2381.2677642143385\n",
      "Episode  4332 : Reward =  -2398.719239294529\n",
      "Episode  4333 : Reward =  -2500.285229779701\n",
      "Episode  4334 : Reward =  -2440.622765302658\n",
      "Episode  4335 : Reward =  -2415.562196556391\n",
      "Episode  4336 : Reward =  -2432.9427014676435\n",
      "Episode  4337 : Reward =  -2562.422848030984\n",
      "Episode  4338 : Reward =  -2357.310311917128\n",
      "Episode  4339 : Reward =  -2371.631998602213\n",
      "Episode  4340 : Reward =  -2456.4948968974454\n",
      "Episode  4341 : Reward =  -2513.2673809019434\n",
      "Episode  4342 : Reward =  -2360.77112865448\n",
      "Episode  4343 : Reward =  -2509.338645526539\n",
      "Episode  4344 : Reward =  -2497.7873951233046\n",
      "Episode  4345 : Reward =  -2488.4403090564115\n",
      "Episode  4346 : Reward =  -2485.799154341221\n",
      "Episode  4347 : Reward =  -2359.3623735904694\n",
      "Episode  4348 : Reward =  -2535.6193967548716\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4349 : Reward =  -2470.6524733901024\n",
      "Episode  4350 : Reward =  -2635.799949630967\n",
      "Episode  4351 : Reward =  -2465.6737816929817\n",
      "Episode  4352 : Reward =  -2515.4510260224342\n",
      "Episode  4353 : Reward =  -2459.2086547700274\n",
      "Episode  4354 : Reward =  -2470.6326916850226\n",
      "Episode  4355 : Reward =  -2370.1357516086714\n",
      "Episode  4356 : Reward =  -2489.2170490658896\n",
      "Episode  4357 : Reward =  -2438.985076376568\n",
      "Episode  4358 : Reward =  -2464.736773788929\n",
      "Episode  4359 : Reward =  -2403.69718170166\n",
      "Episode  4360 : Reward =  -2449.8694787061827\n",
      "Episode  4361 : Reward =  -2429.361739703785\n",
      "Episode  4362 : Reward =  -2434.9869862285955\n",
      "Episode  4363 : Reward =  -2371.9335156679153\n",
      "Episode  4364 : Reward =  -2516.714712211262\n",
      "Episode  4365 : Reward =  -2446.294310156168\n",
      "Episode  4366 : Reward =  -2528.4681563228964\n",
      "Episode  4367 : Reward =  -2484.6582946777344\n",
      "Episode  4368 : Reward =  -2473.367082664143\n",
      "Episode  4369 : Reward =  -2546.0845397747175\n",
      "Episode  4370 : Reward =  -2462.5100188342435\n",
      "Episode  4371 : Reward =  -2418.328330282034\n",
      "Episode  4372 : Reward =  -2443.749489792953\n",
      "Episode  4373 : Reward =  -2502.7482571092946\n",
      "Episode  4374 : Reward =  -2457.146813392639\n",
      "Episode  4375 : Reward =  -2386.3187844193594\n",
      "Episode  4376 : Reward =  -2427.144390705885\n",
      "Episode  4377 : Reward =  -2422.504122742783\n",
      "Episode  4378 : Reward =  -2397.765209142031\n",
      "Episode  4379 : Reward =  -2458.092281259517\n",
      "Episode  4380 : Reward =  -2496.504451695742\n",
      "Episode  4381 : Reward =  -2529.6679487228394\n",
      "Episode  4382 : Reward =  -2444.1536514163017\n",
      "Episode  4383 : Reward =  -2481.000693265261\n",
      "Episode  4384 : Reward =  -2330.7469341158867\n",
      "Saving better model at episode 4384 with reward -2330.7469341158867\n",
      "Episode  4385 : Reward =  -2582.1679282188416\n",
      "Episode  4386 : Reward =  -2445.5603923833983\n",
      "Episode  4387 : Reward =  -2416.4273354411125\n",
      "Episode  4388 : Reward =  -2555.4284508860724\n",
      "Episode  4389 : Reward =  -2473.5618736831057\n",
      "Episode  4390 : Reward =  -2508.8593847191946\n",
      "Episode  4391 : Reward =  -2521.4865950793624\n",
      "Episode  4392 : Reward =  -2344.456721842289\n",
      "Episode  4393 : Reward =  -2443.4848594752657\n",
      "Episode  4394 : Reward =  -2670.3567594376905\n",
      "Episode  4395 : Reward =  -2541.462075807075\n",
      "Episode  4396 : Reward =  -2634.7419665827556\n",
      "Episode  4397 : Reward =  -2542.941989004612\n",
      "Episode  4398 : Reward =  -2451.9472174048424\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4399 : Reward =  -2507.079566836357\n",
      "Episode  4400 : Reward =  -2764.1053700296793\n",
      "Episode  4401 : Reward =  -2460.2171388304846\n",
      "Episode  4402 : Reward =  -2416.7583984769003\n",
      "Episode  4403 : Reward =  -2414.3292157053947\n",
      "Episode  4404 : Reward =  -2694.5179794282317\n",
      "Episode  4405 : Reward =  -2474.6414056420326\n",
      "Episode  4406 : Reward =  -2562.2427001631872\n",
      "Episode  4407 : Reward =  -2641.7192736119628\n",
      "Episode  4408 : Reward =  -2548.386912414204\n",
      "Episode  4409 : Reward =  -2654.008259007107\n",
      "Episode  4410 : Reward =  -2631.8372187018394\n",
      "Episode  4411 : Reward =  -2396.1253682374954\n",
      "Episode  4412 : Reward =  -2532.568948864937\n",
      "Episode  4413 : Reward =  -2583.1903953318542\n",
      "Episode  4414 : Reward =  -2338.3188245332854\n",
      "Episode  4415 : Reward =  -2468.1143317855017\n",
      "Episode  4416 : Reward =  -2483.276751458645\n",
      "Episode  4417 : Reward =  -2503.43417722858\n",
      "Episode  4418 : Reward =  -2525.454503366123\n",
      "Episode  4419 : Reward =  -2671.224567032332\n",
      "Episode  4420 : Reward =  -2373.4665297865868\n",
      "Episode  4421 : Reward =  -2482.456960209976\n",
      "Episode  4422 : Reward =  -2471.344022154808\n",
      "Episode  4423 : Reward =  -2485.242453098297\n",
      "Episode  4424 : Reward =  -2478.0496898925917\n",
      "Episode  4425 : Reward =  -2535.9081982410567\n",
      "Episode  4426 : Reward =  -2354.195562962355\n",
      "Episode  4427 : Reward =  -2579.880934275608\n",
      "Episode  4428 : Reward =  -2471.650153875351\n",
      "Episode  4429 : Reward =  -2495.1824533975737\n",
      "Episode  4430 : Reward =  -2484.81186706699\n",
      "Episode  4431 : Reward =  -2635.894653773779\n",
      "Episode  4432 : Reward =  -2466.6774580515043\n",
      "Episode  4433 : Reward =  -2394.9787774086\n",
      "Episode  4434 : Reward =  -2569.1326208797796\n",
      "Episode  4435 : Reward =  -2409.6364038586617\n",
      "Episode  4436 : Reward =  -2506.3919873920786\n",
      "Episode  4437 : Reward =  -2515.5355713403837\n",
      "Episode  4438 : Reward =  -2496.1256434321404\n",
      "Episode  4439 : Reward =  -2593.466705478649\n",
      "Episode  4440 : Reward =  -2719.4560252799793\n",
      "Episode  4441 : Reward =  -2385.677922964096\n",
      "Episode  4442 : Reward =  -2478.533403456211\n",
      "Episode  4443 : Reward =  -2423.858449101448\n",
      "Episode  4444 : Reward =  -2670.825312989561\n",
      "Episode  4445 : Reward =  -2450.9485341993677\n",
      "Episode  4446 : Reward =  -2766.891527935922\n",
      "Episode  4447 : Reward =  -2488.1603016853333\n",
      "Episode  4448 : Reward =  -2548.987002849579\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4449 : Reward =  -2597.282111323351\n",
      "Episode  4450 : Reward =  -2576.560096383095\n",
      "Episode  4451 : Reward =  -2504.709531668486\n",
      "Episode  4452 : Reward =  -2580.983635544777\n",
      "Episode  4453 : Reward =  -2662.9820052151626\n",
      "Episode  4454 : Reward =  -2546.754788581194\n",
      "Episode  4455 : Reward =  -2368.583763841452\n",
      "Episode  4456 : Reward =  -2448.905814353289\n",
      "Episode  4457 : Reward =  -2605.9357433355467\n",
      "Episode  4458 : Reward =  -2545.904737774195\n",
      "Episode  4459 : Reward =  -2390.2319064736366\n",
      "Episode  4460 : Reward =  -2634.377683946262\n",
      "Episode  4461 : Reward =  -2429.543702248396\n",
      "Episode  4462 : Reward =  -2589.1583175695555\n",
      "Episode  4463 : Reward =  -2419.5029494166374\n",
      "Episode  4464 : Reward =  -2477.241975554596\n",
      "Episode  4465 : Reward =  -2390.94617283708\n",
      "Episode  4466 : Reward =  -2722.319282389158\n",
      "Episode  4467 : Reward =  -2412.620709002018\n",
      "Episode  4468 : Reward =  -2551.50116852569\n",
      "Episode  4469 : Reward =  -2621.2388051188605\n",
      "Episode  4470 : Reward =  -2546.05702739954\n",
      "Episode  4471 : Reward =  -2576.3265466094017\n",
      "Episode  4472 : Reward =  -2550.9627335703985\n",
      "Episode  4473 : Reward =  -2631.002944752633\n",
      "Episode  4474 : Reward =  -2500.7178472316878\n",
      "Episode  4475 : Reward =  -2555.197878420353\n",
      "Episode  4476 : Reward =  -2614.072633907258\n",
      "Episode  4477 : Reward =  -2436.2843893766403\n",
      "Episode  4478 : Reward =  -2491.1574664115906\n",
      "Episode  4479 : Reward =  -2522.1098752617836\n",
      "Episode  4480 : Reward =  -2444.3719938433783\n",
      "Episode  4481 : Reward =  -2396.8985888449056\n",
      "Episode  4482 : Reward =  -2413.127257324676\n",
      "Episode  4483 : Reward =  -2602.715272411763\n",
      "Episode  4484 : Reward =  -2447.114148378372\n",
      "Episode  4485 : Reward =  -2580.400322684418\n",
      "Episode  4486 : Reward =  -2451.75881886846\n",
      "Episode  4487 : Reward =  -2475.6325563788414\n",
      "Episode  4488 : Reward =  -2573.203482747078\n",
      "Episode  4489 : Reward =  -2458.8465150631087\n",
      "Episode  4490 : Reward =  -2509.2898964322226\n",
      "Episode  4491 : Reward =  -2581.337101459503\n",
      "Episode  4492 : Reward =  -2447.9736893213408\n",
      "Episode  4493 : Reward =  -2530.2119770646095\n",
      "Episode  4494 : Reward =  -2552.751185834408\n",
      "Episode  4495 : Reward =  -2397.846792638302\n",
      "Episode  4496 : Reward =  -2457.8998921004636\n",
      "Episode  4497 : Reward =  -2566.284979888569\n",
      "Episode  4498 : Reward =  -2559.265913285236\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4499 : Reward =  -2520.4003908409877\n",
      "Episode  4500 : Reward =  -2472.367641553342\n",
      "Episode  4501 : Reward =  -2411.4171117319866\n",
      "Episode  4502 : Reward =  -2497.8247390165134\n",
      "Episode  4503 : Reward =  -2629.734710770457\n",
      "Episode  4504 : Reward =  -2454.6580533385277\n",
      "Episode  4505 : Reward =  -2548.4309968118614\n",
      "Episode  4506 : Reward =  -2389.8145276904106\n",
      "Episode  4507 : Reward =  -2313.146971464157\n",
      "Saving better model at episode 4507 with reward -2313.146971464157\n",
      "Episode  4508 : Reward =  -2344.9709405303\n",
      "Episode  4509 : Reward =  -2536.625073708515\n",
      "Episode  4510 : Reward =  -2338.6557794213295\n",
      "Episode  4511 : Reward =  -2230.7395704984665\n",
      "Saving better model at episode 4511 with reward -2230.7395704984665\n",
      "Episode  4512 : Reward =  -2298.3371530858385\n",
      "Episode  4513 : Reward =  -2473.9181345141546\n",
      "Episode  4514 : Reward =  -2440.4654491906113\n",
      "Episode  4515 : Reward =  -2475.5353433861537\n",
      "Episode  4516 : Reward =  -2250.0160180926323\n",
      "Episode  4517 : Reward =  -2304.266363441944\n",
      "Episode  4518 : Reward =  -2480.2979262507574\n",
      "Episode  4519 : Reward =  -2304.985602617264\n",
      "Episode  4520 : Reward =  -2387.759658519091\n",
      "Episode  4521 : Reward =  -2481.740906957449\n",
      "Episode  4522 : Reward =  -2396.09140057243\n",
      "Episode  4523 : Reward =  -2527.5137177792894\n",
      "Episode  4524 : Reward =  -2375.410514808172\n",
      "Episode  4525 : Reward =  -2433.9924530386925\n",
      "Episode  4526 : Reward =  -2410.86649495727\n",
      "Episode  4527 : Reward =  -2532.0835233702464\n",
      "Episode  4528 : Reward =  -2396.8363729715347\n",
      "Episode  4529 : Reward =  -2332.5232449769974\n",
      "Episode  4530 : Reward =  -2578.6596595136034\n",
      "Episode  4531 : Reward =  -2449.1988362110274\n",
      "Episode  4532 : Reward =  -2576.6617446317478\n",
      "Episode  4533 : Reward =  -2484.775947332382\n",
      "Episode  4534 : Reward =  -2481.9651333093643\n",
      "Episode  4535 : Reward =  -2496.40466169166\n",
      "Episode  4536 : Reward =  -2507.11914871639\n",
      "Episode  4537 : Reward =  -2420.867174245338\n",
      "Episode  4538 : Reward =  -2488.6318404761655\n",
      "Episode  4539 : Reward =  -2389.6608278751373\n",
      "Episode  4540 : Reward =  -2545.1989593680782\n",
      "Episode  4541 : Reward =  -2457.0220006791455\n",
      "Episode  4542 : Reward =  -2523.039632264437\n",
      "Episode  4543 : Reward =  -2467.4677337779804\n",
      "Episode  4544 : Reward =  -2453.9614107049124\n",
      "Episode  4545 : Reward =  -2678.8279242291255\n",
      "Episode  4546 : Reward =  -2656.3682282567024\n",
      "Episode  4547 : Reward =  -2543.6889978051186\n",
      "Episode  4548 : Reward =  -2578.7728762713773\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4549 : Reward =  -2542.8901153578568\n",
      "Episode  4550 : Reward =  -2537.8221265164716\n",
      "Episode  4551 : Reward =  -2597.7346168756485\n",
      "Episode  4552 : Reward =  -2430.2908105254173\n",
      "Episode  4553 : Reward =  -2383.449492815794\n",
      "Episode  4554 : Reward =  -2304.653461396694\n",
      "Episode  4555 : Reward =  -2358.249863807024\n",
      "Episode  4556 : Reward =  -2371.8376804365917\n",
      "Episode  4557 : Reward =  -2367.239977300167\n",
      "Episode  4558 : Reward =  -2219.4384751319885\n",
      "Saving better model at episode 4558 with reward -2219.4384751319885\n",
      "Episode  4559 : Reward =  -2347.0347370505333\n",
      "Episode  4560 : Reward =  -2431.1105249524117\n",
      "Episode  4561 : Reward =  -2479.5544504559653\n",
      "Episode  4562 : Reward =  -2453.959303379059\n",
      "Episode  4563 : Reward =  -2316.1684027314186\n",
      "Episode  4564 : Reward =  -2357.6526839733124\n",
      "Episode  4565 : Reward =  -2331.452481687069\n",
      "Episode  4566 : Reward =  -2350.6393654346466\n",
      "Episode  4567 : Reward =  -2367.235190987587\n",
      "Episode  4568 : Reward =  -2326.7688632011414\n",
      "Episode  4569 : Reward =  -2342.2279666662216\n",
      "Episode  4570 : Reward =  -2264.408473968506\n",
      "Episode  4571 : Reward =  -2327.442231953144\n",
      "Episode  4572 : Reward =  -2375.213062652718\n",
      "Episode  4573 : Reward =  -2256.560270667076\n",
      "Episode  4574 : Reward =  -2294.289464533329\n",
      "Episode  4575 : Reward =  -2337.4887560606003\n",
      "Episode  4576 : Reward =  -2280.2557613886015\n",
      "Episode  4577 : Reward =  -2406.358729398722\n",
      "Episode  4578 : Reward =  -2296.872073471546\n",
      "Episode  4579 : Reward =  -2320.2805084026472\n",
      "Episode  4580 : Reward =  -2312.8520678914206\n",
      "Episode  4581 : Reward =  -2324.1798605918884\n",
      "Episode  4582 : Reward =  -2279.943267285824\n",
      "Episode  4583 : Reward =  -2340.2577647007124\n",
      "Episode  4584 : Reward =  -2338.3603455460684\n",
      "Episode  4585 : Reward =  -2389.3918682188387\n",
      "Episode  4586 : Reward =  -2352.495873156847\n",
      "Episode  4587 : Reward =  -2288.402067848812\n",
      "Episode  4588 : Reward =  -2367.338412679653\n",
      "Episode  4589 : Reward =  -2269.0973781347275\n",
      "Episode  4590 : Reward =  -2289.266966164112\n",
      "Episode  4591 : Reward =  -2317.615785717964\n",
      "Episode  4592 : Reward =  -2256.646190413605\n",
      "Episode  4593 : Reward =  -2269.623576346697\n",
      "Episode  4594 : Reward =  -2433.8354467749596\n",
      "Episode  4595 : Reward =  -2316.393993023695\n",
      "Episode  4596 : Reward =  -2438.6751243247795\n",
      "Episode  4597 : Reward =  -2282.659276664257\n",
      "Episode  4598 : Reward =  -2256.2381780147552\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4599 : Reward =  -2281.0174446702003\n",
      "Episode  4600 : Reward =  -2274.0642221010344\n",
      "Episode  4601 : Reward =  -2351.3534354929866\n",
      "Episode  4602 : Reward =  -2341.3820913805766\n",
      "Episode  4603 : Reward =  -2242.0921870470047\n",
      "Episode  4604 : Reward =  -2252.5237908363342\n",
      "Episode  4605 : Reward =  -2373.1017839078845\n",
      "Episode  4606 : Reward =  -2193.0138037204742\n",
      "Saving better model at episode 4606 with reward -2193.0138037204742\n",
      "Episode  4607 : Reward =  -2265.7187356352806\n",
      "Episode  4608 : Reward =  -2429.434852696876\n",
      "Episode  4609 : Reward =  -2211.948326051235\n",
      "Episode  4610 : Reward =  -2292.68976521492\n",
      "Episode  4611 : Reward =  -2359.0153041569097\n",
      "Episode  4612 : Reward =  -2238.2150360941887\n",
      "Episode  4613 : Reward =  -2283.0015654004233\n",
      "Episode  4614 : Reward =  -2296.4515295996475\n",
      "Episode  4615 : Reward =  -2288.3307232623047\n",
      "Episode  4616 : Reward =  -2399.174543861212\n",
      "Episode  4617 : Reward =  -2384.056315764844\n",
      "Episode  4618 : Reward =  -2245.4983020424843\n",
      "Episode  4619 : Reward =  -2239.870650947094\n",
      "Episode  4620 : Reward =  -2297.168659076154\n",
      "Episode  4621 : Reward =  -2278.406854569912\n",
      "Episode  4622 : Reward =  -2262.5771320462227\n",
      "Episode  4623 : Reward =  -2293.14207879446\n",
      "Episode  4624 : Reward =  -2296.125098594795\n",
      "Episode  4625 : Reward =  -2306.2238774075317\n",
      "Episode  4626 : Reward =  -2225.202274564566\n",
      "Episode  4627 : Reward =  -2369.666211673389\n",
      "Episode  4628 : Reward =  -2314.883708715439\n",
      "Episode  4629 : Reward =  -2353.333368576984\n",
      "Episode  4630 : Reward =  -2334.740652121525\n",
      "Episode  4631 : Reward =  -2158.1266798377037\n",
      "Saving better model at episode 4631 with reward -2158.1266798377037\n",
      "Episode  4632 : Reward =  -2314.015606764616\n",
      "Episode  4633 : Reward =  -2322.937693897547\n",
      "Episode  4634 : Reward =  -2273.3975598303186\n",
      "Episode  4635 : Reward =  -2332.079360462646\n",
      "Episode  4636 : Reward =  -2243.121993660927\n",
      "Episode  4637 : Reward =  -2270.1350294947624\n",
      "Episode  4638 : Reward =  -2340.1423232406974\n",
      "Episode  4639 : Reward =  -2425.951247402798\n",
      "Episode  4640 : Reward =  -2286.787472784519\n",
      "Episode  4641 : Reward =  -2294.6615161075397\n",
      "Episode  4642 : Reward =  -2329.7816800562246\n",
      "Episode  4643 : Reward =  -2323.3086987820966\n",
      "Episode  4644 : Reward =  -2318.546297296941\n",
      "Episode  4645 : Reward =  -2294.584609314859\n",
      "Episode  4646 : Reward =  -2262.723825573921\n",
      "Episode  4647 : Reward =  -2303.7945198453085\n",
      "Episode  4648 : Reward =  -2259.3432695641322\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4649 : Reward =  -2237.6016297972815\n",
      "Episode  4650 : Reward =  -2254.9088816046715\n",
      "Episode  4651 : Reward =  -2271.421759012999\n",
      "Episode  4652 : Reward =  -2307.3053852319717\n",
      "Episode  4653 : Reward =  -2194.202617585659\n",
      "Episode  4654 : Reward =  -2332.3996467366023\n",
      "Episode  4655 : Reward =  -2212.0801895943982\n",
      "Episode  4656 : Reward =  -2317.8746433033753\n",
      "Episode  4657 : Reward =  -2250.461384356022\n",
      "Episode  4658 : Reward =  -2402.4912066822\n",
      "Episode  4659 : Reward =  -2251.0989565340383\n",
      "Episode  4660 : Reward =  -2116.163500070572\n",
      "Saving better model at episode 4660 with reward -2116.163500070572\n",
      "Episode  4661 : Reward =  -2238.041816651821\n",
      "Episode  4662 : Reward =  -2203.475484374823\n",
      "Episode  4663 : Reward =  -2348.213642813186\n",
      "Episode  4664 : Reward =  -2193.1321789388603\n",
      "Episode  4665 : Reward =  -2490.23924456524\n",
      "Episode  4666 : Reward =  -2291.0442199473323\n",
      "Episode  4667 : Reward =  -2203.1928409337997\n",
      "Episode  4668 : Reward =  -2182.447840452194\n",
      "Episode  4669 : Reward =  -2423.176958844125\n",
      "Episode  4670 : Reward =  -2186.978594303131\n",
      "Episode  4671 : Reward =  -2248.216032385826\n",
      "Episode  4672 : Reward =  -2345.7812655419702\n",
      "Episode  4673 : Reward =  -2450.153043970338\n",
      "Episode  4674 : Reward =  -2279.476968622679\n",
      "Episode  4675 : Reward =  -2345.1302051310486\n",
      "Episode  4676 : Reward =  -2230.0073336958885\n",
      "Episode  4677 : Reward =  -2295.8402201024396\n",
      "Episode  4678 : Reward =  -2244.066886076103\n",
      "Episode  4679 : Reward =  -2376.376003183346\n",
      "Episode  4680 : Reward =  -2254.619169175625\n",
      "Episode  4681 : Reward =  -2096.078100034367\n",
      "Saving better model at episode 4681 with reward -2096.078100034367\n",
      "Episode  4682 : Reward =  -2285.5154481566565\n",
      "Episode  4683 : Reward =  -2156.06720495224\n",
      "Episode  4684 : Reward =  -2203.4254486597197\n",
      "Episode  4685 : Reward =  -2299.403935469608\n",
      "Episode  4686 : Reward =  -2206.0301655567305\n",
      "Episode  4687 : Reward =  -2160.062771856785\n",
      "Episode  4688 : Reward =  -2243.7164101600647\n",
      "Episode  4689 : Reward =  -2320.266106668772\n",
      "Episode  4690 : Reward =  -2237.2767189232213\n",
      "Episode  4691 : Reward =  -2113.0608132481575\n",
      "Episode  4692 : Reward =  -2161.139606654644\n",
      "Episode  4693 : Reward =  -2114.5822960770743\n",
      "Episode  4694 : Reward =  -2217.0750744109096\n",
      "Episode  4695 : Reward =  -2165.8849400281906\n",
      "Episode  4696 : Reward =  -2183.208394829096\n",
      "Episode  4697 : Reward =  -2220.7141627435626\n",
      "Episode  4698 : Reward =  -2095.126167241396\n",
      "Saving better model at episode 4698 with reward -2095.126167241396\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4699 : Reward =  -2171.941891380917\n",
      "Episode  4700 : Reward =  -2245.0561424269486\n",
      "Episode  4701 : Reward =  -2126.716571453871\n",
      "Episode  4702 : Reward =  -2313.5468667001123\n",
      "Episode  4703 : Reward =  -2143.720885047089\n",
      "Episode  4704 : Reward =  -2060.0207027196884\n",
      "Saving better model at episode 4704 with reward -2060.0207027196884\n",
      "Episode  4705 : Reward =  -2103.3718717098236\n",
      "Episode  4706 : Reward =  -2240.6235222395353\n",
      "Episode  4707 : Reward =  -2067.3058242834227\n",
      "Episode  4708 : Reward =  -2038.390731394291\n",
      "Saving better model at episode 4708 with reward -2038.390731394291\n",
      "Episode  4709 : Reward =  -2232.632834741245\n",
      "Episode  4710 : Reward =  -2328.8925478820743\n",
      "Episode  4711 : Reward =  -2232.3293377161026\n",
      "Episode  4712 : Reward =  -2246.4933542609215\n",
      "Episode  4713 : Reward =  -2227.1270722150803\n",
      "Episode  4714 : Reward =  -2226.193346142769\n",
      "Episode  4715 : Reward =  -2412.274545210211\n",
      "Episode  4716 : Reward =  -2242.2071735349996\n",
      "Episode  4717 : Reward =  -2345.55746663488\n",
      "Episode  4718 : Reward =  -2535.584146237339\n",
      "Episode  4719 : Reward =  -2189.633448123932\n",
      "Episode  4720 : Reward =  -2638.296445047822\n",
      "Episode  4721 : Reward =  -2169.3193323612213\n",
      "Episode  4722 : Reward =  -2283.864473172794\n",
      "Episode  4723 : Reward =  -2206.474330484867\n",
      "Episode  4724 : Reward =  -2342.329341420303\n",
      "Episode  4725 : Reward =  -2340.2576728834915\n",
      "Episode  4726 : Reward =  -2402.823494777143\n",
      "Episode  4727 : Reward =  -2246.053788069548\n",
      "Episode  4728 : Reward =  -2381.8101571574016\n",
      "Episode  4729 : Reward =  -2298.4263026714325\n",
      "Episode  4730 : Reward =  -2355.1516830325127\n",
      "Episode  4731 : Reward =  -2307.558404210867\n",
      "Episode  4732 : Reward =  -2267.097985602836\n",
      "Episode  4733 : Reward =  -2257.53561479217\n",
      "Episode  4734 : Reward =  -2314.3769595063345\n",
      "Episode  4735 : Reward =  -2361.1781242861557\n",
      "Episode  4736 : Reward =  -2365.8652996457236\n",
      "Episode  4737 : Reward =  -2187.8350069522858\n",
      "Episode  4738 : Reward =  -2470.0605307669043\n",
      "Episode  4739 : Reward =  -2264.249715268612\n",
      "Episode  4740 : Reward =  -2368.253287590961\n",
      "Episode  4741 : Reward =  -2392.8081780163157\n",
      "Episode  4742 : Reward =  -2472.8892769069075\n",
      "Episode  4743 : Reward =  -2311.2357502616064\n",
      "Episode  4744 : Reward =  -2402.5484558715625\n",
      "Episode  4745 : Reward =  -2339.4660322702543\n",
      "Episode  4746 : Reward =  -2259.648058239283\n",
      "Episode  4747 : Reward =  -2261.7987844944\n",
      "Episode  4748 : Reward =  -2256.7921740449087\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4749 : Reward =  -2319.9903942978995\n",
      "Episode  4750 : Reward =  -2343.375093638897\n",
      "Episode  4751 : Reward =  -2362.9281402602005\n",
      "Episode  4752 : Reward =  -2388.394372586073\n",
      "Episode  4753 : Reward =  -2365.4283094493253\n",
      "Episode  4754 : Reward =  -2327.9585318005697\n",
      "Episode  4755 : Reward =  -2586.2817965597505\n",
      "Episode  4756 : Reward =  -2446.7405970542345\n",
      "Episode  4757 : Reward =  -2231.7423921859877\n",
      "Episode  4758 : Reward =  -2291.1828827261925\n",
      "Episode  4759 : Reward =  -2477.008316077213\n",
      "Episode  4760 : Reward =  -2345.7714475168987\n",
      "Episode  4761 : Reward =  -2239.187629558067\n",
      "Episode  4762 : Reward =  -2424.580071705191\n",
      "Episode  4763 : Reward =  -2337.2964286579895\n",
      "Episode  4764 : Reward =  -2246.9521448016167\n",
      "Episode  4765 : Reward =  -2260.7657104170935\n",
      "Episode  4766 : Reward =  -2237.6201120615005\n",
      "Episode  4767 : Reward =  -2165.7122505307198\n",
      "Episode  4768 : Reward =  -2408.243692613119\n",
      "Episode  4769 : Reward =  -2343.1291927186353\n",
      "Episode  4770 : Reward =  -2334.676688492298\n",
      "Episode  4771 : Reward =  -2241.624771539034\n",
      "Episode  4772 : Reward =  -2277.4715493408544\n",
      "Episode  4773 : Reward =  -2293.706804931164\n",
      "Episode  4774 : Reward =  -2180.67587608099\n",
      "Episode  4775 : Reward =  -2514.071512207448\n",
      "Episode  4776 : Reward =  -2253.52261865139\n",
      "Episode  4777 : Reward =  -2312.1896963715553\n",
      "Episode  4778 : Reward =  -2392.64898685358\n",
      "Episode  4779 : Reward =  -2274.9531863331795\n",
      "Episode  4780 : Reward =  -2236.5490581429617\n",
      "Episode  4781 : Reward =  -2235.2664390802383\n",
      "Episode  4782 : Reward =  -2301.9555631367075\n",
      "Episode  4783 : Reward =  -2266.754310131073\n",
      "Episode  4784 : Reward =  -2428.8901090993686\n",
      "Episode  4785 : Reward =  -2408.3060580343604\n",
      "Episode  4786 : Reward =  -2143.1474573016167\n",
      "Episode  4787 : Reward =  -2323.299485385418\n",
      "Episode  4788 : Reward =  -2379.3835087780894\n",
      "Episode  4789 : Reward =  -2120.4690529195177\n",
      "Episode  4790 : Reward =  -2152.0022429823875\n",
      "Episode  4791 : Reward =  -2404.1486639742798\n",
      "Episode  4792 : Reward =  -2307.7846835031314\n",
      "Episode  4793 : Reward =  -2349.725211867462\n",
      "Episode  4794 : Reward =  -2284.1034905090137\n",
      "Episode  4795 : Reward =  -2211.8933730161802\n",
      "Episode  4796 : Reward =  -2219.5633564082486\n",
      "Episode  4797 : Reward =  -2252.3050636053085\n",
      "Episode  4798 : Reward =  -2179.2802978157997\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4799 : Reward =  -2227.970739722252\n",
      "Episode  4800 : Reward =  -2320.662048765789\n",
      "Episode  4801 : Reward =  -2225.497707614075\n",
      "Episode  4802 : Reward =  -2563.4654049043597\n",
      "Episode  4803 : Reward =  -2283.921861359249\n",
      "Episode  4804 : Reward =  -2367.7217302409513\n",
      "Episode  4805 : Reward =  -2229.5606696605682\n",
      "Episode  4806 : Reward =  -2239.066907171072\n",
      "Episode  4807 : Reward =  -2311.360058614384\n",
      "Episode  4808 : Reward =  -2237.8917448011744\n",
      "Episode  4809 : Reward =  -2265.720356441955\n",
      "Episode  4810 : Reward =  -2426.8197793130817\n",
      "Episode  4811 : Reward =  -2282.860280403267\n",
      "Episode  4812 : Reward =  -2097.974580705166\n",
      "Episode  4813 : Reward =  -2225.9352103558886\n",
      "Episode  4814 : Reward =  -2108.4277331233025\n",
      "Episode  4815 : Reward =  -2315.1289123744364\n",
      "Episode  4816 : Reward =  -2276.9953332034456\n",
      "Episode  4817 : Reward =  -2055.7819018363953\n",
      "Episode  4818 : Reward =  -2301.659961113106\n",
      "Episode  4819 : Reward =  -2149.777900636196\n",
      "Episode  4820 : Reward =  -2242.935268465342\n",
      "Episode  4821 : Reward =  -2243.3400774002075\n",
      "Episode  4822 : Reward =  -2034.204410135746\n",
      "Saving better model at episode 4822 with reward -2034.204410135746\n",
      "Episode  4823 : Reward =  -2486.0874460711284\n",
      "Episode  4824 : Reward =  -1992.6616621017456\n",
      "Saving better model at episode 4824 with reward -1992.6616621017456\n",
      "Episode  4825 : Reward =  -2079.2616530656815\n",
      "Episode  4826 : Reward =  -2284.114236239256\n",
      "Episode  4827 : Reward =  -2404.757468644442\n",
      "Episode  4828 : Reward =  -2198.614001274109\n",
      "Episode  4829 : Reward =  -2214.4018148183823\n",
      "Episode  4830 : Reward =  -2184.9100994467735\n",
      "Episode  4831 : Reward =  -2359.7577692306654\n",
      "Episode  4832 : Reward =  -2093.9044675827026\n",
      "Episode  4833 : Reward =  -2464.1095270962114\n",
      "Episode  4834 : Reward =  -2165.042323231697\n",
      "Episode  4835 : Reward =  -2279.747755173506\n",
      "Episode  4836 : Reward =  -2204.885202058922\n",
      "Episode  4837 : Reward =  -2068.106726169586\n",
      "Episode  4838 : Reward =  -2207.2654565609114\n",
      "Episode  4839 : Reward =  -2113.9133880734444\n",
      "Episode  4840 : Reward =  -2219.010710954666\n",
      "Episode  4841 : Reward =  -2025.3715257048607\n",
      "Episode  4842 : Reward =  -2323.6803360357094\n",
      "Episode  4843 : Reward =  -2317.788253435265\n",
      "Episode  4844 : Reward =  -2485.5288939327593\n",
      "Episode  4845 : Reward =  -2248.0905987060682\n",
      "Episode  4846 : Reward =  -2117.4910415410995\n",
      "Episode  4847 : Reward =  -2181.993683516979\n",
      "Episode  4848 : Reward =  -2332.948285378437\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4849 : Reward =  -2268.970013627182\n",
      "Episode  4850 : Reward =  -2201.4161509362566\n",
      "Episode  4851 : Reward =  -2247.511235296726\n",
      "Episode  4852 : Reward =  -2296.0706661715312\n",
      "Episode  4853 : Reward =  -2112.528727531433\n",
      "Episode  4854 : Reward =  -2218.3209193348885\n",
      "Episode  4855 : Reward =  -2170.5284336209297\n",
      "Episode  4856 : Reward =  -2165.5011922208173\n",
      "Episode  4857 : Reward =  -2108.2801095843315\n",
      "Episode  4858 : Reward =  -2320.791782680811\n",
      "Episode  4859 : Reward =  -2210.880687955679\n",
      "Episode  4860 : Reward =  -2037.5644450187683\n",
      "Episode  4861 : Reward =  -2299.6417657136917\n",
      "Episode  4862 : Reward =  -2268.9830069578306\n",
      "Episode  4863 : Reward =  -2126.57070761919\n",
      "Episode  4864 : Reward =  -2205.7807994260597\n",
      "Episode  4865 : Reward =  -2347.2629796118135\n",
      "Episode  4866 : Reward =  -2165.796946167946\n",
      "Episode  4867 : Reward =  -2098.541459619999\n",
      "Episode  4868 : Reward =  -2357.32427982139\n",
      "Episode  4869 : Reward =  -2260.519980975758\n",
      "Episode  4870 : Reward =  -2081.249253332615\n",
      "Episode  4871 : Reward =  -2231.0950319767\n",
      "Episode  4872 : Reward =  -2205.102683365345\n",
      "Episode  4873 : Reward =  -2041.586444079876\n",
      "Episode  4874 : Reward =  -2325.8516390695377\n",
      "Episode  4875 : Reward =  -2384.811027980322\n",
      "Episode  4876 : Reward =  -2142.864375293255\n",
      "Episode  4877 : Reward =  -2302.6084108985083\n",
      "Episode  4878 : Reward =  -2245.9562591090007\n",
      "Episode  4879 : Reward =  -2315.600619897306\n",
      "Episode  4880 : Reward =  -2057.711850106716\n",
      "Episode  4881 : Reward =  -2113.940992895426\n",
      "Episode  4882 : Reward =  -2205.1146519816534\n",
      "Episode  4883 : Reward =  -2211.7520748739184\n",
      "Episode  4884 : Reward =  -2113.0167173779623\n",
      "Episode  4885 : Reward =  -2069.197405576706\n",
      "Episode  4886 : Reward =  -2375.0904933065767\n",
      "Episode  4887 : Reward =  -1946.7963824868202\n",
      "Saving better model at episode 4887 with reward -1946.7963824868202\n",
      "Episode  4888 : Reward =  -2053.580815255642\n",
      "Episode  4889 : Reward =  -2233.856540955524\n",
      "Episode  4890 : Reward =  -2281.155408803286\n",
      "Episode  4891 : Reward =  -2034.2633471488953\n",
      "Episode  4892 : Reward =  -2333.2974349943506\n",
      "Episode  4893 : Reward =  -2092.9595532417297\n",
      "Episode  4894 : Reward =  -1972.857054233551\n",
      "Episode  4895 : Reward =  -2287.432239774527\n",
      "Episode  4896 : Reward =  -2106.366160929203\n",
      "Episode  4897 : Reward =  -2055.2751972079277\n",
      "Episode  4898 : Reward =  -2314.1185067979204\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4899 : Reward =  -2268.8598842657225\n",
      "Episode  4900 : Reward =  -2016.6982848644257\n",
      "Episode  4901 : Reward =  -2142.2662945389748\n",
      "Episode  4902 : Reward =  -2327.9788950457378\n",
      "Episode  4903 : Reward =  -2078.955661058426\n",
      "Episode  4904 : Reward =  -2506.2292368769313\n",
      "Episode  4905 : Reward =  -2078.7117830551283\n",
      "Episode  4906 : Reward =  -1938.0150896310806\n",
      "Saving better model at episode 4906 with reward -1938.0150896310806\n",
      "Episode  4907 : Reward =  -2176.404015302658\n",
      "Episode  4908 : Reward =  -2043.5707419551031\n",
      "Episode  4909 : Reward =  -2179.5661168134825\n",
      "Episode  4910 : Reward =  -2121.4905465928423\n",
      "Episode  4911 : Reward =  -2121.9643146395683\n",
      "Episode  4912 : Reward =  -2204.6083852735865\n",
      "Episode  4913 : Reward =  -2366.995518422598\n",
      "Episode  4914 : Reward =  -2151.10595745212\n",
      "Episode  4915 : Reward =  -2064.1060493588448\n",
      "Episode  4916 : Reward =  -2042.4516521692276\n",
      "Episode  4917 : Reward =  -2088.4952211380005\n",
      "Episode  4918 : Reward =  -2201.444541219534\n",
      "Episode  4919 : Reward =  -2065.899820748629\n",
      "Episode  4920 : Reward =  -2160.085394743742\n",
      "Episode  4921 : Reward =  -2162.108078900637\n",
      "Episode  4922 : Reward =  -2164.643659234047\n",
      "Episode  4923 : Reward =  -2260.7711475491524\n",
      "Episode  4924 : Reward =  -2119.529231735836\n",
      "Episode  4925 : Reward =  -2084.979161152016\n",
      "Episode  4926 : Reward =  -2125.1599822676794\n",
      "Episode  4927 : Reward =  -2189.463088580738\n",
      "Episode  4928 : Reward =  -2069.0930153131485\n",
      "Episode  4929 : Reward =  -2123.6035636663437\n",
      "Episode  4930 : Reward =  -2328.8445697798534\n",
      "Episode  4931 : Reward =  -2176.3033083081245\n",
      "Episode  4932 : Reward =  -2176.896278086962\n",
      "Episode  4933 : Reward =  -2117.0987619161606\n",
      "Episode  4934 : Reward =  -2070.9922080636024\n",
      "Episode  4935 : Reward =  -2128.3814601898193\n",
      "Episode  4936 : Reward =  -2059.3701125383377\n",
      "Episode  4937 : Reward =  -2225.288707651119\n",
      "Episode  4938 : Reward =  -2083.747008562088\n",
      "Episode  4939 : Reward =  -2156.483324829401\n",
      "Episode  4940 : Reward =  -2184.6530537045614\n",
      "Episode  4941 : Reward =  -2196.7947116530554\n",
      "Episode  4942 : Reward =  -2213.061749994755\n",
      "Episode  4943 : Reward =  -2094.353327333927\n",
      "Episode  4944 : Reward =  -2222.7242810726166\n",
      "Episode  4945 : Reward =  -2228.893671274185\n",
      "Episode  4946 : Reward =  -2049.9560890197754\n",
      "Episode  4947 : Reward =  -2172.441874751221\n",
      "Episode  4948 : Reward =  -2311.3136296868324\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4949 : Reward =  -2288.220190525055\n",
      "Episode  4950 : Reward =  -2243.7313643781054\n",
      "Episode  4951 : Reward =  -2219.447517812252\n",
      "Episode  4952 : Reward =  -2192.0361271500587\n",
      "Episode  4953 : Reward =  -2254.586150109768\n",
      "Episode  4954 : Reward =  -2289.729460064234\n",
      "Episode  4955 : Reward =  -2193.661523461342\n",
      "Episode  4956 : Reward =  -2280.818895701231\n",
      "Episode  4957 : Reward =  -2179.2688546180725\n",
      "Episode  4958 : Reward =  -2316.5579732096808\n",
      "Episode  4959 : Reward =  -2349.585643955837\n",
      "Episode  4960 : Reward =  -2181.249197602272\n",
      "Episode  4961 : Reward =  -2167.499641895294\n",
      "Episode  4962 : Reward =  -2272.781080842018\n",
      "Episode  4963 : Reward =  -2279.56465280056\n",
      "Episode  4964 : Reward =  -2299.714861938129\n",
      "Episode  4965 : Reward =  -2361.9117414130974\n",
      "Episode  4966 : Reward =  -2501.232014335613\n",
      "Episode  4967 : Reward =  -2215.7323625683784\n",
      "Episode  4968 : Reward =  -2277.6808814406395\n",
      "Episode  4969 : Reward =  -2423.97276658691\n",
      "Episode  4970 : Reward =  -2319.6258173672068\n",
      "Episode  4971 : Reward =  -2248.6383735909267\n",
      "Episode  4972 : Reward =  -2254.330952346325\n",
      "Episode  4973 : Reward =  -2429.4197878603877\n",
      "Episode  4974 : Reward =  -2211.2367140054703\n",
      "Episode  4975 : Reward =  -2376.927728954615\n",
      "Episode  4976 : Reward =  -2381.909066081047\n",
      "Episode  4977 : Reward =  -2437.30111204075\n",
      "Episode  4978 : Reward =  -2265.910032037558\n",
      "Episode  4979 : Reward =  -2342.512266680658\n",
      "Episode  4980 : Reward =  -2276.5157861709595\n",
      "Episode  4981 : Reward =  -2261.513067305088\n",
      "Episode  4982 : Reward =  -2201.9826113618033\n",
      "Episode  4983 : Reward =  -2301.1993629336357\n",
      "Episode  4984 : Reward =  -2217.481693148613\n",
      "Episode  4985 : Reward =  -2151.565100610256\n",
      "Episode  4986 : Reward =  -2313.959475494842\n",
      "Episode  4987 : Reward =  -2168.093078672886\n",
      "Episode  4988 : Reward =  -2383.185685042204\n",
      "Episode  4989 : Reward =  -2130.944957435131\n",
      "Episode  4990 : Reward =  -2293.9919353163855\n",
      "Episode  4991 : Reward =  -2361.84560815237\n",
      "Episode  4992 : Reward =  -2308.046619716944\n",
      "Episode  4993 : Reward =  -2136.953972876072\n",
      "Episode  4994 : Reward =  -2218.2116483449936\n",
      "Episode  4995 : Reward =  -2211.7407441735268\n",
      "Episode  4996 : Reward =  -2208.182623922825\n",
      "Episode  4997 : Reward =  -2160.2670731544495\n",
      "Episode  4998 : Reward =  -2273.457483176054\n",
      "--------------------------------------------------------------------------------------------\n",
      "setting actor output action_std to min_action_std :  0.1\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode  4999 : Reward =  -2189.8750725388527\n",
      "Episode  5000 : Reward =  -2144.2756514549255\n"
     ]
    }
   ],
   "source": [
    "################################### Training ###################################\n",
    "\n",
    "\n",
    "####### initialize environment hyperparameters ######\n",
    "\n",
    "has_continuous_action_space = True #không gian action rời rạc\n",
    "best_reward = -float('inf')  # ban đầu là âm vô cực\n",
    "max_ep_len = 1000                    # max timesteps in one episode\n",
    "max_training_timesteps = int(5000000)   # break training loop if timeteps > max_training_timesteps -- dừng train khi số bước vượt quá\n",
    "\n",
    "print_freq = max_ep_len * 4     # print avg reward in the interval (in num timesteps)\n",
    "log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
    "\n",
    "\n",
    "action_std = 0.5\n",
    "action_std_decay_rate = 0.005\n",
    "min_action_std = 0.1\n",
    "action_std_decay_freq = 50000\n",
    "\n",
    "################ PPO hyperparameters ################\n",
    "\n",
    "update_timestep = 2048    # update policy every n timesteps -- cập nhật policy\n",
    "K_epochs = 80               # update policy for K epochs -- số lần lặp tối ưu trên 1 batch dữ liệu\n",
    "eps_clip = 0.2              # clip parameter for PPO \n",
    "gamma = 0.99                # discount factor\n",
    "lambda_gae = 0\n",
    "lr_actor = 0.0002       # learning rate for actor network\n",
    "lr_critic = 0.0002       # learning rate for critic network\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "################## Environment parameters ##############\n",
    "lambda_rate = 200\n",
    "D_max = 5\n",
    "xi = 0.01\n",
    "max_power = - (2 ** (lambda_rate/200)-1)/(math.log10(1-(xi**(D_max**-1)/D_max)))\n",
    "snr_feedback=True,# Có phản hồi SNR\n",
    "harq_type='IR'\n",
    "\n",
    "env = ENV_paper(lambda_rate, D_max, xi, max_power, snr_feedback, harq_type)\n",
    "\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "# print(\"save checkpoint path : \" + checkpoint_path)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "############# print all hyperparameters #############\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"max training timesteps : \", max_training_timesteps)\n",
    "print(\"max timesteps per episode : \", max_ep_len)\n",
    "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
    "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"state space dimension : \", state_dim)\n",
    "print(\"action space dimension : \", action_dim)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "if has_continuous_action_space:\n",
    "    print(\"Initializing a continuous action space policy\")\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"starting std of action distribution : \", action_std)\n",
    "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
    "    print(\"minimum std of action distribution : \", min_action_std)\n",
    "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
    "\n",
    "else:\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\")\n",
    "print(\"PPO K epochs : \", K_epochs)\n",
    "print(\"PPO epsilon clip : \", eps_clip)\n",
    "print(\"discount factor (gamma) : \", gamma)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"optimizer learning rate actor : \", lr_actor)\n",
    "print(\"optimizer learning rate critic : \", lr_critic)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "################# training procedure ################\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma,lambda_gae, K_epochs, eps_clip, has_continuous_action_space, action_std, minibatch_size = 128)\n",
    "\n",
    "\n",
    "# printing and logging variables\n",
    "# print_running_reward = 0\n",
    "# print_running_episodes = 0\n",
    "\n",
    "# log_running_reward = 0\n",
    "# log_running_episodes = 0\n",
    "\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "\n",
    "\n",
    "# training loop\n",
    "while time_step <= max_training_timesteps: #vòng lặp dừng khi vượt quá max_time_step\n",
    "\n",
    "    state = env.reset() #trả về trạng thái ban đầu \n",
    "\n",
    "    # Check if state is tuple\n",
    "    if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "\n",
    "    current_ep_reward = 0 #tổng phần thưởng trong episode hiện tại\n",
    "\n",
    "    for t in range(1, max_ep_len+1): #chạy tối đa 500 bước\n",
    "\n",
    "        # select action with policy\n",
    "        action = ppo_agent.select_action(state) #chọn action cho state dự vào policy hiện tại\n",
    "        state, reward, done, info = env.step(action) #thực hiện hành động và nhận phản hồi\n",
    "\n",
    "        # saving reward and is_terminals vào buffer\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done \n",
    "        )\n",
    "\n",
    "        time_step +=1\n",
    "        current_ep_reward += reward\n",
    "        if i_episode == 10000:\n",
    "            print(info)\n",
    "        #print(info)\n",
    "\n",
    "        # update PPO agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent.update() #cập nhật lại policy nếu đủ số bước\n",
    "\n",
    "        # if continuous action space; then decay action std of ouput action distribution\n",
    "        # Nếu không gian hành động là liên tục, giảm độ lệch chuẩn để chuyển từ khám phá sang khai thác\n",
    "\n",
    "\n",
    "        # break; if the episode is over\n",
    "        if done:\n",
    "            break\n",
    "    if has_continuous_action_space and time_step % action_std_decay_freq == 0 :\n",
    "        ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "    print('Episode ', i_episode, ': Reward = ', current_ep_reward)\n",
    "\n",
    "    # print_running_reward += current_ep_reward\n",
    "    # print_running_episodes += 1\n",
    "\n",
    "    # log_running_reward += current_ep_reward\n",
    "    # log_running_episodes += 1\n",
    "    # Save model if reward improves\n",
    "    \n",
    "    if current_ep_reward >= best_reward:\n",
    "        print(f\"Saving better model at episode {i_episode} with reward {current_ep_reward}\")\n",
    "        best_reward = current_ep_reward\n",
    "        torch.save(ppo_agent.policy.state_dict(), 'ppo_best_model_paper.pth')\n",
    "\n",
    "\n",
    "    i_episode += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2b61858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(ppo_agent, model_path, env, num_episodes=50, max_ep_len=1000):\n",
    "    \"\"\"\n",
    "    Hàm đánh giá mô hình PPO trên nhiều episodes và chỉ in kết quả trung bình.\n",
    "    \n",
    "    Args:\n",
    "        ppo_agent (PPO): Tác nhân PPO đã được khởi tạo.\n",
    "        model_path (str): Đường dẫn đến tệp mô hình đã lưu.\n",
    "        env (gym.Env): Môi trường để đánh giá.\n",
    "        num_episodes (int): Số episodes để đánh giá (mặc định là 50).\n",
    "        max_ep_len (int): Số bước tối đa trong một episode (mặc định là 1000).\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Tải trạng thái mô hình đã lưu vào policy\n",
    "    ppo_agent.policy.load_state_dict(torch.load(model_path))\n",
    "    ppo_agent.policy.eval()\n",
    "\n",
    "    total_powers = []\n",
    "    total_rewards = []\n",
    "    total_delay_violations = []\n",
    "\n",
    "    for episode in range(1, num_episodes + 1):\n",
    "        state = env.reset()\n",
    "        if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "\n",
    "        episode_power = 0.0\n",
    "        episode_reward = 0.0\n",
    "        delay_violation = 0\n",
    "\n",
    "        for t in range(1, max_ep_len + 1):\n",
    "            # Chuyển state thành tensor\n",
    "            state_tensor = torch.FloatTensor(state).to(device)\n",
    "            \n",
    "            # Lấy giá trị trung bình từ actor\n",
    "            with torch.no_grad():\n",
    "                action_mean = ppo_agent.policy.actor(state_tensor)\n",
    "            \n",
    "            # Chuyển thành numpy array để dùng trong môi trường\n",
    "            action = action_mean.cpu().numpy()\n",
    "            \n",
    "            # Thực hiện hành động trong môi trường\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            # Lấy thông tin từ info\n",
    "            power = info.get('power', 0.0)\n",
    "            delay_violation = info.get('delay_violation', 0)\n",
    "            \n",
    "            # Cộng dồn công suất và phần thưởng\n",
    "            episode_power += power\n",
    "            episode_reward += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Lưu kết quả của episode\n",
    "        total_powers.append(episode_power)\n",
    "        total_rewards.append(episode_reward)\n",
    "        total_delay_violations.append(delay_violation)\n",
    "\n",
    "    # Tính kết quả trung bình sau 50 episodes\n",
    "    avg_total_power = np.mean(total_powers)\n",
    "    avg_average_power = np.mean([power / max_ep_len for power in total_powers])\n",
    "    avg_total_reward = np.mean(total_rewards)\n",
    "    avg_delay_violations = np.mean(total_delay_violations)\n",
    "\n",
    "    print(\"\\n--- Kết quả trung bình sau 50 episodes ---\")\n",
    "    print(f\"Trung bình tổng công suất truyền: {avg_total_power:.2f}\")\n",
    "    print(f\"Trung bình công suất truyền mỗi episode: {avg_average_power:.2f}\")\n",
    "    print(f\"Trung bình tổng Reward: {avg_total_reward:.2f}\")\n",
    "    print(f\"Trung bình số lần vi phạm độ trễ: {avg_delay_violations:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e5866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Kết quả trung bình sau 50 episodes ---\n",
      "Trung bình tổng công suất truyền: 2116.07\n",
      "Trung bình công suất truyền mỗi episode: 2.12\n",
      "Trung bình tổng Reward: -2116.08\n",
      "Trung bình số lần vi phạm độ trễ: 1.34\n"
     ]
    }
   ],
   "source": [
    "model_path = 'ppo_best_model_paper.pth'\n",
    "evaluate_model(ppo_agent, model_path, env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
