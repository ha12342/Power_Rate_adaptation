{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47fb5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\ctarg416\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\ctarg416\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (2.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\ctarg416\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\ctarg416\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\ctarg416\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (0.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41078d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371349e4",
   "metadata": {},
   "source": [
    "PAPER ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3f2a1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENV_paper():\n",
    "    def __init__(self,\n",
    "                 lambda_rate,\n",
    "                 D_max,\n",
    "                 xi,\n",
    "                 max_power,\n",
    "                 snr_feedback,\n",
    "                 harq_type):\n",
    "        \n",
    "\n",
    "        # Tham số hệ thống\n",
    "        self.lambda_rate = lambda_rate  # Tốc độ đến trung bình (bit/slot)\n",
    "        self.D_max = D_max  # Độ trễ tối đa (slot)\n",
    "        self.xi = xi  # Xác suất vi phạm độ trễ mục tiêu\n",
    "        self.max_power = max_power  # Công suất tối đa\n",
    "        self.snr_feedback = snr_feedback  # Có phản hồi SNR hay không\n",
    "        self.harq_type = harq_type  # Loại HARQ: 'CC' hoặc 'IR'\n",
    "        self.n = 200  # Số lần sử dụng kênh mỗi slot\n",
    "        self.T = int(10 / xi)  # Số slot mỗi episode\n",
    "        self.Delta = 20 * max_power  # Hằng số phạt lớn\n",
    "        self.beta = 16  # Số mũ cho hàm phạt\n",
    "\n",
    "\n",
    "        # Không gian trạng thái\n",
    "        state_dim = 4 if not snr_feedback else 5\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(state_dim,), dtype=np.float32)\n",
    "\n",
    "\n",
    "        # Không gian hành động: [R(t), p(t)]\n",
    "        self.action_space = gym.spaces.Box(low=np.array([0, 0]), high=np.array([np.inf, max_power]), dtype=np.float32)\n",
    "\n",
    "        # Bộ nhớ lịch sử A(t) cho D_max slot gần nhất\n",
    "        self.arrival_history = []\n",
    "        self.previous_snrs = []\n",
    "\n",
    "        # Khởi tạo trạng thái\n",
    "        self.reset()\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        #Đặt lại môi trường về trạng thái ban đầu\n",
    "        self.q_t = 0  # Độ dài hàng đợi\n",
    "        self.A_t = np.random.poisson(self.lambda_rate)  # Số bit đến\n",
    "        self.d_t = 0  # Số lần vi phạm độ trễ trong episode\n",
    "        self.k = 0  # Số lần truyền của gói tin hiện tại\n",
    "        self.t = 0  # đếm bước hiện tại\n",
    "        self.gamma_k = 0 if self.snr_feedback else None  # SNR còn lại\n",
    "        self.arrival_history = [self.A_t]\n",
    "        self.previous_snrs = []\n",
    "        state = [self.q_t, self.A_t, self.d_t, self.k]\n",
    "        if self.snr_feedback:\n",
    "            state.append(self.gamma_k)\n",
    "        return np.array(state)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        R_t, p_t = action  # Tốc độ mã hóa và công suất truyền\n",
    "        self.t += 1\n",
    "\n",
    "\n",
    "        R_t = max(R_t, 0)\n",
    "        p_t = np.clip(p_t, 0, self.max_power)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Mô phỏng kênh fading Rayleigh\n",
    "        h = np.random.normal(0, 1) + 1j * np.random.normal(0, 1)\n",
    "        snr = p_t * (np.abs(h)**2)\n",
    "\n",
    "\n",
    "\n",
    "        # Xác định thành công truyền\n",
    "        if self.k == 0:  # Truyền mới\n",
    "            success = np.log2(1 + snr) >= R_t\n",
    "        else:  # Truyền lại\n",
    "            if self.harq_type == 'CC':\n",
    "                if self.snr_feedback:\n",
    "                    accumulated_snr = sum(self.previous_snrs) + snr\n",
    "                    success = np.log2(1 + accumulated_snr) >= R_t\n",
    "                else:\n",
    "                    # Giả định công suất không đổi qua các lần truyền lại\n",
    "                    # Cần xem lại vì mỗi lần truyền lại p_t không đổi nhưng có h khác nhau\n",
    "                    accumulated_snr = sum(self.previous_snrs) + snr\n",
    "                    success = np.log2(1 + accumulated_snr) >= R_t\n",
    "            elif self.harq_type == 'IR':\n",
    "                if self.snr_feedback:\n",
    "                    total_rate = sum([np.log2(1 + s) for s in self.previous_snrs]) + np.log2(1 + snr)\n",
    "                    success = total_rate >= R_t\n",
    "        \n",
    "\n",
    "        \n",
    "        # Tính toán tốc độ phục vụ S(t)\n",
    "        S_t = self.n * R_t if success else 0\n",
    "\n",
    "        # Cập nhật độ dài hàng đợi tạm thời\n",
    "        q_tmp = max(self.q_t + self.A_t - S_t, 0)\n",
    "\n",
    "\n",
    "        \n",
    "        # Tính q_th(t) dựa trên lịch sử A(t) trong D_max slot\n",
    "        if len(self.arrival_history) >= self.D_max:\n",
    "            q_th = sum(self.arrival_history[-self.D_max:])\n",
    "        else:\n",
    "            q_th = sum(self.arrival_history)\n",
    "        \n",
    "        # Kiểm tra vi phạm độ trễ\n",
    "        if q_tmp > q_th:\n",
    "            self.d_t += 1\n",
    "            w_t = self._calculate_penalty()\n",
    "            reward = -p_t - w_t\n",
    "        else:\n",
    "            reward = -p_t\n",
    "        \n",
    "        # Cập nhật hàng đợi với PODD\n",
    "        self.q_t = min(q_tmp, q_th)\n",
    "\n",
    "\n",
    "\n",
    "        # Cập nhật trạng thái\n",
    "        self.A_t = np.random.poisson(self.lambda_rate)\n",
    "        self.arrival_history.append(self.A_t)\n",
    "        if len(self.arrival_history) > self.D_max:\n",
    "            self.arrival_history.pop(0)\n",
    "        \n",
    "        if success:\n",
    "            self.k = 0\n",
    "            self.gamma_k = 0 if self.snr_feedback else None\n",
    "            self.previous_snrs = []\n",
    "        else:\n",
    "            self.k += 1\n",
    "            if self.snr_feedback:\n",
    "                if self.harq_type == 'CC':\n",
    "                    self.gamma_k = max(2**R_t - 1 - sum(self.previous_snrs), 0)\n",
    "                elif self.harq_type == 'IR':\n",
    "                    self.gamma_k = max((2**R_t) / np.prod([1 + s for s in self.previous_snrs]) - 1, 0)\n",
    "            self.previous_snrs.append(snr)\n",
    "        \n",
    "        state = [self.q_t, self.A_t, self.d_t, self.k]\n",
    "        if self.snr_feedback:\n",
    "            state.append(self.gamma_k)\n",
    "        \n",
    "        # Kiểm tra kết thúc episode (giả định đơn giản)\n",
    "        done = self.t >= self.T\n",
    "        \n",
    "        info = {'power': p_t, 'delay_violation': self.d_t}\n",
    "        \n",
    "        return np.array(state), reward, done, info\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _calculate_penalty(self):\n",
    "        #Tính toán giá trị phạt w(t) dựa trên số lần vi phạm độ trễ.\n",
    "        if self.d_t <= self.T * self.xi:\n",
    "            return self.Delta * (self.d_t / (self.T * self.xi)) ** self.beta\n",
    "        return self.Delta\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc65c503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trạng thái ban đầu: [  0 286   0   0   0]\n",
      "\n",
      "--- Bước 1 ---\n",
      "Hành động: [3. 1.]\n",
      "Trạng thái tiếp theo: [286. 314.   0.   1.   7.]\n",
      "Phần thưởng: -1.0\n",
      "Thông tin: {'power': np.float64(1.0), 'delay_violation': 0}\n",
      "\n",
      "--- Bước 2 ---\n",
      "Hành động: [3. 2.]\n",
      "Trạng thái tiếp theo: [600.         313.           0.           2.           4.73909189]\n",
      "Phần thưởng: -2.0\n",
      "Thông tin: {'power': np.float64(2.0), 'delay_violation': 0}\n",
      "\n",
      "--- Bước 3 ---\n",
      "Hành động: [3.  0.5]\n",
      "Trạng thái tiếp theo: [313. 333.   0.   0.   0.]\n",
      "Phần thưởng: -0.5\n",
      "Thông tin: {'power': np.float64(0.5), 'delay_violation': 0}\n",
      "\n",
      "--- Bước 4 ---\n",
      "Hành động: [3.   0.25]\n",
      "Trạng thái tiếp theo: [646. 338.   0.   1.   7.]\n",
      "Phần thưởng: -0.25\n",
      "Thông tin: {'power': np.float64(0.25), 'delay_violation': 0}\n",
      "\n",
      "--- Bước 5 ---\n",
      "Hành động: [3.  0.1]\n",
      "Trạng thái tiếp theo: [984.         304.           0.           2.           6.71754529]\n",
      "Phần thưởng: -0.1\n",
      "Thông tin: {'power': np.float64(0.1), 'delay_violation': 0}\n",
      "\n",
      "--- Bước 6 ---\n",
      "Hành động: [3.  0.1]\n",
      "Trạng thái tiếp theo: [1288.          328.            0.            3.            6.23572202]\n",
      "Phần thưởng: -0.1\n",
      "Thông tin: {'power': np.float64(0.1), 'delay_violation': 0}\n",
      "\n",
      "--- Bước 7 ---\n",
      "Hành động: [3.  0.1]\n",
      "Trạng thái tiếp theo: [1616.         324.           0.           4.           6.1947051]\n",
      "Phần thưởng: -0.1\n",
      "Thông tin: {'power': np.float64(0.1), 'delay_violation': 0}\n",
      "\n",
      "--- Bước 8 ---\n",
      "Hành động: [3.  0.2]\n",
      "Trạng thái tiếp theo: [1.6270000e+03 3.2700000e+02 1.0000000e+00 5.0000000e+00 6.1316671e+00]\n",
      "Phần thưởng: -0.20000000000020002\n",
      "Thông tin: {'power': np.float64(0.2), 'delay_violation': 1}\n",
      "\n",
      "--- Bước 9 ---\n",
      "Hành động: [3.   0.22]\n",
      "Trạng thái tiếp theo: [1621.          330.            2.            6.            5.65111909]\n",
      "Phần thưởng: -0.2200000131072\n",
      "Thông tin: {'power': np.float64(0.22), 'delay_violation': 2}\n",
      "\n",
      "--- Bước 10 ---\n",
      "Hành động: [3.   0.23]\n",
      "Trạng thái tiếp theo: [1613.          328.            3.            7.            5.58086088]\n",
      "Phần thưởng: -0.2300086093442\n",
      "Thông tin: {'power': np.float64(0.23), 'delay_violation': 3}\n",
      "\n",
      "--- Bước 11 ---\n",
      "Hành động: [3.   0.12]\n",
      "Trạng thái tiếp theo: [1637.          325.            4.            8.            3.24160085]\n",
      "Phần thưởng: -0.1208589934592\n",
      "Thông tin: {'power': np.float64(0.12), 'delay_violation': 4}\n",
      "\n",
      "--- Bước 12 ---\n",
      "Hành động: [3.    0.181]\n",
      "Trạng thái tiếp theo: [1634.          313.            5.            9.            3.20199367]\n",
      "Phần thưởng: -0.211517578125\n",
      "Thông tin: {'power': np.float64(0.181), 'delay_violation': 5}\n",
      "\n",
      "--- Bước 13 ---\n",
      "Hành động: [3.   0.08]\n",
      "Trạng thái tiếp theo: [1623.          327.            6.           10.            3.10841096]\n",
      "Phần thưởng: -0.6442219814911997\n",
      "Thông tin: {'power': np.float64(0.08), 'delay_violation': 6}\n",
      "\n",
      "--- Bước 14 ---\n",
      "Hành động: [3.   0.28]\n",
      "Trạng thái tiếp theo: [1623.          293.            7.           11.            3.07609998]\n",
      "Phần thưởng: -6.926586113920194\n",
      "Thông tin: {'power': np.float64(0.28), 'delay_violation': 7}\n",
      "\n",
      "--- Bước 15 ---\n",
      "Hành động: [3.   0.12]\n",
      "Trạng thái tiếp theo: [1586.         295.           8.          12.           2.4007086]\n",
      "Phần thưởng: -56.41499534213124\n",
      "Thông tin: {'power': np.float64(0.12), 'delay_violation': 8}\n",
      "\n",
      "--- Bước 16 ---\n",
      "Hành động: [3.   0.14]\n",
      "Trạng thái tiếp theo: [1553.          304.            9.           13.            2.22194614]\n",
      "Phần thưởng: -370.7440377703683\n",
      "Thông tin: {'power': np.float64(0.14), 'delay_violation': 9}\n",
      "\n",
      "--- Bước 17 ---\n",
      "Hành động: [3.  0.1]\n",
      "Trạng thái tiếp theo: [1.5320000e+03 3.3200000e+02 1.0000000e+01 1.4000000e+01 1.5088196e+00]\n",
      "Phần thưởng: -2000.1\n",
      "Thông tin: {'power': np.float64(0.1), 'delay_violation': 10}\n",
      "\n",
      "--- Bước 18 ---\n",
      "Hành động: [3.   0.04]\n",
      "Trạng thái tiếp theo: [1.55100000e+03 2.99000000e+02 1.10000000e+01 1.50000000e+01\n",
      " 1.11053104e+00]\n",
      "Phần thưởng: -2000.04\n",
      "Thông tin: {'power': np.float64(0.04), 'delay_violation': 11}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "\n",
    "    # Khởi tạo môi trường\n",
    "    env = ENV_paper(lambda_rate=300, D_max=5, xi=0.01, max_power=100, snr_feedback=True, harq_type='CC')\n",
    "    state = env.reset()\n",
    "    print(\"Trạng thái ban đầu:\", state)\n",
    "\n",
    "    # Danh sách hành động thử nghiệm: [R(t), p(t)]\n",
    "    actions = [\n",
    "        np.array([3.0, 1.0]),\n",
    "        np.array([3.0, 2.0]),\n",
    "        np.array([3.0, 0.5]),\n",
    "        np.array([3.0, 0.25]),\n",
    "        np.array([3.0, 0.1]),\n",
    "        np.array([3.0, 0.1]),\n",
    "        np.array([3.0, 0.1]),\n",
    "        np.array([3.0, 0.2]),\n",
    "        np.array([3.0, 0.22]),\n",
    "        np.array([3.0, 0.23]),\n",
    "        np.array([3.0, 0.12]),\n",
    "        np.array([3.0, 0.181]),\n",
    "        np.array([3.0, 0.08]),\n",
    "        np.array([3.0, 0.28]),\n",
    "        np.array([3.0, 0.12]),\n",
    "        np.array([3.0, 0.14]),\n",
    "        np.array([3.0, 0.10]),\n",
    "        np.array([3.0, 0.04]),\n",
    "    ]\n",
    "\n",
    "    # Thực hiện lần lượt các hành động\n",
    "    for i, action in enumerate(actions):\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        print(f\"\\n--- Bước {i + 1} ---\")\n",
    "        print(\"Hành động:\", action)\n",
    "        print(\"Trạng thái tiếp theo:\", next_state)\n",
    "        print(\"Phần thưởng:\", reward)\n",
    "        print(\"Thông tin:\", info)\n",
    "        if done:\n",
    "            print(\"===> Episode kết thúc do đạt T bước.\")\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
